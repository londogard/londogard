{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Recipe - Daft Object Detection\"\n",
    "description: \"A recipe on how to load data for Object Detection using Daft\"\n",
    "categories: [daft, recipe]\n",
    "date: \"2024-11-20\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my previous [blog-post](/posts/2024-10-24-data-loading-daft/) I introduced Daft. Now I wish to share recipes on how to do some things.\n",
    "\n",
    "## Loading From HuggingFace Datasets\n",
    "\n",
    "HuggingFace Datasets is one of the biggest dataset providers out there, integrating with them is something that is of great importance. Luckily it's easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting daft\n",
      "  Downloading daft-0.1.2-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from daft) (3.6.2)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from daft) (1.23.5)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from daft) (65.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->daft) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->daft) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->daft) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->daft) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/londogard/Library/Python/3.11/lib/python/site-packages (from matplotlib->daft) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->daft) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib->daft) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/londogard/Library/Python/3.11/lib/python/site-packages (from matplotlib->daft) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/londogard/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.7->matplotlib->daft) (1.16.0)\n",
      "Installing collected packages: daft\n",
      "Successfully installed daft-0.1.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U daft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>objects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>682</td>\n",
       "      <td>1024</td>\n",
       "      <td>{'bbox_id': [150311, 150312, 150313, 150314], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>683</td>\n",
       "      <td>1024</td>\n",
       "      <td>{'bbox_id': [158953, 158954, 158955, 158956, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                              image  width  height  \\\n",
       "0        23  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...    682    1024   \n",
       "1        25  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...    683    1024   \n",
       "\n",
       "                                             objects  \n",
       "0  {'bbox_id': [150311, 150312, 150313, 150314], ...  \n",
       "1  {'bbox_id': [158953, 158954, 158955, 158956, 1...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import datasets\n",
    "import daft\n",
    "\n",
    "daft.set_execution_config(enable_native_executor=True, default_morsel_size=256)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DaftHFDatasetWrapper:\n",
    "    _ds: datasets.Dataset\n",
    "    df_train: daft.DataFrame\n",
    "    df_val: daft.DataFrame\n",
    "\n",
    "def load_from_hf_dataset() -> DaftHFDatasetWrapper:\n",
    "    ds = datasets.load_dataset(\"detection-datasets/fashionpedia\")\n",
    "    df_train = daft.from_arrow(ds[\"train\"].data.table[:1000])\n",
    "    df_val = daft.from_arrow(ds[\"val\"].data.table[:1000])\n",
    "\n",
    "    return DaftHFDatasetWrapper(ds, df_train, df_val)\n",
    "\n",
    "daft_ds = load_from_hf_dataset()\n",
    "# custom to fashionpedia\n",
    "fashionpedia_num_classes = daft_ds._ds[\"train\"].features[\"objects\"].feature[\"category\"].num_classes\n",
    "\n",
    "daft_ds.df_train.limit(2).to_pandas()   # pretty-print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our DataFrame's ready we can start to load the data and train a model.\n",
    "\n",
    "To keep things simple we'll use a off-the-shelf model to do Object Detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "import lightning as L\n",
    "\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2\n",
    "from torchvision.transforms.functional import convert_image_dtype\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "\n",
    "class SimpleModel(L.LightningModule):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.model = fasterrcnn_resnet50_fpn_v2(num_classes=num_classes)\n",
    "\n",
    "    def forward(self, images, targets=None):\n",
    "        \"\"\"\n",
    "        Forward method for training and inference.\n",
    "        - During training, provide `targets` for loss computation.\n",
    "        - During inference, `targets` should be None for predictions.\n",
    "        \"\"\"\n",
    "        if targets:\n",
    "            return self.model(images, targets)\n",
    "        else:\n",
    "            return self.model(images)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Training step to compute loss.\n",
    "        \"\"\"\n",
    "        images, targets = batch\n",
    "        images = [convert_image_dtype(img, dtype=torch.float) for img in images]\n",
    "        loss_dict = self.model(images, targets)\n",
    "        loss = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Validation step for loss computation or other metrics.\n",
    "        \"\"\"\n",
    "        images, targets = batch\n",
    "        images = [convert_image_dtype(img, dtype=torch.float) for img in images]\n",
    "        loss_dict = self.model(images, targets)\n",
    "        val_loss = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        self.log(\"val_loss\", val_loss, prog_bar=True, logger=True)\n",
    "        return val_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configures optimizer and optionally a learning rate scheduler.\n",
    "        \"\"\"\n",
    "        optimizer = AdamW(self.model.parameters(), lr=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing an Image from HF Datasets\n",
    "\n",
    "To go from their \"image\" colums we need to decode the image. It's quite simply and the recipe below achieve this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table class=\"dataframe\">\n",
       "<thead><tr><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">image_id<br />Int64</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">image<br />Image[MIXED]</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">width<br />Int64</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">height<br />Int64</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">objects<br />Struct[bbox_id: List[Int64], category: List[Int64], bbox: List[FixedSizeList[Float64; 4]], area: List[Int64]]</th></tr></thead>\n",
       "<tbody>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">23</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\"><img style=\"max-height:128px;width:auto\" src=\"data:image/png;base64, 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\" alt=\"<Image>\" /></div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">682</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1024</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">{bbox_id: [150311, 150312, 150313, 150314],<br />category: [23, 23, 33, 10],<br />bbox: [[445, 910, 505, 983], [239, 940, 284, 994], [298, 282, 386, 352], [210, 282, 448, 665]],<br />area: [1422, 843, 373, 56375],<br />}</div></td></tr>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">25</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\"><img style=\"max-height:128px;width:auto\" src=\"data:image/png;base64, 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\" alt=\"<Image>\" /></div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">683</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1024</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">{bbox_id: [158953, 158954, 158955, 158956, 158957, 158958, 158959, 158960, 158961, 158962],<br />category: [2, 33, 31, 31, 13, 7, 22, 22, 23, 23],<br />bbox: [[182, 220, 472, 647], [294, 221, 407, 257], [405, 297, 472, 647], [182, 264, 266, 621], [284, 135, 372, 169], [238, 537, 414, 606], [351, 732, 417, 922], [202, 749, 270, 930], [200, 921, 256, 979], [373, 903, 455, 966]],<br />area: [87267, 1220, 16895, 18541, 1468, 9360, 8629, 8270, 2717, 3121],<br />}</div></td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "<small>(Showing first 2 rows)</small>\n",
       "</div>"
      ],
      "text/plain": [
       "╭──────────┬──────────────┬───────┬────────┬───────────────────────────────────────────────────────────╮\n",
       "│ image_id ┆ image        ┆ width ┆ height ┆ objects                                                   │\n",
       "│ ---      ┆ ---          ┆ ---   ┆ ---    ┆ ---                                                       │\n",
       "│ Int64    ┆ Image[MIXED] ┆ Int64 ┆ Int64  ┆ Struct[bbox_id: List[Int64], category: List[Int64], bbox: │\n",
       "│          ┆              ┆       ┆        ┆ List[FixedSizeList[Float64; 4]], area: List[Int64]]       │\n",
       "╞══════════╪══════════════╪═══════╪════════╪═══════════════════════════════════════════════════════════╡\n",
       "│ 23       ┆ <Image>      ┆ 682   ┆ 1024   ┆ {bbox_id: [150311, 150312, 15…                            │\n",
       "├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ 25       ┆ <Image>      ┆ 683   ┆ 1024   ┆ {bbox_id: [158953, 158954, 15…                            │\n",
       "╰──────────┴──────────────┴───────┴────────┴───────────────────────────────────────────────────────────╯\n",
       "\n",
       "(Showing first 2 rows)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| fig-cap: \"A Daft DataFrame, nifty as it shows images in notebooks!\"\n",
    "hf_img_to_daft_img = daft.col(\"image\").struct.get(\"bytes\").image.decode()\n",
    "\n",
    "daft_ds.df_train = daft_ds.df_train.with_column(\n",
    "    \"image\", hf_img_to_daft_img\n",
    ")\n",
    "daft_ds.df_train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table class=\"dataframe\">\n",
       "<thead><tr><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">objects<br />Struct[bbox_id: List[Int64], category: List[Int64], bbox: List[FixedSizeList[Float64; 4]], area: List[Int64]]</th></tr></thead>\n",
       "<tbody>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">{bbox_id: [150311, 150312, 150313, 150314],<br />category: [23, 23, 33, 10],<br />bbox: [[445, 910, 505, 983], [239, 940, 284, 994], [298, 282, 386, 352], [210, 282, 448, 665]],<br />area: [1422, 843, 373, 56375],<br />}</div></td></tr>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">{bbox_id: [158953, 158954, 158955, 158956, 158957, 158958, 158959, 158960, 158961, 158962],<br />category: [2, 33, 31, 31, 13, 7, 22, 22, 23, 23],<br />bbox: [[182, 220, 472, 647], [294, 221, 407, 257], [405, 297, 472, 647], [182, 264, 266, 621], [284, 135, 372, 169], [238, 537, 414, 606], [351, 732, 417, 922], [202, 749, 270, 930], [200, 921, 256, 979], [373, 903, 455, 966]],<br />area: [87267, 1220, 16895, 18541, 1468, 9360, 8629, 8270, 2717, 3121],<br />}</div></td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "<small>(Showing first 2 rows)</small>\n",
       "</div>"
      ],
      "text/plain": [
       "╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ objects                                                                                                       │\n",
       "│ ---                                                                                                           │\n",
       "│ Struct[bbox_id: List[Int64], category: List[Int64], bbox: List[FixedSizeList[Float64; 4]], area: List[Int64]] │\n",
       "╞═══════════════════════════════════════════════════════════════════════════════════════════════════════════════╡\n",
       "│ {bbox_id: [150311, 150312, 15…                                                                                │\n",
       "├╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ {bbox_id: [158953, 158954, 15…                                                                                │\n",
       "╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "\n",
       "(Showing first 2 rows)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "daft_ds.df_train.select(\"objects\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming and working with images\n",
    "\n",
    "Daft has some unique syntax for simple operations like `resize`.  \n",
    "To do the standard transforms we have to move into the python domain, and that's done by utilizing `np.array`'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table class=\"dataframe\">\n",
       "<thead><tr><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">image_id<br />Int64</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">image<br />Image[MIXED]</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">width<br />Int64</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">height<br />Int64</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">objects<br />Struct[bbox_id: List[Int64], category: List[Int64], bbox: List[FixedSizeList[Float64; 4]], area: List[Int64]]</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">bboxes<br />Tensor(Float32)</th></tr></thead>\n",
       "<tbody>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">23</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\"><img style=\"max-height:128px;width:auto\" src=\"data:image/png;base64, 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\" alt=\"<Image>\" /></div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">682</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1024</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">{bbox_id: [150311, 150312, 150313, 150314],<br />category: [23, 23, 33, 10],<br />bbox: [[445, 910, 505, 983], [239, 940, 284, 994], [298, 282, 386, 352], [210, 282, 448, 665]],<br />area: [1422, 843, 373, 56375],<br />}</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">&lt;Tensor shape=(4, 4)&gt;</div></td></tr>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">25</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\"><img style=\"max-height:128px;width:auto\" src=\"data:image/png;base64, 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\" alt=\"<Image>\" /></div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">683</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1024</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">{bbox_id: [158953, 158954, 158955, 158956, 158957, 158958, 158959, 158960, 158961, 158962],<br />category: [2, 33, 31, 31, 13, 7, 22, 22, 23, 23],<br />bbox: [[182, 220, 472, 647], [294, 221, 407, 257], [405, 297, 472, 647], [182, 264, 266, 621], [284, 135, 372, 169], [238, 537, 414, 606], [351, 732, 417, 922], [202, 749, 270, 930], [200, 921, 256, 979], [373, 903, 455, 966]],<br />area: [87267, 1220, 16895, 18541, 1468, 9360, 8629, 8270, 2717, 3121],<br />}</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">&lt;Tensor shape=(10, 4)&gt;</div></td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "<small>(Showing first 2 rows)</small>\n",
       "</div>"
      ],
      "text/plain": [
       "╭──────────┬──────────────┬───────┬────────┬──────────────────────────────────────────────────┬────────────────────────╮\n",
       "│ image_id ┆ image        ┆ width ┆ height ┆ objects                                          ┆ bboxes                 │\n",
       "│ ---      ┆ ---          ┆ ---   ┆ ---    ┆ ---                                              ┆ ---                    │\n",
       "│ Int64    ┆ Image[MIXED] ┆ Int64 ┆ Int64  ┆ Struct[bbox_id: List[Int64], category:           ┆ Tensor(Float32)        │\n",
       "│          ┆              ┆       ┆        ┆ List[Int64], bbox: List[FixedSizeList[Float64;   ┆                        │\n",
       "│          ┆              ┆       ┆        ┆ 4]], area: List[Int64]]                          ┆                        │\n",
       "╞══════════╪══════════════╪═══════╪════════╪══════════════════════════════════════════════════╪════════════════════════╡\n",
       "│ 23       ┆ <Image>      ┆ 682   ┆ 1024   ┆ {bbox_id: [150311, 150312, 15…                   ┆ <Tensor shape=(4, 4)>  │\n",
       "├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ 25       ┆ <Image>      ┆ 683   ┆ 1024   ┆ {bbox_id: [158953, 158954, 15…                   ┆ <Tensor shape=(10, 4)> │\n",
       "╰──────────┴──────────────┴───────┴────────┴──────────────────────────────────────────────────┴────────────────────────╯\n",
       "\n",
       "(Showing first 2 rows)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def apply_torch_transform(bboxes):\n",
    "    bboxes = torch.tensor(bboxes, dtype=torch.float32)\n",
    "    return bboxes\n",
    "\n",
    "daft_ds.df_train = daft_ds.df_train.with_column(\"bboxes\", daft.col(\"objects\").struct.get(\"bbox\").apply(apply_torch_transform, return_dtype=daft.DataType.tensor(daft.DataType.float32())))\n",
    "daft_ds.df_train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/londogard/git/londogard/code/data_loading/.pixi/envs/default/lib/python3.12/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torchvision.transforms import v2 as T\n",
    "\n",
    "img_to_tensor = daft.col(\"image\").cast(daft.DataType.tensor(dtype=daft.DataType.uint8()))\n",
    "\n",
    "transforms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.RandomResizedCrop(size=(224, 224), antialias=True),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "@daft.udf(return_dtype=daft.DataType.tensor(daft.DataType.float32()))\n",
    "def transform(image, bbox):\n",
    "    return transforms(image), transforms(bbox)\n",
    "\n",
    "\n",
    "def transform_images(df: daft.DataFrame) -> daft.DataFrame:\n",
    "    df = df.with_columns({\n",
    "        \"image\": img_to_tensor.apply(lambda x: transforms(x), return_dtype=daft.DataType.tensor(daft.DataType.float32())),\n",
    "        \"bboxes\": daft.col(\"bboxes\").apply(lambda x: transforms(x), return_dtype=daft.DataType.tensor(daft.DataType.float32()))\n",
    "        })\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "daft_ds.df_train = transform_images(daft_ds.df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table class=\"dataframe\">\n",
       "<thead><tr><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">image_id<br />Int64</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">image<br />Tensor(Float32)</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">width<br />Int64</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">height<br />Int64</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">objects<br />Struct[bbox_id: List[Int64], category: List[Int64], bbox: List[FixedSizeList[Float64; 4]], area: List[Int64]]</th><th style=\"text-wrap: nowrap; max-width:192px; overflow:auto; text-align:left\">bboxes<br />Tensor(Float32)</th></tr></thead>\n",
       "<tbody>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">23</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">&lt;Tensor shape=(3, 224, 224)&gt;</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">682</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1024</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">{bbox_id: [150311, 150312, 150313, 150314],<br />category: [23, 23, 33, 10],<br />bbox: [[445, 910, 505, 983], [239, 940, 284, 994], [298, 282, 386, 352], [210, 282, 448, 665]],<br />area: [1422, 843, 373, 56375],<br />}</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">&lt;Tensor shape=(3, 224, 224)&gt;</div></td></tr>\n",
       "<tr><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">25</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">&lt;Tensor shape=(3, 224, 224)&gt;</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">683</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">1024</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">{bbox_id: [158953, 158954, 158955, 158956, 158957, 158958, 158959, 158960, 158961, 158962],<br />category: [2, 33, 31, 31, 13, 7, 22, 22, 23, 23],<br />bbox: [[182, 220, 472, 647], [294, 221, 407, 257], [405, 297, 472, 647], [182, 264, 266, 621], [284, 135, 372, 169], [238, 537, 414, 606], [351, 732, 417, 922], [202, 749, 270, 930], [200, 921, 256, 979], [373, 903, 455, 966]],<br />area: [87267, 1220, 16895, 18541, 1468, 9360, 8629, 8270, 2717, 3121],<br />}</div></td><td><div style=\"text-align:left; max-width:192px; max-height:64px; overflow:auto\">&lt;Tensor shape=(3, 224, 224)&gt;</div></td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "<small>(Showing first 2 of 2 rows)</small>\n",
       "</div>"
      ],
      "text/plain": [
       "╭──────────┬────────────────────────┬───────┬────────┬────────────────────────────────┬────────────────────────────────╮\n",
       "│ image_id ┆ image                  ┆ width ┆ height ┆ objects                        ┆ bboxes                         │\n",
       "│ ---      ┆ ---                    ┆ ---   ┆ ---    ┆ ---                            ┆ ---                            │\n",
       "│ Int64    ┆ Tensor(Float32)        ┆ Int64 ┆ Int64  ┆ Struct[bbox_id: List[Int64],   ┆ Tensor(Float32)                │\n",
       "│          ┆                        ┆       ┆        ┆ category: List[Int64], bbox:   ┆                                │\n",
       "│          ┆                        ┆       ┆        ┆ List[FixedSizeList[Float64;    ┆                                │\n",
       "│          ┆                        ┆       ┆        ┆ 4]], area: List[Int64]]        ┆                                │\n",
       "╞══════════╪════════════════════════╪═══════╪════════╪════════════════════════════════╪════════════════════════════════╡\n",
       "│ 23       ┆ <Tensor shape=(3, 224, ┆ 682   ┆ 1024   ┆ {bbox_id: [150311, 150312, 15… ┆ <Tensor shape=(3, 224, 224)>   │\n",
       "│          ┆ 224)>                  ┆       ┆        ┆                                ┆                                │\n",
       "├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ 25       ┆ <Tensor shape=(3, 224, ┆ 683   ┆ 1024   ┆ {bbox_id: [158953, 158954, 15… ┆ <Tensor shape=(3, 224, 224)>   │\n",
       "│          ┆ 224)>                  ┆       ┆        ┆                                ┆                                │\n",
       "╰──────────┴────────────────────────┴───────┴────────┴────────────────────────────────┴────────────────────────────────╯\n",
       "\n",
       "(Showing first 2 of 2 rows)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "df = daft_ds.df_train.limit(2).collect()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2095104])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.as_tensor(df.loc[0, \"image\"][\"data\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.as_tensor(df.loc[0, \"bboxes\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pass individual images, not batches",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_bounding_boxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbboxes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/londogard/code/data_loading/.pixi/envs/default/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/londogard/code/data_loading/.pixi/envs/default/lib/python3.12/site-packages/torchvision/utils.py:200\u001b[0m, in \u001b[0;36mdraw_bounding_boxes\u001b[0;34m(image, boxes, labels, colors, fill, width, font, font_size)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe image dtype must be uint8 or float, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass individual images, not batches\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m image\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m}:\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly grayscale and RGB images are supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Pass individual images, not batches"
     ]
    }
   ],
   "source": [
    "torchvision.utils.draw_bounding_boxes(torch.as_tensor(df.loc[0, \"image\"][\"data\"]), torch.as_tensor(df.loc[0, \"bboxes\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
