<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Hampus Londögård">
<meta name="dcterms.date" content="2020-08-01">
<meta name="description" content="In this post I improve the previous FAQ search engine by some low hanging fruits. The requirements stay the same thus SotA is not achieved but rather it’s simply generic &amp; easy on hardware (Raspberry Pi capable).">

<title>Londogard Blog - CoViD-19 FAQ Search Engine 2.0</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon.ico" rel="icon">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
<meta name="twitter:title" content="Londogard Blog - CoViD-19 FAQ Search Engine 2.0">
<meta name="twitter:description" content="In this post I improve the previous FAQ search engine by some low hanging fruits. The requirements stay the same thus SotA is not achieved but rather it’s simply generic &amp; easy on hardware (Raspberry Pi capable).">
<meta name="twitter:image" content="https://colab.research.google.com/assets/colab-badge.svg">
<meta name="twitter:creator" content="@hlondogard">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Londogard Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../pages/presentations.html" rel="" target="">
 <span class="menu-text">Presentations</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://londogard.com/projects" rel="" target="">
 <span class="menu-text">Londogard Projects↗</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../pages/about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../pages/code_setup/code_setup.html" rel="" target="">
 <span class="menu-text">Dev Setup</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/hampus-londögård/" rel="" target=""><i class="bi bi-linkedin" role="img" aria-label="LinkedIn">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/hlondogard" rel="" target=""><i class="bi bi-twitter" role="img" aria-label="Twitter">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bi-github" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-bi-github">    
        <li>
    <a class="dropdown-item" href="https://github.com/lundez" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="dropdown-text">Lundez</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/londogard" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="dropdown-text">Londogard</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml" rel="" target=""><i class="bi bi-rss" role="img" aria-label="Londogard Blog RSS">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">CoViD-19 FAQ Search Engine 2.0</h1>
                  <div>
        <div class="description">
          In this post I improve the previous FAQ search engine by some low hanging fruits. The requirements stay the same thus SotA is not achieved but rather it’s simply generic &amp; easy on hardware (Raspberry Pi capable).
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">nlp</div>
                <div class="quarto-category">deep-learning</div>
                <div class="quarto-category">machine-learning</div>
                <div class="quarto-category">workshop</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Hampus Londögård </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">August 1, 2020</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#covid-19-faq-search-engine-2.0" id="toc-covid-19-faq-search-engine-2.0" class="nav-link active" data-scroll-target="#covid-19-faq-search-engine-2.0">CoViD-19 FAQ Search Engine 2.0</a>
  <ul class="collapse">
  <li><a href="#improvements-to-be-done" id="toc-improvements-to-be-done" class="nav-link" data-scroll-target="#improvements-to-be-done">Improvements to be done</a></li>
  <li><a href="#re-adding-the-old-code" id="toc-re-adding-the-old-code" class="nav-link" data-scroll-target="#re-adding-the-old-code">Re-adding the old code</a></li>
  <li><a href="#going-forward" id="toc-going-forward" class="nav-link" data-scroll-target="#going-forward">Going forward</a>
  <ul class="collapse">
  <li><a href="#tokenization-lower-case" id="toc-tokenization-lower-case" class="nav-link" data-scroll-target="#tokenization-lower-case">1. Tokenization &amp; lower-case</a></li>
  <li><a href="#testing-the-new-input-data" id="toc-testing-the-new-input-data" class="nav-link" data-scroll-target="#testing-the-new-input-data">Testing the new input-data</a></li>
  <li><a href="#lemmatization-and-stop-words" id="toc-lemmatization-and-stop-words" class="nav-link" data-scroll-target="#lemmatization-and-stop-words">2. Lemmatization and Stop Words</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>In this post I improve the previous FAQ search engine by some low hanging fruits. The requirements stay the same thus SotA is not achieved but rather it’s simply generic &amp; easy on hardware (Raspberry Pi capable).</p>
<!--truncate-->
<p><a href="https://colab.research.google.com/github/londogard/nlp-projects/blob/master/python/CoViD_19_QA_cont.ipynb%5D"><img src="https://colab.research.google.com/assets/colab-badge.svg" class="img-fluid" alt="Open In Colab"></a> <a href="https://mybinder.org/v2/gh/londogard/nlp-projects/HEAD?labpath=python%2FCoViD_19_QA_cont.ipynb"><img src="https://mybinder.org/badge_logo.svg" class="img-fluid" alt="Binder"></a></p>
<section id="covid-19-faq-search-engine-2.0" class="level1">
<h1>CoViD-19 FAQ Search Engine 2.0</h1>
<p>As promised here’s a new improved (or is it?) <em>FAQ Search Engine</em> with some minor NLP-lessons added as we go, be ready to learn new (or old) things!<br>
Previously I added some requirements and I wish keep them, here they are as a refresher:</p>
<ul>
<li>The end-product must be unsupervised
<ul>
<li>No manually annotated data</li>
<li>No heuristic applied (i.e.&nbsp;understand the data and improve result by applying domain-specific knowledge on the task)</li>
</ul></li>
<li>It should be light enough to run on a Raspberry Pi later on (hopefully on the JVM to keep it simple with my back-end)</li>
<li>Must be Swedish all the way through - no translations (English models you can transfer knowledge from tends to be stronger, but I want to keep this fun!)</li>
</ul>
<p>These specifications adds a bit of spice, keep manual labour to a minimum at the same time as they prove a challenge that doesn’t aim to achieve State of the Art but rather to be applicable and light!</p>
<p>With that in mind, let’s move onwards!</p>
<section id="improvements-to-be-done" class="level2">
<h2 class="anchored" data-anchor-id="improvements-to-be-done">Improvements to be done</h2>
<p>In the previous <a href="https://londogard.com/blog/4">blog</a> &amp; <a href="https://colab.research.google.com/github/londogard/nlp-projects/blob/master/python/CoViD_19_QA.ipynb">notebook</a> I first implemented a basic FAQ search based on finding the nearest neighbour from the embedded sentences, in the end I used <em>Smooth Inverse Frequency Embeddings</em> (<a href="https://openreview.net/forum?id=SyK00v5xx">A Simple but Tough-to-Beat Baseline for Sentence Embeddings</a>) to embed the sentence which is an improvement from simply averaging the embeddings of the words in the sentence.</p>
<p>In the end I discussed some potential improvements which I wished to investigate. In this notebook I’ll deliver these “improvements” based on grabbing some low hanging fruit. The total “improvements” to try out:</p>
<ul>
<li>Lowercase</li>
<li>Better tokenization</li>
<li>Lemmatizing</li>
<li>Stop words</li>
<li>Ngram &amp; Custom Embeddings (will not be done because of time)</li>
</ul>
<p>To improve further I’d say that either A) <em>a lot</em> of time to understand the data in depth and apply heuristics or B) a <em>supervised</em> approach, which in turn require labeled data (a.k.a sweet valued time). A larger dataset would also be helpful.<br>
All which I don’t have currently.</p>
</section>
<section id="re-adding-the-old-code" class="level2">
<h2 class="anchored" data-anchor-id="re-adding-the-old-code">Re-adding the old code</h2>
<p>First I’ll add the code from “part one” and it’ll not be commented as it has been walked through.<br>
Further I’ve removed the download &amp; parsing of FAQ, now the data is directly downloaded as a <code>tsv</code>-file allowing us to skip some libraries / code-cells.<br>
Some new dependencies are also added, e.g.&nbsp;<code>stanza</code> which is Stanfords new NLP-lib in Python (inspired by <code>spaCy</code>).</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>capture</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U gensim</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>U fse</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install stanza</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install stop<span class="op">-</span>words</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np <span class="co"># linear algebra</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd <span class="co"># data processing, CSV file I/O (e.g. pd.read_csv)</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>tqdm.pandas()</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random </span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> operator </span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> regex <span class="im">as</span> re</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co"># gensim + fasttext</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models.fasttext <span class="im">import</span> FastText, load_facebook_vectors</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> KeyedVectors</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> stop_words <span class="im">import</span> get_stop_words <span class="co"># stop-words from basically all languages</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> stanza</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fse <span class="im">import</span> IndexedList</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fse.models <span class="im">import</span> uSIF</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fse.models.average <span class="im">import</span> FAST_VERSION, MAX_WORDS_IN_BATCH</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(MAX_WORDS_IN_BATCH)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(FAST_VERSION)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>10000
1</code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Download models etc</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>stanza.download(<span class="st">'sv'</span>, logging_level<span class="op">=</span><span class="st">'ERROR'</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"OBS!!</span><span class="ch">\n</span><span class="st">Please download the Swe fastText model &amp; the CoViD FAQ data from links in this code cell!"</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Swe fastText reduced dimensions --&gt;   https://drive.google.com/open?id=1vaWtiSlRAZ3XCdtnSce_6dwQ0T5x0OEJ</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># CoViD FAQ data --&gt;                    https://github.com/londogard/nlp-projects/blob/master/datasets/covid.tsv</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>OBS!!
Please download the Swe fastText model &amp; the CoViD FAQ data from links in this code cell!</code></pre>
<section id="loading-all-the-models" class="level4">
<h4 class="anchored" data-anchor-id="loading-all-the-models">Loading all the models</h4>
<p>This might take a little while, even though the dimensions are reduced the model is pretty large.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>ft_wv <span class="op">=</span> load_facebook_vectors(<span class="st">'~/git/nlp-projects/models/cc.sv.100.bin'</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'~/git/nlp-projects/datasets/covid.tsv'</span>, sep<span class="op">=</span><span class="st">'</span><span class="ch">\t</span><span class="st">'</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> stanza.Pipeline(lang<span class="op">=</span><span class="st">'sv'</span>, processors<span class="op">=</span><span class="st">'tokenize'</span>, logging_level<span class="op">=</span><span class="st">'ERROR'</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> uSIF(ft_wv, workers<span class="op">=</span><span class="dv">4</span>, lang_freq<span class="op">=</span><span class="st">"sv"</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>flatten <span class="op">=</span> <span class="kw">lambda</span> l: [item <span class="cf">for</span> sublist <span class="kw">in</span> l <span class="cf">for</span> item <span class="kw">in</span> sublist] <span class="co"># Helper function to flatten a list</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="going-forward" class="level2">
<h2 class="anchored" data-anchor-id="going-forward">Going forward</h2>
<p>Let’s get on to adding our improvements</p>
<section id="tokenization-lower-case" class="level3">
<h3 class="anchored" data-anchor-id="tokenization-lower-case">1. Tokenization &amp; lower-case</h3>
<p>The first and forthmost improvement is to lowercase the text and then tokenize it using a better method of tokenization.<br>
Let’s take a look at how <em>stanza</em> helps us out by applying a much better tokenization.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>q <span class="op">=</span> <span class="st">"Hej där borta! Jag känner igen dig, Johan's kompis? Eller är det Johannas?"</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>stanza_tokenize <span class="op">=</span> <span class="kw">lambda</span> x: [token.text <span class="cf">for</span> sentence <span class="kw">in</span> nlp(x).sentences <span class="cf">for</span> token <span class="kw">in</span> sentence.tokens]</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>prev <span class="op">=</span> q.split()</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>new <span class="op">=</span> stanza_tokenize(q)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Previously:</span><span class="ch">\t</span><span class="sc">{</span>prev[:<span class="dv">12</span>]<span class="sc">}</span><span class="ss">.."</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"After:</span><span class="ch">\t\t</span><span class="sc">{</span>new[:<span class="dv">12</span>]<span class="sc">}</span><span class="ss">.."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>Previously: ['Hej', 'där', 'borta!', 'Jag', 'känner', 'igen', 'dig,', "Johan's", 'kompis?', 'Eller', 'är', 'det']..
After:      ['Hej', 'där', 'borta', '!', 'Jag', 'känner', 'igen', 'dig', ',', 'Johan', "'", 's']..</code></pre>
<p><strong>So, what are we looking at?</strong><br>
Stanza handled our tokenization and increased the number of tokens, can this really be good!?<br>
Yes! Keep calm and don’t jump the ship yet, the increased number of tokens will be followed by a decrease of unique tokens, and indirectly out of vocobulary (OOV) tokens. Unlike what we set out to do we still don’t lower-case the output, this will follow later, now let me explain what the tokenization helps us achieve:</p>
<ol type="1">
<li>Punctuation, e.g.&nbsp;[!,?..], is tokenized into its own token.</li>
<li>Some compound words are split up, e.g.&nbsp;<em>Johan’s</em> is now <em>Johan</em>, <em>’</em>, <em>s</em> which is three (3) separate tokens rather than one.</li>
</ol>
<p>Because of the updated tokenization <em>fredag</em> and <em>fredag!</em> is now tokenized as [<em>fredag</em>] and [<em>fredag</em>, <em>!</em>], this in fact turns <em>fredag</em> into the same token in both thus achieving the same vector when embedded which is great, because it really means the same. The exclamation mark itself also applies the same meaning to all places it’s applied, which in itself is an improvement now also as we embed it separately.</p>
<p><strong>Why is this good?</strong><br>
Even though we see a direct increase in number of tokens we see a <strong>decrease</strong> of number of unique tokens because we now tokenize <em>borta</em>, <em>borta?</em>, &amp; <em>borta!</em> as the same token, with one additional for the punctuation in the two latter cases rather than 3 separate tokens which would map to different data.<br>
The coverage of our Word Embeddings also increase because we now tokenize the text better. Perhaps <em>borta!</em> does not exist but <em>borta</em> surely do exist in the embedding dictionary / lookup.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># A bit ugly, that's what happens when you're lazy</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_dimensions(preprocessing<span class="op">=</span>[stanza_tokenize]):</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    prev <span class="op">=</span> flatten(df[<span class="st">'question'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.split()).tolist())</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    post <span class="op">=</span> flatten(df[<span class="st">'question'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: preprocess(x, preprocessing)).tolist())</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Previously: </span><span class="sc">{</span><span class="bu">len</span>(prev)<span class="sc">}</span><span class="ss"> tokens (</span><span class="sc">{</span><span class="bu">len</span>(<span class="bu">set</span>(prev))<span class="sc">}</span><span class="ss"> unique)"</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Post: </span><span class="sc">{</span><span class="bu">len</span>(post)<span class="sc">}</span><span class="ss"> tokens (</span><span class="sc">{</span><span class="bu">len</span>(<span class="bu">set</span>(post))<span class="sc">}</span><span class="ss"> unique)"</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Token reduction by ~</span><span class="sc">{</span><span class="dv">100</span> <span class="op">*</span> (<span class="dv">1</span><span class="op">-</span> <span class="bu">len</span>(<span class="bu">set</span>(post))<span class="op">/</span><span class="bu">len</span>(<span class="bu">set</span>(prev)))<span class="sc">:.1f}</span><span class="ss"> %"</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> [<span class="st">'#Tokens'</span>, <span class="st">'#Unique Tokens'</span>]</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    width <span class="op">=</span> <span class="fl">0.35</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.arange(<span class="bu">len</span>(labels))</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    rects1 <span class="op">=</span> ax.bar(x <span class="op">-</span> width<span class="op">/</span><span class="dv">2</span>, [<span class="bu">len</span>(prev), <span class="bu">len</span>(<span class="bu">set</span>(prev))], width, label<span class="op">=</span><span class="st">'Before'</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    rects2 <span class="op">=</span> ax.bar(x <span class="op">+</span> width<span class="op">/</span><span class="dv">2</span>, [<span class="bu">len</span>(post), <span class="bu">len</span>(<span class="bu">set</span>(post))], width, label<span class="op">=</span><span class="st">'After'</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'Tokens'</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="st">'Tokens before and after'</span>)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    ax.set_xticklabels(labels)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    ax.set_xticks(x)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    ax.legend()</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    fig.tight_layout()</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a><span class="co"># preprocessing is a list of lambda functions to apply</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess(text, preprocessing):</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> f <span class="kw">in</span> preprocessing:</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> f(text)</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> text</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Let’s take a look how much this actually mattered!</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>test_dimensions()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>Previously: 629 tokens (289 unique)
Post: 713 tokens (273 unique)
Token reduction by ~5.5 %</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="output_13_1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">svg</figcaption>
</figure>
</div>
<p>The expectations set up has been achieved and we can clearly see that the raw number of tokens grew while the unique token count shrinked.<br>
Applying lower-case to the text will further reduce the number of unique tokens, and obviously keep the number of tokens at the same count.</p>
<p>Let’s add lower-casing and see what happens!</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>lowercase <span class="op">=</span> <span class="kw">lambda</span> x: x.lower()</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>preprocess_funcs <span class="op">=</span> [lowercase, stanza_tokenize]</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>test_dimensions(preprocessing<span class="op">=</span>preprocess_funcs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>Previously: 629 tokens (289 unique)
Post: 712 tokens (260 unique)
Token reduction by ~10.0 %</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="output_15_1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">svg</figcaption>
</figure>
</div>
<section id="lower-casing" class="level4">
<h4 class="anchored" data-anchor-id="lower-casing">Lower-casing</h4>
<p>Going from 5.5 to 10 % reduction is nothing to sneeze at, by applying these two simple techniques we now have the same data in a better format which allows us to have a lower number of unique tokens.<br>
Pretty awesome right?</p>
<p>Let’s get on with this and apply the preprocessing to the questions and test it out with the FAQ-search!</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'X'</span>] <span class="op">=</span> df[<span class="st">'question'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: preprocess(x, preprocess_funcs))</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'X'</span>].head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>0                            [vad, är, coronavirus, ?]
1                               [vad, är, covid-19, ?]
2    [vad, skiljer, covid-19, från, säsongsinfluens...
3               [vilka, är, symtomen, på, covid-19, ?]
4    [hur, vet, jag, om, mina, symtom, beror, på, p...
Name: X, dtype: object</code></pre>
</section>
</section>
<section id="testing-the-new-input-data" class="level3">
<h3 class="anchored" data-anchor-id="testing-the-new-input-data">Testing the new input-data</h3>
<p>Now that we’ve created our input data we need to test our model on this!<br>
By applying the <code>IndexedList</code> which is the dataformat <code>SFE</code> wants as input we can train the model and then test it.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>sfe_format <span class="op">=</span> IndexedList(df[<span class="st">'X'</span>].tolist())</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>model.train(sfe_format)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>(75, 712)</code></pre>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Helper method to test the closest questions</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_n_closest_questions(question, preprocessing, n<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    q_fixed <span class="op">=</span> preprocess(question, preprocessing)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    resp <span class="op">=</span> model.sv.similar_by_sentence(q_fixed, model<span class="op">=</span>model, indexable<span class="op">=</span>df[<span class="st">'question'</span>].tolist()) <span class="co"># [([tokens], score)]</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    resp <span class="op">=</span> [<span class="ss">f'</span><span class="sc">{</span>result[<span class="dv">2</span>]<span class="sc">:.2f}</span><span class="ss">: </span><span class="sc">{</span>result[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> result <span class="kw">in</span> resp]</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>.join(resp[:n]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>get_n_closest_questions(<span class="st">"kan min hamster bli smittad?"</span>, preprocess_funcs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>0.67: Kan man bli smittad av en person som har covid-19 men som inte har några symtom?
0.63: Kan covid-19 smitta mellan djur och människa och kan mitt husdjur smittas av viruset?
0.54: Kan viruset smitta till människa via post och paket?
0.42: Kan smitta överföras från mygg till människa?</code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>get_n_closest_questions(<span class="st">"Hur får jag min son att förstå?"</span>, preprocess_funcs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>0.82: Hur pratar man med barn om det nya coronaviruset?
0.80: Vad är covid-19?
0.78: Hur sjuk blir man av covid-19?
0.77: Hur länge är man sjuk av covid-19?</code></pre>
</section>
<section id="lemmatization-and-stop-words" class="level3">
<h3 class="anchored" data-anchor-id="lemmatization-and-stop-words">2. Lemmatization and Stop Words</h3>
<p>Let’s try to further improve this by actually lemmatizing and applying stop-words!</p>
<section id="lemmatization" class="level4">
<h4 class="anchored" data-anchor-id="lemmatization">Lemmatization</h4>
<p>So what is Lemmatization? Quoting Stanfords description:</p>
<blockquote class="blockquote">
<p>For grammatical reasons, documents are going to use different forms of a word, such as organize, organizes, and organizing. Additionally, there are families of derivationally related words with similar meanings, such as democracy, democratic, and democratization. In many situations, it seems as if it would be useful for a search for one of these words to return documents that contain another word in the set.</p>
</blockquote>
<blockquote class="blockquote">
<p>The goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form. For instance:</p>
</blockquote>
<pre><code>     am, are, is =&gt; be
     car, cars, car's, cars' =&gt; car </code></pre>
<blockquote class="blockquote">
<p>The result of this mapping of text will be something like:</p>
</blockquote>
<pre><code>     the boy's cars are different colors =&gt;
     the boy car be differ color </code></pre>
</section>
<section id="what-is-stop-words" class="level4">
<h4 class="anchored" data-anchor-id="what-is-stop-words">What is stop-words?</h4>
<p>Stop-words are words we want to throw away as they add no real purpose. In older Machine Learning approaches it was way more important to add stop-words but in newer Deep Learning with Neural Networks stop-words often can be a negative thing, removing understanding of the sentence and perhaps minor differences which makes the world for understanding.</p>
<p>A example of a stop-word list could be <code>["hej", "vem", "då", "och", ...]</code> which means that these words would be removed from a sentence.</p>
<p>In our case it makes sense to remove words like ‘vad’, ‘varför’ and so on because the return of the FAQ seems to be very weighted towards these words.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> stanza.Pipeline(lang<span class="op">=</span><span class="st">'sv'</span>, processors<span class="op">=</span><span class="st">'tokenize,mwt,pos,lemma'</span>, logging_level<span class="op">=</span><span class="st">'ERROR'</span>)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>stanza_lemma <span class="op">=</span> <span class="kw">lambda</span> x: [token.lemma <span class="cf">for</span> sentence <span class="kw">in</span> nlp(x).sentences <span class="cf">for</span> token <span class="kw">in</span> sentence.words]</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>preprocess_funcs_lemma <span class="op">=</span> [lowercase, stanza_lemma]</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Previously:</span><span class="ch">\t</span><span class="sc">{</span>preprocess(<span class="st">"hur förklarar jag för min dotter och son?"</span>, preprocess_funcs)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'After:</span><span class="ch">\t\t</span><span class="sc">{</span>preprocess(<span class="st">"hur förklarar jag för min dotter och son?"</span>, preprocess_funcs_lemma)<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>Previously: ['hur', 'förklarar', 'jag', 'för', 'min', 'dotter', 'och', 'son', '?']
After:      ['hur', 'förklara', 'jag', 'för', 'jag', 'dotter', 'och', 'son', '?']</code></pre>
<p><strong>Some interesting notes</strong><br>
Seeing ‘<em>min</em>’ getting converted to ‘<em>jag</em>’ is both good and bad, in this case we reduce dimensionality of the problem but we loose context and understanding. <em>jag</em> and <em>min</em> certainly does not mean the same thing.</p>
<p>Let’s see how it pans out…</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>test_dimensions(preprocess_funcs_lemma)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>Previously: 629 tokens (289 unique)
Post: 712 tokens (228 unique)
Token reduction by ~21.1 %</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="output_26_1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">svg</figcaption>
</figure>
</div>
<div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">del</span> model</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> uSIF(ft_wv, workers<span class="op">=</span><span class="dv">4</span>, lang_freq<span class="op">=</span><span class="st">"sv"</span>)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'X'</span>] <span class="op">=</span> df[<span class="st">'question'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: preprocess(x, preprocess_funcs_lemma))</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>sfe_format <span class="op">=</span> IndexedList(df[<span class="st">'X'</span>].tolist())</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>model.train(sfe_format)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>(75, 712)</code></pre>
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>get_n_closest_questions(<span class="st">"kan min hamster bli smittad?"</span>, preprocess_funcs_lemma)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>0.75: Kan covid-19 smitta mellan djur och människa och kan mitt husdjur smittas av viruset?
0.69: Hur smittar covid-19?
0.68: Kan man smittas flera gånger av det nya coronaviruset?
0.63: Smittar covid-19 via vatten och mat?</code></pre>
<div class="sourceCode" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>get_n_closest_questions(<span class="st">"Hur får jag min son att förstå?"</span>, preprocess_funcs_lemma)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>0.79: Vad är covid-19?
0.75: Hur sjuk blir man av covid-19?
0.74: Hur länge är man sjuk av covid-19?
0.66: Om en person i familjen är sjuk - måste alla stanna hemma då?</code></pre>
</section>
<section id="analyzing-the-results" class="level4">
<h4 class="anchored" data-anchor-id="analyzing-the-results">Analyzing the results</h4>
<p><strong>Improvements?</strong><br>
Not really, the model has an improved response to the ‘hamster-question’ but it’s way off when asking about the son.</p>
<p><strong>Why?</strong><br>
The most likely explanation is that even though we reduce the input dimensions an awful lot we remove dimensions that brings value, and removing value is bad - just as was touched upon previously. It might be helpful in some cases, perhaps this could prove helpful for a supervised approach such as TF-IDF + Support Vector Machine.</p>
<p><strong>Any good parts?</strong><br>
Yes, we can see some pretty hefty memory-requirement reductions when working with other types of models by applying this. Actually, in the case of this we could reduce the memory requirement by lemmatizing the dictionary of the embeddings and removing all non-lemmas. All in all, this could lead to a small performance loss but great memory win.</p>
</section>
<section id="stop-words" class="level4">
<h4 class="anchored" data-anchor-id="stop-words">Stop words</h4>
<p>As promised we shall apply stop-words, but as we saw no performance gain with lemmatization we’ll keep the old tokenization.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>stop_words <span class="op">=</span> get_stop_words(<span class="st">'sv'</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>clean_stop <span class="op">=</span> <span class="kw">lambda</span> x: [word <span class="cf">for</span> word <span class="kw">in</span> x <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> stop_words]</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>preprocessing_func_stop <span class="op">=</span> [lowercase, stanza_tokenize, clean_stop]</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="kw">del</span> model</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> uSIF(ft_wv, workers<span class="op">=</span><span class="dv">4</span>, lang_freq<span class="op">=</span><span class="st">"sv"</span>)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'X'</span>] <span class="op">=</span> df[<span class="st">'question'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: preprocess(x, preprocessing_func_stop)) <span class="co"># We don't need to remove stop-words in the sentences in our </span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>sfe_format <span class="op">=</span> IndexedList(df[<span class="st">'X'</span>].tolist())</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>model.train(sfe_format)</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>preprocess(<span class="st">"hur förklarar jag för min dotter och son?"</span>, preprocessing_func_stop)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>['förklarar', 'dotter', 'son', '?']</code></pre>
<div class="sourceCode" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>test_dimensions(preprocessing_func_stop)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>Previously: 629 tokens (289 unique)
Post: 417 tokens (206 unique)
Token reduction by ~28.7 %</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="output_32_1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">svg</figcaption>
</figure>
</div>
<div class="sourceCode" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>get_n_closest_questions(<span class="st">"kan min hamster bli smittad?"</span>, preprocessing_func_stop)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>0.66: Kan man bli smittad av en person som har covid-19 men som inte har några symtom?
0.64: Kan covid-19 smitta mellan djur och människa och kan mitt husdjur smittas av viruset?
0.54: Kan viruset smitta till människa via post och paket?
0.41: Kan smitta överföras från mygg till människa?</code></pre>
<div class="sourceCode" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>get_n_closest_questions(<span class="st">"Hur får jag min son att förstå?"</span>, preprocessing_func_stop)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>0.83: Vad är covid-19?
0.83: Hur pratar man med barn om det nya coronaviruset?
0.80: Hur sjuk blir man av covid-19?
0.80: Hur länge är man sjuk av covid-19?</code></pre>
</section>
<section id="further-analyzing" class="level4">
<h4 class="anchored" data-anchor-id="further-analyzing">Further analyzing</h4>
<p>In my mind we’ve some pretty good responses, in a way better and another way worse than lemmatizaton. Certainly not a set-back but neither a step forward.<br>
Testing different approaches and turning things on and off is a great way to increase data understanding and also gives a better sense of what different preprocessing functions actually does.<br>
In fact this is actually part of the most common Machine Learning development approach, working much like agile, which is iteratively circular and called <a href="https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining">CRISP-DM</a>. I won’t go deeply into CRISP-DM (already did once in my Master Thesis), but the following image gives you the gist.<br>
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/CRISP-DM_Process_Diagram.png/220px-CRISP-DM_Process_Diagram.png" class="img-fluid" alt="CRISP-DM"></p>
<p>Finally, as we see no great impact by applying either lemmatization nor stop-words we might just give up at the lower-case + stanza tokenization, but I’d like to make one last shot in the dark - custom stop words! Let’s see how it fares…</p>
<section id="custom-stop-words-breaking-the-rules" class="level5">
<h5 class="anchored" data-anchor-id="custom-stop-words-breaking-the-rules">Custom Stop Words (breaking the rules)</h5>
<p>So I decided to break the rules and create a small simple heuristic by applying custom stop words.<br>
Let’s figure out which words we should remove using the following steps (which could in fact be automated)!</p>
<ol type="1">
<li>Find the most common words</li>
<li>Remove the ones which does not give any greater value</li>
</ol>
<div class="sourceCode" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'X'</span>] <span class="op">=</span> df[<span class="st">'question'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: preprocess(x, preprocess_funcs))</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>counter <span class="op">=</span> Counter(flatten(df[<span class="st">'X'</span>].tolist()))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="bu">sorted</span>(counter.items(), key<span class="op">=</span><span class="kw">lambda</span> item: item[<span class="dv">1</span>], reverse<span class="op">=</span><span class="va">True</span>)[:<span class="dv">15</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>[('?', 75),
 ('covid-19', 28),
 ('vad', 25),
 ('och', 22),
 ('hur', 21),
 ('för', 20),
 ('det', 15),
 ('kan', 14),
 ('i', 14),
 ('jag', 13),
 ('av', 13),
 ('gäller', 12),
 ('som', 12),
 ('är', 11),
 ('en', 11)]</code></pre>
<div class="sourceCode" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>stop_words <span class="op">=</span> [<span class="st">'?'</span>, <span class="st">'och'</span>, <span class="st">'jag'</span>, <span class="st">'i'</span>, <span class="st">'är'</span>, <span class="st">'en'</span>, <span class="st">'min'</span>, <span class="st">'?'</span>]</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>clean_stop <span class="op">=</span> <span class="kw">lambda</span> x: [word <span class="cf">for</span> word <span class="kw">in</span> x <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> stop_words]</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>preprocessing_func_stop <span class="op">=</span> [lowercase, stanza_tokenize, clean_stop]</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="kw">del</span> model</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> uSIF(ft_wv, workers<span class="op">=</span><span class="dv">4</span>, lang_freq<span class="op">=</span><span class="st">"sv"</span>)</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'X'</span>] <span class="op">=</span> df[<span class="st">'question'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: preprocess(x, preprocessing_func_stop)) <span class="co"># We don't need to remove stop-words in the sentences in our </span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>sfe_format <span class="op">=</span> IndexedList(df[<span class="st">'X'</span>].tolist())</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>model.train(sfe_format)</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>preprocess(<span class="st">"hur förklarar jag för min dotter och son?"</span>, preprocessing_func_stop)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>['hur', 'förklarar', 'för', 'dotter', 'son']</code></pre>
<div class="sourceCode" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>get_n_closest_questions(<span class="st">"Hur får jag min son att förstå?"</span>, preprocessing<span class="op">=</span>preprocess_funcs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>0.83: Hur pratar man med barn om det nya coronaviruset?
0.83: Vad är covid-19?
0.80: Hur sjuk blir man av covid-19?
0.79: Hur länge är man sjuk av covid-19?</code></pre>
<div class="sourceCode" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>get_n_closest_questions(<span class="st">"kan min hamster bli smittad?"</span>, preprocessing<span class="op">=</span>preprocess_funcs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>0.66: Kan man bli smittad av en person som har covid-19 men som inte har några symtom?
0.63: Kan covid-19 smitta mellan djur och människa och kan mitt husdjur smittas av viruset?
0.54: Kan viruset smitta till människa via post och paket?
0.41: Kan smitta överföras från mygg till människa?</code></pre>
<p>Not bad, not amazing - I feel pretty happy about this.</p>
<p>So what can be done from now on if time and resources where available?</p>
<ul>
<li>Add a classifier + TF-IDF</li>
<li>BERT / ALBERT QA (the State-of-the-Art right now)</li>
</ul>
<p>Thanks for this time,<br>
- Hampus Londögård</p>


</section>
</section>
</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="londogard/londogard" data-repo-id="MDEwOlJlcG9zaXRvcnkyOTcyNzE0MzE=" data-category="General" data-category-id="MDE4OkRpc2N1c3Npb25DYXRlZ29yeTMwODYxNzM4" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://www.buymeacoffee.com/hlondogard"><img src="https://cdn.buymeacoffee.com/buttons/v2/default-blue.png" class="img-fluid" width="100"></a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://github.com/sponsors/Lundez?o=esb"><img src="https://img.shields.io/static/v1?label=Sponsor&amp;message=%E2%9D%A4&amp;logo=GitHub&amp;color=%23fe8e86.png" class="img-fluid" width="100"></a>
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="../../pages/about.html">About</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/hampus-londögård/">
      <i class="bi bi-linkedin" role="img" aria-label="LinkedIn">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/hlondogard">
      <i class="bi bi-twitter" role="img" aria-label="Twitter">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/lundez">
      <i class="bi bi-github" role="img" aria-label="Lundez GitHub">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml">
      <i class="bi bi-rss" role="img" aria-label="Londogard Blog RSS">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>



</body></html>