---
title: "Self-Contained ML Models through MLFLow Model Registry"
description: "Most in the machine learning community knows about MLFlow and uses it to track experiments. One of multiple 'extras' is the Model Registry. The Model Registry is quite cool and I'll share how you can build your self-contained ML models."
categories: [python, mlflow, deployment, machine-learning]
date: "2025-02-25"
---

# MLFlow Model Registry

MLFlow is a popular tool to track your experiment to compare metrics, parameters and much more. It helps streamlining your job as a _data scientist_, and it also assist _machine learning engineers_ with the deployment of said models.

## MLFlow MLModel

MLModels is MLFlows "self-contained model" that can automatically build a Docker Container and run through the built-in `mlflow serve` command. It's an interesting concept that's not "phenomenal" or "innovating" but helps streamlining our lives, just like the "bread and butter" MLFlow Experiments.  
That's also what I like about MLFlow, they don't try to take it too far - it's kept simple.

### Why?

Keeping it short:

1. A **"self-contained model"** with all the code files and dependencies in a simple package
2. **Natively Integrated in MLFlow** which is one of the biggest "MLOps" systems
3. All the MLFLow goodies enabled, such as `ModelRegistry`, `model-evaluation`, and `auto-Apache Spark UDF`.

### Flavours

MLModel automatically support multiple formats: _Keras_, _PyTorch_, _scikit-learn_, and many more ([full list](https://mlflow.org/docs/latest/models.html#built-in-model-flavors)).  
More interestingly they really support _ANY_ model through their `PytonModel` which is what I opt to use.

#### Why PythonModel

`PythonModel` allows you to get a streamlined format that supports custom models, including _Preprocessing_ and _Postprocessing_. Quite excellent!

To keep it simple you define a `PythonModel` as follows:

```python
class MyModel(mlflow.pyfunc.PythonModel):
    def predict(self, context, model_input: np.ndarray, params: dict | None):
        # model_input can also be pd.DataFrame, dict[str, np.ndarray], ...
        return model_input
```

There's additionally a `load_context` method which lets you write how to load your model and other things. It's run when "booting up".

To log:

```python
import mlflow

model_path = "my_model.py"

with mlflow.start_run():
    model_info = mlflow.pyfunc.log_model(
        python_model=MyModel(),
        artifact_path="my_model",
    )

my_model = mlflow.pyfunc.load_model(model_info.model_uri)
```

#### `infer_code_paths` bugged

If you find, like me, that `infer_code_paths` don't work well see my fix in this [blog-post](posts/2025-02-27-python-dependency-collector).

This problem seems to be very common if you use sub-classing or have custom dependencies that are called outside `load_context`, but my simple script helps you out!

# Outro

MLModels provide a simple way to deploy models in a self-contained way.

I hope you try out MLModels as they're a cool feature,  
Hampus Londögård