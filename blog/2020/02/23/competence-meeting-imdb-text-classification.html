<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.15">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Londogard Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Londogard Blog Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><title data-react-helmet="true">[2019-02-04] AFRY NLP Competence Meeting: Text Classification IMDB | Londogard Blog</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://blog.londogard.com/blog/2020/02/23/competence-meeting-imdb-text-classification"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_tag" content="default"><meta data-react-helmet="true" name="keywords" content="nlp, kotlin, jvm, deep-learning, machine-learning, blog"><meta data-react-helmet="true" property="og:title" content="[2019-02-04] AFRY NLP Competence Meeting: Text Classification IMDB | Londogard Blog"><meta data-react-helmet="true" name="description" content="This blog contains my first Competence Meeting where basic NLP concepts where taught and an classifier with good performance was implemented (on IMDB sentiment)."><meta data-react-helmet="true" property="og:description" content="This blog contains my first Competence Meeting where basic NLP concepts where taught and an classifier with good performance was implemented (on IMDB sentiment)."><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="article:published_time" content="2020-02-23T00:00:00.000Z"><meta data-react-helmet="true" property="article:author" content="https://github.com/lundez"><meta data-react-helmet="true" property="article:tag" content="machine-learning,nlp,workshop"><link data-react-helmet="true" rel="icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://blog.londogard.com/blog/2020/02/23/competence-meeting-imdb-text-classification"><link data-react-helmet="true" rel="alternate" href="https://blog.londogard.com/blog/2020/02/23/competence-meeting-imdb-text-classification" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://blog.londogard.com/blog/2020/02/23/competence-meeting-imdb-text-classification" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.2b920993.css">
<link rel="preload" href="/assets/js/runtime~main.e672e69a.js" as="script">
<link rel="preload" href="/assets/js/main.6539f25b.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="Londogard logo" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/favicon.ico" alt="Londogard logo" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title">Londogard Blog</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/blog/archive">Blog Archive</a><a class="navbar__item navbar__link" href="/presentations">Presentations</a></div><div class="navbar__items navbar__items--right"><a href="https://londogard.com/about" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>About<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><a href="https://londogard.com/projects" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>Londogard Projects<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><a href="https://github.com/londogard" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_Pssr toggle_TdHA toggleDisabled_jDku"><div class="toggleTrack_SSoT" role="button" tabindex="-1"><div class="toggleTrackCheck_XobZ"><span class="toggleIcon_eZtF">ðŸŒœ</span></div><div class="toggleTrackX_YkSC"><span class="toggleIcon_eZtF">ðŸŒž</span></div><div class="toggleTrackThumb_uRm4"></div></div><input type="checkbox" class="toggleScreenReader_JnkT" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-post-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_a9qW thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_uKok margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Kvuv"><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/probabilistic-forecasting">Probabilistic Forecasting Made Simple</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/timeseries-learnings">Timeseries Learnings at AFRY</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/2022/11/06/babymonitor-pt-1">Babymonitor #1</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/2022/09/07/docker-simplified-presentation">Docker (Presentation)</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/gpt2-snapsvisor">GPT2-snapsvisor - Generating Swedish Drinking Songs</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="blogPostTitle_rzP5" itemprop="headline">[2019-02-04] AFRY NLP Competence Meeting: Text Classification IMDB</h1><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2020-02-23T00:00:00.000Z" itemprop="datePublished">February 23, 2020</time> Â· <!-- -->18 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><a href="https://github.com/lundez" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_o0gy" src="https://github.com/lundez.png" alt="Hampus LondÃ¶gÃ¥rd"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/lundez" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Hampus LondÃ¶gÃ¥rd</span></a></div><small class="avatar__subtitle" itemprop="description">Main Contributor of Londogard</small></div></div></div></div></header><div id="post-content" class="markdown" itemprop="articleBody"><p>I&#x27;ve set a goal to create one blog post per Competence Meeting I&#x27;ve held at AFRY to spread the knowledge further. This goal will also grab all the older meetings, my hope is that I&#x27;ll be finished before summer 2020, but we&#x27;ll see.</p><hr><h3 class="anchor anchorWithStickyNavbar_mojV" id="introduction">Introduction<a class="hash-link" href="#introduction" title="Direct link to heading">â€‹</a></h3><p>Most of my Competence Meetings take place in the form of Jupyter Notebooks (<code>.ipynb</code>). Notebooks are awesome as they allow us to:</p><ol><li>Mix and match <em>markdown</em> &amp; <em>code</em>-blocks</li><li>Keep the state of the program, i.e. very explorative</li></ol><p>This is really good in combination with the workshop-format that we usually have.
Using services such as <a href="https://colab.research.google.com/" target="_blank" rel="noopener noreferrer">Google Colab</a> one can take the file and open it in the browser and run it there. This means that we don&#x27;t need any downloads and pretty often we also have a speed gain because the node used is faster than a laptop with its GPU. </p><p>Let&#x27;s get on to the competence evening.</p><hr><h2 class="anchor anchorWithStickyNavbar_mojV" id="text-classification">Text Classification<a class="hash-link" href="#text-classification" title="Direct link to heading">â€‹</a></h2><p>Today we&#x27;ll go through text classification, what it is, how it is used and how to make it yourself while trying to keep have a great mix of both theory and practical use. Text classification is just what the name suggest, a way to classify texts. Let it be spam or reviews, you train it and it&#x27;ll predict what class the text belongs to.</p><hr><h3 class="anchor anchorWithStickyNavbar_mojV" id="a-good-baseline">A good baseline<a class="hash-link" href="#a-good-baseline" title="Direct link to heading">â€‹</a></h3><p>To have a good baseline is incredibly important in Machine Learning. In summary you want the following</p><ul><li>Simple model to predict outcome</li><li>Use this model to compare your new, more complex model to</li></ul><p>This is to be able to know what progress you&#x27;re making. You don&#x27;t want to do anything more complex without any gains.</p><p>One pretty common simple baseline is just to pick a random class as prediction.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="classes--features">Classes &amp; Features<a class="hash-link" href="#classes--features" title="Direct link to heading">â€‹</a></h3><p>What is a class and feature?</p><p>Features are the input to the model, you can see a machine learning system as a \&quot;consumer\&quot; of features. You can view this as a cookie monster consuming cookies and then he says if they taste good or bad. He has the input, cookie, that can be a feature. He then has a output, class, that is good/bad. Repeat this a lot of times and you can retrieve statistics if Cookie Y is good or bad.</p><p>To generalize this system we would divide the feature into multiple feature, like what ingredients the cookie contains. So instead of saying this is a \&quot;Chocolate Chip Cookie\&quot; we know tell the system the features are:</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">chocolate</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> yes</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sugar</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">yes</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">honey</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">no</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">oat</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">no</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cinnamon</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> no</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sweet</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> yes</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sour</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> no\&quot;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>. In numerical input it would translate to something as <code>[1,1,0,0,0,1,0]</code>.</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="one-hot-encoding---how-we-represent-features--classes">One-Hot-Encoding - how we represent features &amp; classes<a class="hash-link" href="#one-hot-encoding---how-we-represent-features--classes" title="Direct link to heading">â€‹</a></h4><p>As shown in the translation to numerical vectors we don&#x27;t represent words as actual words. We always use numbers, often we even use something called <em>One-Hot-Encoding</em>.</p><p>One-Hot-Encoding means that we have an array of one 1 and the rest is 0s. This is to optimize math performed by the GPU (or CPU).</p><p>Using the example of <em>Good</em> &amp; <em>Bad</em> cookies with the extension of <em>Decent</em> we will One-Hot-Encode these as the following</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">Good   </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Bad    </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Decent </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">]</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>The same is applied to our features. If you&#x27;re using a framework (such as Keras) it is pretty common that they include an method to do this, or even that it is done automatically for you.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="back-to-text-classification">Back to text classification<a class="hash-link" href="#back-to-text-classification" title="Direct link to heading">â€‹</a></h3><p>To classify a text we do what is called an <em>sentiment analysis</em> meaning that we try to estimate the <em>sentiment polarity</em> of a text body. In the first part of this workshop we&#x27;ll be assuming that there&#x27;s only two sentiments, <em>Negative</em> and <em>Positive</em>. Then we can express this as the following classification problem:</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">Feature</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> String body</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Class</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">   Bad</span><span class="token operator" style="color:#393A34">|</span><span class="token plain">Good</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>The output, <em>Classes</em>, are easy to One-Hot-Encode but how do we succesfully One-Hot-Encode a string? A character can be seen as a class but is that really something we can learn from? To solve this we need to preprocess our input somehow.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="preprocessing">Preprocessing<a class="hash-link" href="#preprocessing" title="Direct link to heading">â€‹</a></h3><p>Preprocessing is an incredibly important part of Machine Learning. Combining preprocessing with <em>Data Mining</em> is actually around 70% of the workload (IBM) when developing models through the CRISP-DM. From my experience this is true.</p><p>Having good data and finding the most important features is incredibly important to have a competent system. In this task we need to preprocess the text to simplify the learning process for our system. We will do the following:</p><ul><li>Clean the text</li><li>Vectorize the texts into numerical vectors</li></ul><h4 class="anchor anchorWithStickyNavbar_mojV" id="cleaning-the-text">Cleaning the text<a class="hash-link" href="#cleaning-the-text" title="Direct link to heading">â€‹</a></h4><p>Why do we need to clean the text? It is to remove weird stuff &amp; outliers. If we have the text <code>I&#x27;m a cat.</code>we want to simplify this into <code>[i&#x27;m, a, cat]</code> or even <code>[im, a, cat]</code>.</p><p>Removing data such as non-alphabetical characters and the letter case makes more data look a like and reduces the dimension of our input -- this simplifies the learning of the system. But removing features can be bad also, if someone writes in all CAPS we can guess that they&#x27;re angry. But let&#x27;s take that later.</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> regex </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> re</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">clean_text</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">text</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    \&quot;\&quot;\&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Applies some pre</span><span class="token operator" style="color:#393A34">-</span><span class="token plain">processing on the given text</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Steps </span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token operator" style="color:#393A34">-</span><span class="token plain"> Removing punctuation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token operator" style="color:#393A34">-</span><span class="token plain"> Lowering text</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    \&quot;\&quot;\&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># remove the characters [\\], [&#x27;] and [\&quot;]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    text </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> re</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">sub</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">r\&quot;\\\\\&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> \&quot;\&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> text</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    text </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> re</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">sub</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">r\&quot;\\&#x27;\&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> \&quot;\&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> text</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Extra: Is regex needed? Other ways to accomplish this.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    text </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> re</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">sub</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">r\&quot;\\\&quot;\&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> \&quot;\&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> text</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># replace all non alphanumeric with space </span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    text </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> re</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">sub</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">r\&quot;\\W</span><span class="token operator" style="color:#393A34">+</span><span class="token plain">\&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> \&quot; \&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> text</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># text = re.sub(r\&quot;&lt;.+?&gt;\&quot;, \&quot; \&quot;, text) # &lt;br&gt;&lt;/br&gt;hej&lt;br&gt;&lt;/br&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Extra: How would we go ahead and remove HTML? Time to learn some Regex!</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> text</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">strip</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">lower</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">clean_text</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">\&quot;Wow</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> we can clean text now</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain"> Isn&#x27;t that amazing!?\&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">split</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="vectorization">Vectorization<a class="hash-link" href="#vectorization" title="Direct link to heading">â€‹</a></h4><p>Now that we can extract text we need to be able to input it to the system. We have to vectorize it. In this part we&#x27;ll vectorize each word as a number. The simplest approach to this is using <em>Bag of Words</em> (BOW).</p><p>Bag of Words creates a list of words which is called the <em>Dictionary</em>. The Dictionary is just a list of the words from the training data.</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">Training data</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;Ã…F </span><span class="token keyword" style="color:#00009f">is</span><span class="token plain"> a big company\&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> \&quot;Ã…F making future\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> Dictionary</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">Ã…F</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">is</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> a</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> big</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> company</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> making</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> future</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">New text</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> \&quot;Ã…F company </span><span class="token keyword" style="color:#00009f">is</span><span class="token plain"> a future company\&quot; </span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">]</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>Our new text is vectorized on top of the dictionary. You take the dictionary and replace the words position with the count of it that is found in the new text.</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="finalizing-the-preprocessing">Finalizing the preprocessing<a class="hash-link" href="#finalizing-the-preprocessing" title="Direct link to heading">â€‹</a></h4><p>We can actually do some more things to improve the system which I won&#x27;t go into detail about (read the code). We remove stop-words and so on.</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> sklearn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">feature_extraction</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">text </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> CountVectorizer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">training_texts </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    \&quot;Ã…F </span><span class="token keyword" style="color:#00009f">is</span><span class="token plain"> a big company\&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    \&quot;Ã…F making future\&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">test_texts </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    \&quot;Ã…F company </span><span class="token keyword" style="color:#00009f">is</span><span class="token plain"> a future company\&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># this is the vectorizer</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">vectorizer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> CountVectorizer</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    stop_words</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">\&quot;english\&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Removes english stop words (such as &#x27;a&#x27;, &#x27;is&#x27; and so on.)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    preprocessor</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">clean_text  </span><span class="token comment" style="color:#999988;font-style:italic"># Customized preprocessor</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># fit the vectorizer on the training text</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">vectorizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">fit</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">training_texts</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># get the vectorizer&#x27;s vocabulary</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">inv_vocab </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">v</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> k </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> k</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> v </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> vectorizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">vocabulary_</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">items</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">vocabulary </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">inv_vocab</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">i</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> i </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> </span><span class="token builtin">range</span><span class="token punctuation" style="color:#393A34">(</span><span class="token builtin">len</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">inv_vocab</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># vectorization example</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pd</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">DataFrame</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    data</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">vectorizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transform</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">test_texts</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">toarray</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    index</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;Test sentence\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    columns</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">vocabulary</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="lets-do-something-fun-out-of-this">Let&#x27;s do something fun out of this!<a class="hash-link" href="#lets-do-something-fun-out-of-this" title="Direct link to heading">â€‹</a></h3><p>To begin with we need data. Luckily I know a perfect dataset for this -- the IMDB movie reviews from stanford. This is a widely used dataset throughout <em>Sentiment Analysis</em>. The data contains 50 000 reviews where 50 % is positive and the rest negative. First we fetch a dataset. Download <a href="http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz" target="_blank" rel="noopener noreferrer">this file</a> and unpack it (into <code>aclImdb</code>) if the first code-snippet was unsuccessful.</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> numpy </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">load_train_test_imdb_data</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">data_dir</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    \&quot;\&quot;\&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Loads the IMDB train</span><span class="token operator" style="color:#393A34">/</span><span class="token plain">test datasets </span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> a folder path</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Input</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    data_dir</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> path to the \&quot;aclImdb\&quot; folder</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Returns</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    train</span><span class="token operator" style="color:#393A34">/</span><span class="token plain">test datasets </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> pandas dataframes</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    \&quot;\&quot;\&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    data </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> split </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;train\&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> \&quot;test\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">split</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> sentiment </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;neg\&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> \&quot;pos\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            score </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> sentiment </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> \&quot;pos\&quot; </span><span class="token keyword" style="color:#00009f">else</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            path </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> os</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">path</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">join</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">data_dir</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> split</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> sentiment</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            file_names </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> os</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">listdir</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">path</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> f_name </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> file_names</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                </span><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> </span><span class="token builtin">open</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">os</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">path</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">join</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">path</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> f_name</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> \&quot;r\&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> f</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    review </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> f</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">read</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">split</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">append</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">review</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> score</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># We shuffle the data to make sure we don&#x27;t train on sorted data. This results in some bad training.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">random</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">shuffle</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;train\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;train\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> pd</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">DataFrame</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;train\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                                 columns</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;text&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;sentiment&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">random</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">shuffle</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;test\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;test\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> pd</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">DataFrame</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;test\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                                columns</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;text&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;sentiment&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;train\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;test\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">train_data</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> test_data </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> load_train_test_imdb_data</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    data_dir</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">\&quot;aclImdb</span><span class="token operator" style="color:#393A34">/</span><span class="token plain">\&quot;</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="lets-create-our-classifier">Let&#x27;s create our classifier<a class="hash-link" href="#lets-create-our-classifier" title="Direct link to heading">â€‹</a></h3><p>We now have a dataset that we have successfully partitioned into a dictionary so that we can use it for our classifier.</p><p>Do you see an issue with our baseline right now?</p><p>...As mentioned we want to only have important features to simplify training. Right now we have an enormous amount of features, our BOW-approach result in an 80 000-dimensional vector. Because of this we <em>must</em> use simple algorithms that learn fast &amp; easy, e.g. <a href="https://en.wikipedia.org/wiki/Support-vector_machine" target="_blank" rel="noopener noreferrer">Linear SVM</a>, <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier" target="_blank" rel="noopener noreferrer">Naive Bayes</a> or <a href="https://en.wikipedia.org/wiki/Logistic_regression" target="_blank" rel="noopener noreferrer">Logistic Regression</a>.</p><p>Let&#x27;s create some code that actually let&#x27;s us train a Linear SVM!</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> sklearn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">metrics </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> accuracy_score</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> sklearn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">svm </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> LinearSVC</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Transform each text into a vector of word counts</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">vectorizer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> CountVectorizer</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">stop_words</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">\&quot;english\&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                             preprocessor</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">clean_text</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">training_features </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> vectorizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">fit_transform</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">train_data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;text\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">test_features </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> vectorizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transform</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">test_data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;text\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Training</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> LinearSVC</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">fit</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">training_features</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> train_data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;sentiment\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">y_pred </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">test_features</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Evaluation</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">acc </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> accuracy_score</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">test_data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;sentiment\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> y_pred</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">\&quot;Accuracy on the IMDB dataset</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token punctuation" style="color:#393A34">:</span><span class="token punctuation" style="color:#393A34">.</span><span class="token number" style="color:#36acaa">2f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">\&quot;</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">format</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">acc</span><span class="token operator" style="color:#393A34">*</span><span class="token number" style="color:#36acaa">100</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="comparison-to-state-of-the-art">Comparison to state-of-the-art<a class="hash-link" href="#comparison-to-state-of-the-art" title="Direct link to heading">â€‹</a></h3><p>Our accuracy is somewhere around 83.5-84 % which is really good! With this simple model and incredibly simplistic feature extraction we achieve a really high amount of correct answer! Comparing this to state-of-the-art we&#x27;re around 11 percent units beneat (~95% accuracy achieved <a href="https://arxiv.org/pdf/1801.06146.pdf" target="_blank" rel="noopener noreferrer">here</a>).</p><p>Incredible right? Exciting!? For me it is at least!</p><p>How do we improve from here?</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="improving-the-model">Improving the model<a class="hash-link" href="#improving-the-model" title="Direct link to heading">â€‹</a></h3><p>We have some huge improvements to make outside of fine-tuning, so we&#x27;ll skip the fine-tuning from now.</p><p>The first step is to improve our vectorization.</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="tf-idf">TF-IDF<a class="hash-link" href="#tf-idf" title="Direct link to heading">â€‹</a></h4><p>If you were at <em>first friday (@Ã…F)</em> you have heard about TF-IDF earlier. TF-IDF stands for <em>Term Frequence-Inverse Document Frequency</em> and is a measurement that aims to fight imbalances in texts.</p><p>In our vectorization step we look at the word-count meaning that we&#x27;ll have some biases to how much a word is present, the longer the text the more the bias. To reduce this we can take the word-count divided by the total amount of words in the text (TF). We also want to downscale the words that are incredibly frequent such as stop words and topic-related words, and upscale unusual words somewhat, e.g.<em>glamorous</em> might not be frequent but it is important to the text most likely. We use <em>IDF</em> for this. We then take these two and combine.</p><p><img src="https://cdn-images-1.medium.com/max/800/1*FgQgJYozG7colT9rys066w.png" alt="alt text"></p><h3 class="anchor anchorWithStickyNavbar_mojV" id="implementation-details">Implementation details<a class="hash-link" href="#implementation-details" title="Direct link to heading">â€‹</a></h3><p>This is actually really easy to do as <em>sklearn</em> already has a finished <code>TfIdfVectorizer</code> so all we have to do is to replace the <code>CountVectorizer</code>. Let&#x27;s see how it goes!</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> sklearn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">svm </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> LinearSVC</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> sklearn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">metrics </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> accuracy_score</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> sklearn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">feature_extraction</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">text </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> TfidfVectorizer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Transform each text into a vector of word counts</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">vectorizer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> TfidfVectorizer</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">stop_words</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">\&quot;english\&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                             preprocessor</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">clean_text</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">training_features </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> vectorizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">fit_transform</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">train_data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;text\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">test_features </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> vectorizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transform</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">test_data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;text\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Training</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> LinearSVC</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">fit</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">training_features</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> train_data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;sentiment\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">y_pred </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">test_features</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Evaluation</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">acc </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> accuracy_score</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">test_data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;sentiment\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> y_pred</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">\&quot;Accuracy on the IMDB dataset</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token punctuation" style="color:#393A34">:</span><span class="token punctuation" style="color:#393A34">.</span><span class="token number" style="color:#36acaa">2f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">\&quot;</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">format</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">acc</span><span class="token operator" style="color:#393A34">*</span><span class="token number" style="color:#36acaa">100</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Extra: Implement our own TfIdfVectorizer.</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="conclusion-of-tf-idf">Conclusion of TF-IDF<a class="hash-link" href="#conclusion-of-tf-idf" title="Direct link to heading">â€‹</a></h3><p>The <code>TfIdVectorizer</code> improved our scoring with 2 percent units, that&#x27;s incredible for such an easy improvement!</p><p>This for me shows how important it is to understand the data and what is important. You really need to grasp how to extract the important and what tools are available.</p><p>But let&#x27;s not stop here, lets reiterate and improve further.</p><p>What is the next natural step? Context I believe. During my master-thesis on spell correction of Street Names it was very obvious how important context is to increase the models understanding. Unfortunately we couldn&#x27;t use the context of a sentence in the thesis (as of the nature of street names) but here we can!</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="use-of-context">Use of context<a class="hash-link" href="#use-of-context" title="Direct link to heading">â€‹</a></h3><p>Words by themself prove some meaning but sometimes they&#x27;re used in a negated sense, e.g. <em>not good</em>. <em>Good</em> in itself would most likely be positive but if we can get the context around the word we can be more sure about in what manner it is applied.</p><p>We call this <em>N-grams</em> where N is equal to the amount of words taken into consideration for each word. Using bigrams (N=2) we get the following:</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">companies often use corporate bs </span><span class="token operator" style="color:#393A34">=</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">companies</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> often</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> use</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> slogans</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">companies</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> often</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">often</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">use</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">use</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">slogans</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">]</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>Sometimes you include a start &amp; ending word so that it would be <code>(\\t, companies)</code> and <code>(slogans, \\r)</code> or such. In this case as we are not finetuning we won&#x27;t go into that. We&#x27;ll keep it simple.</p><p>The all-mighty sklearn <code>TfIdfVectorizer</code> actually already have included N-gram support using the parameter <code>ngram_range=(1, N)</code>. So let&#x27;s make it simple for us and make use of that!</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> sklearn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">svm </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> LinearSVC</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> sklearn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">metrics </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> accuracy_score</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> sklearn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">feature_extraction</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">text </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> TfidfVectorizer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Transform each text into a vector of word counts</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">vectorizer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> TfidfVectorizer</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">ngram_range</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                            strip_accents</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;ascii&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                            max_df</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.98</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">training_features </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> vectorizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">fit_transform</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">train_data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;text\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">test_features </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> vectorizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transform</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">test_data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;text\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Training</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> LinearSVC</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">fit</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">training_features</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> train_data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;sentiment\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">y_pred </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">test_features</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Evaluation</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">acc </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> accuracy_score</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">test_data</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">\&quot;sentiment\&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> y_pred</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">\&quot;Accuracy on the IMDB dataset</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token punctuation" style="color:#393A34">:</span><span class="token punctuation" style="color:#393A34">.</span><span class="token number" style="color:#36acaa">2f</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain">\&quot;</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">format</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">acc</span><span class="token operator" style="color:#393A34">*</span><span class="token number" style="color:#36acaa">100</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="conclusion-of-n-gram">Conclusion of N-gram<a class="hash-link" href="#conclusion-of-n-gram" title="Direct link to heading">â€‹</a></h3><p>Once again we see a massive improvement. We&#x27;re almost touching 89 % now! That&#x27;s just a mere 6 percent units below state-of-the-art. What can we do to improve now?</p><p>Some possible improvements for you to try!</p><ul><li>Use a custom threshold to reduce the dimensions</li><li>Play around with the <code>ngram_range</code> (don&#x27;t forget a threshold if you do this)</li><li>Improve the preprocessing</li></ul><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Try some fun things here if you want too :)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="conclusion-of-phase-1">Conclusion of phase 1<a class="hash-link" href="#conclusion-of-phase-1" title="Direct link to heading">â€‹</a></h2><p>We have created a strong baseline for text classification with great accuracy for its simplicity. The following steps has been done</p><ul><li>First a simple preprocessing step which is of great importance. We have to remember to not make it to complex, the complexity of preprocessing is like an evil circle in the end. In our case we remove punctuations, stopwords and lower the case.</li><li>Secondly we vectorize the data to make it readable by the system. A classifier requires numerical features. For this we had a <code>TfIdfVectorizer</code> that computes frequency of words while downsampling words that are to common &amp; upsampling unusual words.</li><li>Finally we added N-gram to the model to increase the understanding of the sentence by supplying context.</li></ul><h2 class="anchor anchorWithStickyNavbar_mojV" id="phase-2">Phase 2<a class="hash-link" href="#phase-2" title="Direct link to heading">â€‹</a></h2><p>How do we improve from here? TF-IDF has its cons and pros. Some of the cons are that they:</p><ul><li>Don&#x27;t account for any kind of positioning at all</li><li>The dimensions are ridiculous large</li><li>They can&#x27;t capture semantics.</li></ul><p>Improvements upon this is made by using neural networks and word embeddings.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="word-embeddings">Word Embeddings<a class="hash-link" href="#word-embeddings" title="Direct link to heading">â€‹</a></h2><p>Word Embeddings &amp; Neural Networks are where we left off. By change our model to instead utilize these two concepts we can improve the accuracy once again.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="word-embeddings-1">Word Embeddings<a class="hash-link" href="#word-embeddings-1" title="Direct link to heading">â€‹</a></h3><p>Word Embeddings (WE) are actually a type of Neural Network. It uses <em>embedding</em> to create the model. I quickly explained WE during my presentation on Summarization and how to build a great summarizer. Today we&#x27;ll go a little more into depth.</p><p>To begin with I&#x27;ll take the most common example, WE lets us do the following arithmetiric with words:</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">King </span><span class="token operator" style="color:#393A34">-</span><span class="token plain"> Man </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> Woman </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> Queen</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>This is, in my opinion, completely amazing and fascinating. How does this work? Where do I learn more? Those are my first thoughts. In fact the theory is pretty basic until you get to the nittygritty details, as with most things.</p><p>WE is built on the concept ot learn how words are related to eachother. What company do a word have? To make the example more complex we can redefine this too the following: <code>A is to B what C is to D</code>.</p><p>Currently there is three \&quot;big\&quot; models that are widely used. The first one Word2Vec (<a href="https://arxiv.org/abs/1301.3781" target="_blank" rel="noopener noreferrer">Mikolov et al 2013</a>), the second is GloVe (MIT <a href="https://nlp.stanford.edu/projects/glove/" target="_blank" rel="noopener noreferrer">MIT</a>, <a href="https://nlp.stanford.edu/pubs/glove.pdf" target="_blank" rel="noopener noreferrer">Pennington et al 2014</a>) and the final one is fastText (<a href="https://github.com/facebookresearch/fastText" target="_blank" rel="noopener noreferrer">facebook</a>).</p><p>We will look into how you can achieve this without Deep Learning / Neural Networks unlike the models mentioned.</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="step-1-how-to-represent-words-in-a-numerical-vector">Step 1: How to represent words in a numerical vector<a class="hash-link" href="#step-1-how-to-represent-words-in-a-numerical-vector" title="Direct link to heading">â€‹</a></h4><p>The first thing we have to do to actually understand/achieve word embeddings is to represent words in a numerical vector. In relation to this a quick explanation of sparse &amp; dense representations would be great. Read more in detail at <a href="https://en.wikipedia.org/wiki/Sparse_matrix" target="_blank" rel="noopener noreferrer">Wikipedia: Sparse Matrix</a></p><p><strong>Sparse representation</strong> is when we represent something very sparsely. It tells us that the points in the space is very few in regards to the dimensions and that most elements are empty. Think one-hot-encoding.</p><p>A <strong>Dense representation</strong> in comparison has few dimensions in comparison to possible values and most elements are filled. Think of something continuous.</p><p>The most simple way to represent words in a numerical vector is something we touched earlier, by one-hot-encoding them, i.e. a sparse representation.</p><p><img src="https://cdn-images-1.medium.com/max/1200/1*YEJf9BQQh0ma1ECs6x_7yQ.png" alt="Source :(Marco Bonzanini, 2017)">(Source: Marco Bonzanini, 2017)</p><p>Because of how languages are structured having one-hot-encoding means that we will have an incredibly sparse matrix (can be good) but it will have an enormous amount of dimensions (bad).</p><p>On top of this how would we go ahead and measure the distance between words? Normally one would use the <a href="https://en.wikipedia.org/wiki/Cosine_similarity" target="_blank" rel="noopener noreferrer">cosine similarity</a> but if we have a one-hot-encoding all the words would be orthogonal against eachother meaning that the dot-product will be zero.</p><p>Creating a dense representation however would indeed capture similarity as we could make use of cosine-similarity and more. Introducing Word2Vec.</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="step-2-word2vec-representing-data-densely">Step 2: Word2Vec, representing data densely<a class="hash-link" href="#step-2-word2vec-representing-data-densely" title="Direct link to heading">â€‹</a></h4><p>The goal of Word2Vec, at least to my understanding, is to actually predict the context of a word. Or in other words we learn embeddings by prediciting the context of the word. The <em>context</em> here being the same definition as in N-grams. Word2Vec uses <em>shallow neural network</em> to learn word vectors so that each word is good at predicting its own contexts (more about his in <strong>Skip-Grams</strong>) and how to predict a word given a context (more about this in <strong>CBOW</strong>).</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="skip-gram">Skip-gram<a class="hash-link" href="#skip-gram" title="Direct link to heading">â€‹</a></h4><p>Skip-gram very simplified is when you train on the N-grams but without the real word. <img src="https://cdn-images-1.medium.com/max/800/1*swlaqv7p_3xI4eL37C1pAA.png" alt="alt text"></p><p>As of now we have empirical results showing how this technique is very successful at learning the meaning of the words. On top of this the embedding that we get has both <em>direction of semantic and syntatic meaning</em> that are exposed in example such as <code>King - Man...</code>.</p><p>Another example would be: <code>Vector(Madrid) - Vector(Spain) + Vector(Sweden) ~ Vector(Stockholm)</code></p><h4 class="anchor anchorWithStickyNavbar_mojV" id="so-how-do-the-arithmetic-of-words-actually-work">So how do the arithmetic of words actually work?<a class="hash-link" href="#so-how-do-the-arithmetic-of-words-actually-work" title="Direct link to heading">â€‹</a></h4><p>I won&#x27;t go into details (some complicated math, see <a href="http://www.aclweb.org/anthology/P17-1007" target="_blank" rel="noopener noreferrer">Gittens et al</a>) but if we assume the following to be true:</p><ul><li>All words are distributed uniformly</li><li>The embedding model is linear</li><li>The conditional distributions of words are indepedent</li></ul><p>Then we can prove that the embedding of the paraphrase of a set of words is obtained by taking the sum over the embeddings of all of the individual words.</p><p>Using this result it&#x27;s easy to show how the famous man-woman, king-queen relationship works.</p><p>Extra note: You can show this then by havingn <code>King</code> and <code>Queen</code> having the same <code>Male-Female</code>relationship as the <code>King</code> then is the paraphrase of the set of words <code>{Queen, X}</code></p><p>I want to note that these assumptions are not 100 percent accurate. In reality word distributions are thought to follow Zipf&#x27;s law.</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="glove">GloVe<a class="hash-link" href="#glove" title="Direct link to heading">â€‹</a></h4><p>A year after Word2Vec was a fact to the world the scientist decided to reiterate again. This time we got GloVe. GloVe tried to improve upon Word2Vec by that given a word its relationship(s) can be recovered from co-occurence statistics of a large corpus. GloVe is expensive and memory hungry, but it&#x27;s only one load so the issue isn&#x27;t that big. Nitty bitty details</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="fasttext">fastText<a class="hash-link" href="#fasttext" title="Direct link to heading">â€‹</a></h4><p>With fastText one of the biggest problems is solved, both GloVe and Word2Vec only learn embeddings of word of the vocabulary. Because of this we can&#x27;t find an embedding for a word that isn&#x27;t in the dictionary.</p><p>Bojanowski et al solved this by learning the word embeddings using subword information. To summarize fastText learns embeddings of character n-grams instead.</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="the-simple-way">The simple way<a class="hash-link" href="#the-simple-way" title="Direct link to heading">â€‹</a></h4><p>A simple approach to create your own word embeddings without a neural network is by factorizing a co-occurence matrix using SVD (singular-value-decomposition). As mentioned Word2Vec is barely a neural network as it has no hidden layers nor an y non-linearities. GloVe factorizes a co-occurense matrix while gaining even better results.</p><p>I highly recommend you to go check this blog out: <a href="https://multithreaded.stitchfix.com/blog/2017/10/18/stop-using-word2vec/" target="_blank" rel="noopener noreferrer">https://multithreaded.stitchfix.com/blog/2017/10/18/stop-using-word2vec/</a> by Stitch Fix. An awesome read and we can go implement this too!</p></div><footer class="row docusaurus-mt-lg blogPostDetailsFull_h6_j"><div class="col"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/machine-learning">machine-learning</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/nlp">nlp</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/workshop">workshop</a></li></ul></div><div class="col margin-top--sm"><a href="https://github.com/londogard/londogard/blog/2020-02-23-competence-meeting-imdb-text-classification.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_dcUD" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/blog/2020/03/31/email-generator-kotlin-tipsrundan"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">How I created a email generator in Kotlin (for Afry Tipsrundan)</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/blog/2020/02/10/gradle-github-packages"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Gradle, JVM and GitHub Packages</div></a></div></nav></main><div class="col col--2"><div class="tableOfContents_cNA8 thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#text-classification" class="table-of-contents__link toc-highlight">Text Classification</a><ul><li><a href="#a-good-baseline" class="table-of-contents__link toc-highlight">A good baseline</a></li><li><a href="#classes--features" class="table-of-contents__link toc-highlight">Classes &amp; Features</a></li><li><a href="#back-to-text-classification" class="table-of-contents__link toc-highlight">Back to text classification</a></li><li><a href="#preprocessing" class="table-of-contents__link toc-highlight">Preprocessing</a></li><li><a href="#lets-do-something-fun-out-of-this" class="table-of-contents__link toc-highlight">Let&#39;s do something fun out of this!</a></li><li><a href="#lets-create-our-classifier" class="table-of-contents__link toc-highlight">Let&#39;s create our classifier</a></li><li><a href="#comparison-to-state-of-the-art" class="table-of-contents__link toc-highlight">Comparison to state-of-the-art</a></li><li><a href="#improving-the-model" class="table-of-contents__link toc-highlight">Improving the model</a></li><li><a href="#implementation-details" class="table-of-contents__link toc-highlight">Implementation details</a></li><li><a href="#conclusion-of-tf-idf" class="table-of-contents__link toc-highlight">Conclusion of TF-IDF</a></li><li><a href="#use-of-context" class="table-of-contents__link toc-highlight">Use of context</a></li><li><a href="#conclusion-of-n-gram" class="table-of-contents__link toc-highlight">Conclusion of N-gram</a></li></ul></li><li><a href="#conclusion-of-phase-1" class="table-of-contents__link toc-highlight">Conclusion of phase 1</a></li><li><a href="#phase-2" class="table-of-contents__link toc-highlight">Phase 2</a></li><li><a href="#word-embeddings" class="table-of-contents__link toc-highlight">Word Embeddings</a><ul><li><a href="#word-embeddings-1" class="table-of-contents__link toc-highlight">Word Embeddings</a></li></ul></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Support Londogard</div><ul class="footer__items"><li class="footer__item"><a href="https://www.buymeacoffee.com/hlondogard" target="_blank"><img src="https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png" alt="Buy Me A Coffee" style="height: 60px !important;width: 217px !important;"></a></li><li class="footer__item"><div style="display: flex; align-items: center;"><iframe src="https://github.com/sponsors/Lundez/button" title="Sponsor Lundez" height="35" width="116" style="border: 0;"></iframe><div>&nbsp;on GitHub</div></div></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/londogard" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">Feeds</div><ul class="footer__items"><li class="footer__item"><a href="https://blog.londogard.com/blog/rss.xml" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>RSS<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://blog.johnnyreilly.com/blog/atom.xml" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Atom<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2022 Londogard. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.e672e69a.js"></script>
<script src="/assets/js/main.6539f25b.js"></script>
</body>
</html>