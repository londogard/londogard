<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.15">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Londogard Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Londogard Blog Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><title data-react-helmet="true">Release nlp (londogard-nlp-toolkit) 1.1.0 | Londogard Blog</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://blog.londogard.com/blog/2022/01/16/nlp-toolkit-release"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_tag" content="default"><meta data-react-helmet="true" name="keywords" content="nlp, kotlin, jvm, deep-learning, machine-learning, blog"><meta data-react-helmet="true" property="og:title" content="Release nlp (londogard-nlp-toolkit) 1.1.0 | Londogard Blog"><meta data-react-helmet="true" name="description" content="nlp (londogard-nlp-toolkit) has had it&#x27;s 1.1.0 release recently with a lot of new functionality and multiple improvements to efficiency, dive in to understand more!"><meta data-react-helmet="true" property="og:description" content="nlp (londogard-nlp-toolkit) has had it&#x27;s 1.1.0 release recently with a lot of new functionality and multiple improvements to efficiency, dive in to understand more!"><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="article:published_time" content="2022-01-16T00:00:00.000Z"><meta data-react-helmet="true" property="article:author" content="https://github.com/lundez"><meta data-react-helmet="true" property="article:tag" content="nlp,jvm,kotlin"><link data-react-helmet="true" rel="icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://blog.londogard.com/blog/2022/01/16/nlp-toolkit-release"><link data-react-helmet="true" rel="alternate" href="https://blog.londogard.com/blog/2022/01/16/nlp-toolkit-release" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://blog.londogard.com/blog/2022/01/16/nlp-toolkit-release" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.2b27dec1.css">
<link rel="preload" href="/assets/js/runtime~main.09bd1e8c.js" as="script">
<link rel="preload" href="/assets/js/main.95872d60.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="Londogard logo" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/favicon.ico" alt="Londogard logo" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title">Londogard Blog</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/blog/archive">Blog Archive</a><a class="navbar__item navbar__link" href="/presentations">Presentations</a></div><div class="navbar__items navbar__items--right"><a href="https://londogard.com/about" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>About<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><a href="https://londogard.com/projects" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>Londogard Projects<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><a href="https://github.com/londogard" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_Pssr toggle_TdHA toggleDisabled_jDku"><div class="toggleTrack_SSoT" role="button" tabindex="-1"><div class="toggleTrackCheck_XobZ"><span class="toggleIcon_eZtF">🌜</span></div><div class="toggleTrackX_YkSC"><span class="toggleIcon_eZtF">🌞</span></div><div class="toggleTrackThumb_uRm4"></div></div><input type="checkbox" class="toggleScreenReader_JnkT" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-post-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_a9qW thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_uKok margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Kvuv"><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/gpt2-snapsvisor">GPT2-snapsvisor - Generating Swedish Drinking Songs</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/timeseries-pt-3">Forecasting Crypto Prices using Deep Learning (Time Series #3)</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/timeseries-pt-2">Predicting Stock Prices using classical machine Learning (Time Series #2)</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/timeseries-pt-1">Decomposing &amp; Working with Time Series (Time Series #1)</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/kotlinjs-onnx-deep-learning-browser">KotlinJS, ONNX and Deep Learning in the browser</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="blogPostTitle_rzP5" itemprop="headline">Release nlp (londogard-nlp-toolkit) 1.1.0</h1><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2022-01-16T00:00:00.000Z" itemprop="datePublished">January 16, 2022</time> · <!-- -->4 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><a href="https://github.com/lundez" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_o0gy" src="https://github.com/lundez.png" alt="Hampus Londögård"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/lundez" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Hampus Londögård</span></a></div><small class="avatar__subtitle" itemprop="description">Main Contributor of Londogard</small></div></div></div></div></header><div id="post-content" class="markdown" itemprop="articleBody"><p>The 1.1.0 release of nlp (<a href="https://github.com/londogard/londogard-nlp-toolkit" target="_blank" rel="noopener noreferrer">londogard-nlp-toolkit</a>) by londogard is <strong>finally</strong> here!</p><p>I’m writing this small blog-post mainly to showcase some of the new things possible now that we’re moving into classifer-space!<br>
<!-- -->This release took some time to complete because there was some big restructuring and custom implementations required. One thing that I wasn&#x27;t expecting was to implement my own Sparse Matrix on top of <code>multik</code> because there&#x27;s currently no support. Without sparsity text features will make your memory dissapear before you take your second breath! 😅<br>
<!-- -->Luckily I managed to get something up and running. The code is now cleaner and more efficient than previously on top of all the new features.</p><p><strong>N.B.</strong><br>
<!-- -->Most of the examples are taken from <code>/src/test</code>.</p><h1>Vectorizers</h1><p>The first part I&#x27;d like to present is the tooling that required sparse matrices, <em>vectorizers</em>. TF-IDF, Bag of Words &amp; BM-25 requires huge matrices that are very sparse, having it all in memory would be crazy as &gt; 90% is empty (=0.0).<br>
<!-- -->Let&#x27;s look at the vectorizers that now exists:</p><ol><li><p><strong>Bag of Words</strong>, also called Count Vectorizer in <code>sklearn</code>.</p><ul><li>This vectorizer takes words and assign a unique number to each, which is then filled in the final vector</li></ul></li><li><p><strong>TF-IDF</strong></p><ul><li>This vectorizer assigns values to word based on their <em>term frequency &amp; inverse-document frequency.</em> Which is a <strong>incredible strong baseline.</strong> (<a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" target="_blank" rel="noopener noreferrer">Wikipedia.org</a>)</li></ul></li><li><p><strong>BM-25</strong></p><ul><li>This vectorizer is a improvement on top of TF-IDF used by Elastic Search among others. The difference is that BM-25 also base the magnitude on the sentences length, in TF-IDF sometimes long sentences tend to get very high magnitude. (<a href="https://en.wikipedia.org/wiki/Okapi_BM25" target="_blank" rel="noopener noreferrer">Wikipedia</a>)</li></ul></li></ol><p>And yes, it’s possible to vectorize <strong>with ngrams</strong>! 🥳<br>
<!-- -->And yes (x2), it’s using <strong>Sparse Matrices</strong> to keep performance at top! 🤩</p><p>All in all this puts us very close to the famous <strong>sklearn</strong> in terms of versatility.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="usage-of-vectorizers">Usage of Vectorizers<a class="hash-link" href="#usage-of-vectorizers" title="Direct link to heading">​</a></h3><div class="codeBlockContainer_I0IT language-kotlin theme-code-block"><div class="codeBlockContent_wNvx kotlin"><pre tabindex="0" class="prism-code language-kotlin codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">val simpleTok = SimpleTokenizer()  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val simpleTexts = listOf(&quot;hello world!&quot;, &quot;this is a few sentences&quot;)  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .map(simpleTok::split)  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val tfidf = TfIdfVectorizer&lt;Float&gt;() // replace by CountVectorizer or Bm25Vectorizer  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val lhs = tfidf.fitTransform(simpleTexts)  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">println(&quot;Vectorized: $lhs&quot;)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="classifiers">Classifiers<a class="hash-link" href="#classifiers" title="Direct link to heading">​</a></h2><p>And the first feature built on top of the new vectors... <strong>classifiers</strong>!<br>
<!-- -->To be able to figure out if a tweet is negative or positive we need to classify the text, based on the vectorized data.<br>
<!-- -->The following classifiers are added for now:</p><ul><li>Logistic Regression using Stochastic Gradient Descent as optimizer</li><li>Naïve Bayes classifier</li><li>Hidden Markov Model to classify sequences with a sequence output, e.g. <em>Part of Speech</em> (PoS) or <em>Named Entitiy Recognition</em> (NER).</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="usage-of-classifiers">Usage of Classifiers<a class="hash-link" href="#usage-of-classifiers" title="Direct link to heading">​</a></h3><div class="codeBlockContainer_I0IT language-kotlin theme-code-block"><div class="codeBlockContent_wNvx kotlin"><pre tabindex="0" class="prism-code language-kotlin codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">val tfidf = TfIdfVectorizer&lt;Float&gt;()  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val naiveBayes = NaiveBayes() // replace by LogisticRegression if needed  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val out = tfidf.fitTransform(simpleTexts)  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">naiveBayes.fit(out, y)  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">naiveBayes.predict(out) shouldBeEqualTo y</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>and for sequences:</p><div class="codeBlockContainer_I0IT language-kotlin theme-code-block"><div class="codeBlockContent_wNvx kotlin"><pre tabindex="0" class="prism-code language-kotlin codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">val (tokensText, tagsText) = text  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .split(&#x27;\\n&#x27;)  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .map {  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        val (a, b) = it.split(&#x27;\\t&#x27;)  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        a to b  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }.unzip()  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val tokenMap = (tokensText).toSet().withIndex().associate { elem -&gt; elem.value to elem.index }  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val tagMap = (tagsText + &quot;BOS&quot;).toSet().withIndex().associate { elem -&gt; elem.value to elem.index }  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val reversetagMap = tagMap.asIterable().associate { (key, value) -&gt; value to key }  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val hmm = HiddenMarkovModel(  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tagMap.asIterable().associate { (key, value) -&gt; value to key },  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tokenMap.asIterable().associate { (key, value) -&gt; value to key },  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    BegginingOfSentence = tokenMap.getOrDefault(&quot;BOS&quot;, 0)  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    )  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val x = listOf(mk.ndarray(tokensText.mapNotNull(tokenMap::get).toIntArray()))  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">val y = listOf(mk.ndarray(tagsText.mapNotNull(tagMap::get).toIntArray()))  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">hmm.fit(x, y)  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">// predict.map { t -&gt; t.data.map { reversetagMap\[it\] } } to get the real labels!  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">hmm.predict(x) shouldBeEqualTo y</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="unsupervised-keyword-extraction">Unsupervised Keyword Extraction<a class="hash-link" href="#unsupervised-keyword-extraction" title="Direct link to heading">​</a></h2><p>I couldn&#x27;t keep my release small enough... so I added a little gem, <strong>automatic keyword extraction</strong>! This tool is very fast and efficient at doing what it’s doing and is based on a Co-Occurrence Statistical Information algorithm proposed by Y. Matsuo &amp; M. Ishizuka in the following <a href="https://www.researchgate.net/publication/2572200_Keyword_Extraction_from_a_Single_Document_using_Word_Co-occurrence_Statistical_Information" target="_blank" rel="noopener noreferrer">paper</a>.<br>
<!-- -->I think this is incredibly useful when you need something fast, cheap and that takes you 90% of the way!</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="usage-of-keyword-extraction">Usage of Keyword Extraction<a class="hash-link" href="#usage-of-keyword-extraction" title="Direct link to heading">​</a></h3><div class="codeBlockContainer_I0IT language-kotlin theme-code-block"><div class="codeBlockContent_wNvx kotlin"><pre tabindex="0" class="prism-code language-kotlin codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">val keywords = CooccurrenceKeywords.keywords(&quot;Londogard NLP toolkit is works on multiple languages.\\nAn amazing piece of NLP tech.\\nThis is how to fetch keywords! &quot;)  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">keywords shouldBeEqualTo listOf(listOf(&quot;nlp&quot;) to 2)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="embedding-improvements">Embedding Improvements<a class="hash-link" href="#embedding-improvements" title="Direct link to heading">​</a></h2><p><code>LightWordEmbeddings</code>  have had their cache updated into a optimal cache by <code>caffeine</code> , which instead of being randomly deleted from cache takes the least used and remove. This will improve performance greatly!</p><hr><p>That’s it, I’m hoping to release a spaCy-like API during 2022, including Neural Networks. Here’s to the future! 🍾</p></div><footer class="row docusaurus-mt-lg blogPostDetailsFull_h6_j"><div class="col"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/nlp">nlp</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/jvm">jvm</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/kotlin">kotlin</a></li></ul></div><div class="col margin-top--sm"><a href="https://github.com/londogard/londogard/blog/2022-01-16-nlp-toolkit-release.mdx" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_dcUD" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/blog/kotlinjs-onnx-deep-learning-browser"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">KotlinJS, ONNX and Deep Learning in the browser</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/blog/2021/05/17/seam-carving"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Seam Carving (Presentation &amp; Workshop)</div></a></div></nav></main><div class="col col--2"><div class="tableOfContents_cNA8 thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#usage-of-vectorizers" class="table-of-contents__link toc-highlight">Usage of Vectorizers</a></li><li><a href="#classifiers" class="table-of-contents__link toc-highlight">Classifiers</a><ul><li><a href="#usage-of-classifiers" class="table-of-contents__link toc-highlight">Usage of Classifiers</a></li></ul></li><li><a href="#unsupervised-keyword-extraction" class="table-of-contents__link toc-highlight">Unsupervised Keyword Extraction</a><ul><li><a href="#usage-of-keyword-extraction" class="table-of-contents__link toc-highlight">Usage of Keyword Extraction</a></li></ul></li><li><a href="#embedding-improvements" class="table-of-contents__link toc-highlight">Embedding Improvements</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Support Londogard</div><ul class="footer__items"><li class="footer__item"><a href="https://www.buymeacoffee.com/hlondogard" target="_blank"><img src="https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png" alt="Buy Me A Coffee" style="height: 60px !important;width: 217px !important;"></a></li><li class="footer__item"><div style="display: flex; align-items: center;"><iframe src="https://github.com/sponsors/Lundez/button" title="Sponsor Lundez" height="35" width="116" style="border: 0;"></iframe><div>&nbsp;on GitHub</div></div></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/londogard" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">Feeds</div><ul class="footer__items"><li class="footer__item"><a href="https://blog.londogard.com/blog/rss.xml" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>RSS<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://blog.johnnyreilly.com/blog/atom.xml" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Atom<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2022 Londogard. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.09bd1e8c.js"></script>
<script src="/assets/js/main.95872d60.js"></script>
</body>
</html>