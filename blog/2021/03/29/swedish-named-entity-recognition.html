<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.15">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Londogard Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Londogard Blog Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><title data-react-helmet="true">Building a Swedish Named Entity Recognition (NER) model (Flair/Huggingface) | Londogard Blog</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://blog.londogard.com/blog/2021/03/29/swedish-named-entity-recognition"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_tag" content="default"><meta data-react-helmet="true" property="og:title" content="Building a Swedish Named Entity Recognition (NER) model (Flair/Huggingface) | Londogard Blog"><meta data-react-helmet="true" name="description" content="Learn how to fine-tune a Flair NER model and quantize a BERT model from Huggingface to achieve SotA performance &amp; a much more efficient model."><meta data-react-helmet="true" property="og:description" content="Learn how to fine-tune a Flair NER model and quantize a BERT model from Huggingface to achieve SotA performance &amp; a much more efficient model."><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="article:published_time" content="2021-03-29T00:00:00.000Z"><meta data-react-helmet="true" property="article:author" content="https://github.com/lundez"><meta data-react-helmet="true" property="article:tag" content="nlp,machine-learning,workshop"><link data-react-helmet="true" rel="icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://blog.londogard.com/blog/2021/03/29/swedish-named-entity-recognition"><link data-react-helmet="true" rel="alternate" href="https://blog.londogard.com/blog/2021/03/29/swedish-named-entity-recognition" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://blog.londogard.com/blog/2021/03/29/swedish-named-entity-recognition" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.feb03a1a.css">
<link rel="preload" href="/assets/js/runtime~main.1532c46a.js" as="script">
<link rel="preload" href="/assets/js/main.2212e7b3.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="Londogard logo" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/favicon.ico" alt="Londogard logo" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title">Londogard Blog</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/blog/tags">Tags</a><a class="navbar__item navbar__link" href="/blog/archive">Archive</a></div><div class="navbar__items navbar__items--right"><a href="https://londogard.com/projects" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>Londogard Projects<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><a href="https://github.com/londogard" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_Pssr toggle_TdHA toggleDisabled_jDku"><div class="toggleTrack_SSoT" role="button" tabindex="-1"><div class="toggleTrackCheck_XobZ"><span class="toggleIcon_eZtF">üåú</span></div><div class="toggleTrackX_YkSC"><span class="toggleIcon_eZtF">üåû</span></div><div class="toggleTrackThumb_uRm4"></div></div><input type="checkbox" class="toggleScreenReader_JnkT" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-post-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_a9qW thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_uKok margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Kvuv"><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/kotlinjs-onnx-deep-learning-browser">KotlinJS, ONNX and Deep Learning in the browser</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/2022/01/16/nlp-toolkit-release">Release nlp (londogard-nlp-toolkit) 1.1.0</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/2021/05/17/seam-carving">Seam Carving (Presentation &amp; Workshop)</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/2021/04/18/knowledge-distillation-presentation">Knowledge Distillation (Presentation)</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/2021/04/11/til-pwa-github-pages">TIL: GitHub Pages + Progressive Web App (PWA) = ‚ù§Ô∏è</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="blogPostTitle_rzP5" itemprop="headline">Building a Swedish Named Entity Recognition (NER) model (Flair/Huggingface)</h1><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2021-03-29T00:00:00.000Z" itemprop="datePublished">March 29, 2021</time> ¬∑ <!-- -->11 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><a href="https://github.com/lundez" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_o0gy" src="https://github.com/lundez.png" alt="Hampus Lond√∂g√•rd"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/lundez" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Hampus Lond√∂g√•rd</span></a></div><small class="avatar__subtitle" itemprop="description">Main Contributor of Londogard</small></div></div></div></div></header><div id="post-content" class="markdown" itemprop="articleBody"><p>Not interested in reading the whole article and just wanna play around with the model(s)? Head over to <a href="https://londogard.com/ner" target="_blank" rel="noopener noreferrer">londogard.com/ner</a>.
<img src="https://user-images.githubusercontent.com/7490199/113611097-543f9280-964e-11eb-9e59-bd030c32ad0c.png" alt="image">
<strong>P.S.</strong> The Flair model is available for simple installation through <a href="https://huggingface.co/londogard/flair-swe-ner" target="_blank" rel="noopener noreferrer">huggingface.co&#x27;s model hub</a></p><h1>Building a Swedish Named Entity Recognition (NER) model</h1><p>At <em>Londogard</em> we aim to employ Natural Language Processing (NLP) in a practical manner. The goal is not to create the models of OpenAI or Google, but rather something that is usable from the get-go and performant leading to a simple to use product.<br>
<!-- -->In this post I&#x27;ll cover how we at Londogard developed a State-of-the-Art (SotA) Named Entity Recognition (NER) model for Swedish using Flair &amp; huggingface. üéâ</p><p>It all started last weekend when I was allowed into the <a href="https://streamlit.io/" target="_blank" rel="noopener noreferrer">streamlit.io</a>&#x27;s <em>sharing</em> beta.<br>
<!-- -->If you don&#x27;t know what streamlit, here&#x27;s an excerpt from their frontpage:</p><blockquote><p><strong>The fastest way to build and share data apps</strong>
Streamlit turns data scripts into shareable web apps in minutes.<br>
<!-- -->All in Python. All for free. No front‚Äëend experience required.</p></blockquote><p>Essentially streamlit is a way to combine backend &amp; frontend into a unified script-like experience where the default UI looks pretty good. On top of this script-like experience streamlit has built a powerful yet simple to use cache system.</p><blockquote><p>In my opinion creating demos has never been simpler than with streamlit.io</p></blockquote><p>Back to the problem at hands, I wished to deploy a model through streamlit that actually was a meaningful experience where efficiency and performance are combined, according to the Londogard motto.<br>
<!-- -->As such I embarked on the journey that was to deploy a NER model for <em>Swedish</em> where Swedish actually isn&#x27;t all to common in NLP. Lately <em>Kungliga Biblioteket</em> has been trying to improve this through their <a href="https://github.com/Kungbib/swedish-spacy" target="_blank" rel="noopener noreferrer">spaCy-contribution</a>, which yet has to be included in spaCy, and their <a href="https://huggingface.co/KB/" target="_blank" rel="noopener noreferrer">HuggingFace-contributions</a> where we can find BERT, Electra &amp; Albert pre-trained.<br>
<!-- -->My first idea was to take one of these and fine-tune to finally deploy, but the size of BERT is too large as is. </p><p>What choices are left to allow deploy of these models?</p><ul><li>Distilling ‚öóÔ∏è</li><li>Quantizing</li><li>Fine-tuning ALBERT on NER<ul><li>Performance has been shown to be quite a bit below BERT (7% units) in a paper by KTH, for Swedish.</li></ul></li></ul><p><em>So what did I do?</em> I did as any other professional and google&#x27;d.<br>
<!-- -->A library I hadn&#x27;t heard the name of in a year popped up at the top of the results, I was intrigued.<br>
<!-- -->Flair, a library that was created by Zalando Research, now under the flag <code>/flairnlp</code> which in practice means that the core contributor-group has been changed to Humbold-University of Berlin.<br>
<!-- -->Flair contains the so-called <em>Flair Embeddings</em> which are contextual embeddings of high quality. Flair retains SotA for NER in multiple languages through these and the performance is pretty damn good over all.</p><p>Before I dive into the details on how I trained my own model you can find a demo on <a href="https://londogard.com/ner" target="_blank" rel="noopener noreferrer">londogard.com/ner</a>, where the model is deployed through <a href="https://streamlit.io/" target="_blank" rel="noopener noreferrer">streamlit.io</a>.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="named-entity-recognition-and-how-it-can-do-your-bidding">Named Entity Recognition and how it can do your bidding<a class="hash-link" href="#named-entity-recognition-and-how-it-can-do-your-bidding" title="Direct link to heading">‚Äã</a></h2><p>As the name suggests NER is the task to recognize entities in text. Entities can be a lot of different things such as the obvious <em>Person</em> but also <em>Location</em>, <em>Organisation</em> &amp; <em>Time</em>. More entities exists and they can really become whatever your data allows (<em>Brand</em>, <em>Medicine</em> or <em>Dosage</em>? You got it!)</p><p><strong>Practical use-cases of NER</strong></p><ol><li>Automatic anonymization of data</li><li>Medical prescription</li><li>Automatically tag data<ul><li>e.g. News tagged by Organisations, Persons &amp; Locations included</li></ul></li></ol><p>... &amp; much more</p><p>In my case I&#x27;m simply aiming for the traditional NER model which categorize things like <em>Location</em>, <em>Person</em> &amp; <em>Organisation</em>.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="flairing-the-way-to-success">Flair(ing) the way to success<a class="hash-link" href="#flairing-the-way-to-success" title="Direct link to heading">‚Äã</a></h2><p>Flair is a SotA NLP library developed by <a href="https://www.informatik.hu-berlin.de/en/forschung-en/gebiete/ml-en/" target="_blank" rel="noopener noreferrer">Humboldt University of Berlin</a> and friends. As mentioned its core contributors are from Humboldt University of Berlin and the whole idea is to provide contextual embeddings. Some of the things provided through Flair:</p><ol><li>Flair Embeddings</li><li>(Easily) Stacked Embeddings<ul><li>e.g. combine Transformer, Flair &amp; GloVe for your end-model</li></ul></li><li>Easy access to multiple embeddings<ul><li>GloVe, Transformer, ELMo &amp; many more</li></ul></li><li>Simple training of high-performant NER (Token Classifier) Model and a Text Classifier model</li></ol><p>As mentioned Flair retain SotA in multiple languages for NER, but they do the same for POS.  </p><p><strong>The Language Model</strong><br>
<!-- -->If you&#x27;re curious the simplest Flair embeddings are essentially a Language Model built on Dropout, LSTM &amp; a Linear Layer. Pretty simple.</p><p><strong>The Token Classifier (NER/POS)</strong><br>
<!-- -->It&#x27;s based on a small LSTM-network with a CRF on top. The LSTM exists to create features for the CRF to learn and tag from. This is a very common approach which yields high accuracy. If you&#x27;re aware of what features you wish to use a pure CRF can be very strong, Stanford NLP library was actually for very long based on a CRF and had SotA, but the manual feature engineering can be expensive &amp; hard.</p><p><strong>The Text Classifier</strong>
Simply a linear layer on top of the embeddings.</p><p><strong>More Models</strong><br>
<!-- -->Flair actually supports two other tasks, <em>Text Regression</em> &amp; <em>Similarity</em> but I won&#x27;t go in to those.</p><p>More about how I trained my NER will come a bit further down.
To read more about Flair and how they work please check out their <a href="https://github.com/flairNLP/flair" target="_blank" rel="noopener noreferrer">GitHub</a> which also links to the papers.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="swedish-data">Swedish data<a class="hash-link" href="#swedish-data" title="Direct link to heading">‚Äã</a></h2><p>First of all I had to go find some data and I found cr√®me de la cr√®me in <a href="https://spraakbanken.gu.se/en/resources/suc3" target="_blank" rel="noopener noreferrer">SUC 3.0</a>, because we really do sentence by sentence training in NER it&#x27;s not the end of the world that the &#x27;free&#x27; variant that doesn&#x27;t require a research licence is scrambled. Unscrambled data would lead to a better model but it&#x27;s still doable.</p><p>But as Jeremy Howard proposes, start with small and simple data then expand into your full task. SUC 3.0 is pretty large and slow to train. With some fast googling I found a saviour, <em>klintan</em>. Klintan has created a open Swedish NER dataset based on Webbnyheter 2020 from Spr√•kbanken, it&#x27;s semi-manually annotated. This means that he first based it on <em>Gazetters</em>, essentially dataset(s) of entities, and then manually reviewed the data with two different native Swedish Speakers. More people have later added some improvements on top of that, find the full dataset <a href="https://github.com/klintan/swedish-ner-corpus" target="_blank" rel="noopener noreferrer">here</a>, but please note that <em>it&#x27;s much smaller</em> than SUC 3.0.<br>
<!-- -->After finding this dataset I read more into Flair and I found out that they actually provide this dataset through their API and in this dataset we have 4 categories PER, ORG, LOC and MISC.</p><p>With these two datasets in mind I went ahead to train.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="training-the-flair">Training the flair<a class="hash-link" href="#training-the-flair" title="Direct link to heading">‚Äã</a></h2><p>First let me say the <a href="https://github.com/flairNLP/flair/tree/master/resources/docs" target="_blank" rel="noopener noreferrer">documentation</a> is actually pretty good!
First part is to set up the <code>Corpus</code>.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="setting-up-the-corpus--dataset">Setting up the Corpus / Dataset<a class="hash-link" href="#setting-up-the-corpus--dataset" title="Direct link to heading">‚Äã</a></h3><p><strong>The built-in <em>klintan/ner-swedish-corpus</em></strong></p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 1. get the corpus</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">corpus</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Corpus </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> NER_SWEDISH</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">corpus</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 2. what tag do we want to predict?</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tag_type </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;ner&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 3. make the tag dictionary from the corpus</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tag_dictionary </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> corpus</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">make_tag_dictionary</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">tag_type</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">tag_type</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">tag_dictionary</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p><strong>Custom dataset (SUC 3.0, in my case scrambled)</strong><br>
<!-- -->Remember to convert the SUC tags into a IOB format before training. Emil Stenstr√∂m has kindly created a simple Python-script for this available through <a href="https://github.com/EmilStenstrom/suc_to_iob" target="_blank" rel="noopener noreferrer">github.com/EmilStenstrom/suc_to_iob</a>. First transform the data and later you can run the following code</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">columns </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;text&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;ner&#x27;</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># this is the folder in which train, test and dev files reside</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data_folder </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;path/to/data/suc&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># init a corpus using column format, data folder and the names of the train, dev and test files</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">corpus</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> Corpus </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> ColumnCorpus</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">data_folder</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> columns</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> train_file</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;train.txt&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> test_file</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;test.txt&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> dev_file</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;dev.txt&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 2. what tag do we want to predict?</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tag_type </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;ner&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 3. make the tag dictionary from the corpus</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tag_dictionary </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> corpus</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">make_tag_dictionary</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">tag_type</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">tag_type</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">tag_dictionary</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>With this in mind we&#x27;re ready to set up our model for training.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="model-setup">Model Setup<a class="hash-link" href="#model-setup" title="Direct link to heading">‚Äã</a></h3><p>Our model will build on <code>FlairEmbeddings</code> (e.g. contextual embeddings) and <code>BytePairEmbeddings</code> which are a bit like classic <code>WordEmbeddings</code> but done on BPE-tokenized text. This is a really interesting approach which achieves similar performance as <code>fastText</code> using ~ 0.2 % of the total size (11mb vs 6gb).<br>
<!-- -->The model itself will use a LSTM with a hidden size of 256 and a CRF classifier on top.</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 4. initialize embeddings</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">embedding_types </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># WordEmbeddings(&#x27;sv&#x27;), # uncomment to add WordEmb</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    BytePairEmbeddings</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;sv&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    FlairEmbeddings</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;sv-forward&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    FlairEmbeddings</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;sv-backward&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">embeddings</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> StackedEmbeddings </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> StackedEmbeddings</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">embeddings</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">embedding_types</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 5. initialize sequence tagger</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tagger</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> SequenceTagger </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> SequenceTagger</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">hidden_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">256</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                                        embeddings</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">embeddings</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                                        tag_dictionary</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">tag_dictionary</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                                        tag_type</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">tag_type</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                                        use_crf</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="training-the-model">Training the model<a class="hash-link" href="#training-the-model" title="Direct link to heading">‚Äã</a></h3><p>Because I run through google colab and the machine can be terminated any second I run using <code>checkpoint=True</code> which means you can continue training where you left off. My models are saved to my Google Drive, real handy! </p><blockquote><p>Pro-tip: use <code>checkpoint=True</code> in combination with Google Drive on your Google Colab.</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 7. start training</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">trainer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">train</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;drive/MyDrive/path/to/model/save/&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                learning_rate</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                </span><span class="token comment" style="color:#999988;font-style:italic"># set chunk size to lower memory requirements</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                </span><span class="token comment" style="color:#999988;font-style:italic">#mini_batch_chunk_size=16,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                mini_batch_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">32</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                checkpoint</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                embeddings_storage_mode</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;none&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># only required for SUC 3.0 which grows too large</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                </span><span class="token comment" style="color:#999988;font-style:italic">#batch_growth_annealing=True,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                </span><span class="token comment" style="color:#999988;font-style:italic">#anneal_with_restarts=True,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                max_epochs</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">150</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="loading-model-from-checkpoint">Loading model from checkpoint<a class="hash-link" href="#loading-model-from-checkpoint" title="Direct link to heading">‚Äã</a></h3><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">trainer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> ModelTrainer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_checkpoint</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;drive/MyDrive/path/to/model/save/checkpoint.pt&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> corpus</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>And that&#x27;s it!</p></blockquote><h2 class="anchor anchorWithStickyNavbar_mojV" id="result">Result<a class="hash-link" href="#result" title="Direct link to heading">‚Äã</a></h2><p>For me the results looks really good and close to what I expected, I had hoped that Flair would achieve at least 0.88+ F1 but 0.855 isn&#x27;t too bad. The size, speed and simplicity of Flair makes it a great contender!</p><table><thead><tr><th>Dataset</th><th>Size</th><th>Avg F1</th></tr></thead><tbody><tr><td>klintan/swedish-ner-corpus</td><td>320MB</td><td>~<strong>0.89</strong></td></tr><tr><td>SUC 3.0 (PER, LOC &amp; ORG)</td><td>320MB</td><td>~<strong>0.89</strong></td></tr><tr><td>SUC 3.0 (PER, LOC, ORG, TME, MSR, ...)</td><td>320MB</td><td><strong>0.855</strong></td></tr><tr><td>SUC 3.0 (PER, LOC, ORG, TME, MSR, ...) Quantized</td><td>80MB</td><td><strong>0.853</strong></td></tr><tr><td>SUC 3.0 (PER, LOC, ORG, TME, MSR, ...) w/ ALBERT</td><td>50MB</td><td><strong>0.85</strong> (via <a href="http://kth.diva-portal.org/smash/get/diva2:1451804/FULLTEXT01.pdf" target="_blank" rel="noopener noreferrer">KTH</a>)</td></tr><tr><td>SUC 3.0 (PER, LOC, ORG, TME, MSR, ...) w/ BERT (<a href="https://github.com/Kungbib/swedish-bert-models#bert-base-fine-tuned-for-swedish-ner" target="_blank" rel="noopener noreferrer">KungBib</a>)</td><td>480MB</td><td><strong>0.928</strong></td></tr><tr><td>SUC 3.0 (PER, LOC, ORG, TME, MSR, ...) w/ BERT Quantized</td><td>120MB</td><td><strong>0.928</strong></td></tr></tbody></table><p>I believe it&#x27;s important to note that Quantized models are also much faster running ~ 4 times faster (avg 360ms went to 80ms on a CPU for flair).<br>
<!-- -->Quantization updates the f32 into int8 which allows the model to more efficiently utilize CPU and the ONNX-runtime also makes the whole model better at using CPU-instructions.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="deploying-on-streamlitiosharing">Deploying on streamlit.io/sharing<a class="hash-link" href="#deploying-on-streamlitiosharing" title="Direct link to heading">‚Äã</a></h2><p>And for the final part! üéâ
First you need a new public repository on GitHub with the streamlit &amp; model code. This requires to set up a <code>requirements.txt</code> with all necessary dependencies.</p><p>Then you need to figure out how you&#x27;ll host your model if it&#x27;s too large. I found GitHub LFS to work out decently, but the cap was pretty small (1GB / Month) and I broke the limit on my 3rd model. I went ahead and registered on <a href="https://www.backblaze.com" target="_blank" rel="noopener noreferrer">Backblaze</a> which has great reviews, but I think the best solution in my shoes would be to host it through HuggingFace Model storage (free if public!).
<strong>edit:</strong> I actually ended up storing the flair model on <a href="https://huggingface.co/londogard/flair-swe-ner" target="_blank" rel="noopener noreferrer">huggingface.co/londogard/flair-swe-ner</a> ü§ó.</p><p>Setting up the script itself was quite easy for Flair.</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># load tagger for POS and</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token decorator annotation punctuation" style="color:#393A34">@st</span><span class="token decorator annotation punctuation" style="color:#393A34">.</span><span class="token decorator annotation punctuation" style="color:#393A34">cache</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">allow_output_mutation</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">load_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tagger </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> SequenceTagger</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;best-model-large-data.pt&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> tagger</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token decorator annotation punctuation" style="color:#393A34">@st</span><span class="token decorator annotation punctuation" style="color:#393A34">.</span><span class="token decorator annotation punctuation" style="color:#393A34">cache</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">allow_output_mutation</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> hash_funcs</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">SequenceTagger</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">lambda</span><span class="token plain">  _</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">predict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> text</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    manual_sentence </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> Sentence</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">manual_user_input</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">manual_sentence</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> render_ner_html</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">manual_sentence</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> wrap_page</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">False</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tagger </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> load_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">st</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">title</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;Swedish Named Entity Recognition (NER) tagger&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">st</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">subheader</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;Created by [Londogard](https://londogard.com) (Hampus Lond√∂g√•rd)&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">st</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">title</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;Please type something in the box below&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">manual_user_input </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> st</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">text_area</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> </span><span class="token builtin">len</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">manual_user_input</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sentence </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> predict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">tagger</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> manual_user_input</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    st</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">success</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;Below is your tagged string.&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    st</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">write</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">sentence</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> unsafe_allow_html</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>It&#x27;s important to note how I&#x27;ve placed the caching solution. I both cache the model loading &amp; predictions to keep it as speedy as possible.   </p><p>The <code>allow_output_mutation</code> option skips hashing the output to validate that the cache is correct, we don&#x27;t care if output has been modified really.</p><p>The <code>hash_funcs={SequenceTagger: lambda  _: None}</code> is <strong>incredibly important</strong>.<br>
<!-- -->The flair model are pretty slow to hash, especially if quantized. It&#x27;s possible to use <code>id</code> which is a unique ID for the python object that lasts the full lifetime, but because I know that the model wont change I simply use <code>lambda _: None</code> to not do any lookup at all.<br>
<!-- -->If the model input would change in-between using <code>id</code> is the best approach. Note that neither of this approaches are any good if you wanna compare an object to another (e.g. two string inputs), there we should just keep standard hashing.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="outro">Outro<a class="hash-link" href="#outro" title="Direct link to heading">‚Äã</a></h2><p>I trained Flair embeddings which is a much simpler approach than Transformers and achieved almost SotA while having a much smaller &amp; simpler model (~2/3rd of the size). But in the end I was very impressed by how well quantization applies for CPU utilization so I also applied the same approach for BERT-ner by KB, where I even did a ONNX Quantization which has been shown to be even more effective than PyTorch own quantization, but then again it requires the ONNX runtime.</p><p>Both models are available on the same device / streamlit configuration, find them on <a href="https://londogard.com/ner" target="_blank" rel="noopener noreferrer">londogard.com/ner</a>.<br>
<!-- -->The flair model is available through HuggingFace ü§ó through the following: <a href="https://huggingface.co/londogard" target="_blank" rel="noopener noreferrer">londogard (huggingface.co)</a>.</p><p>Thanks for this time,
Hampus Lond√∂g√•rd @ Londogard</p></div><footer class="row docusaurus-mt-lg blogPostDetailsFull_h6_j"><div class="col"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/nlp">nlp</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/machine-learning">machine-learning</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/workshop">workshop</a></li></ul></div><div class="col margin-top--sm"><a href="https://github.com/londogard/londogard/blog/2021-03-29-swedish-named-entity-recognition.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_dcUD" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/blog/2021/04/11/til-pwa-github-pages"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">TIL: GitHub Pages + Progressive Web App (PWA) = ‚ù§Ô∏è</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/blog/2021/03/17/replace-in-string"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">When to use what - RegExp, String Replace &amp; Character Replace (JVM/Kotlin)</div></a></div></nav></main><div class="col col--2"><div class="tableOfContents_cNA8 thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#named-entity-recognition-and-how-it-can-do-your-bidding" class="table-of-contents__link toc-highlight">Named Entity Recognition and how it can do your bidding</a></li><li><a href="#flairing-the-way-to-success" class="table-of-contents__link toc-highlight">Flair(ing) the way to success</a></li><li><a href="#swedish-data" class="table-of-contents__link toc-highlight">Swedish data</a></li><li><a href="#training-the-flair" class="table-of-contents__link toc-highlight">Training the flair</a><ul><li><a href="#setting-up-the-corpus--dataset" class="table-of-contents__link toc-highlight">Setting up the Corpus / Dataset</a></li><li><a href="#model-setup" class="table-of-contents__link toc-highlight">Model Setup</a></li><li><a href="#training-the-model" class="table-of-contents__link toc-highlight">Training the model</a></li></ul></li><li><a href="#result" class="table-of-contents__link toc-highlight">Result</a></li><li><a href="#deploying-on-streamlitiosharing" class="table-of-contents__link toc-highlight">Deploying on streamlit.io/sharing</a></li><li><a href="#outro" class="table-of-contents__link toc-highlight">Outro</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Support Londogard</div><ul class="footer__items"><li class="footer__item"><a href="https://www.buymeacoffee.com/hlondogard" target="_blank"><img src="https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png" alt="Buy Me A Coffee" style="height: 60px !important;width: 217px !important;"></a></li><li class="footer__item"><div style="display: flex; align-items: center;"><iframe src="https://github.com/sponsors/Lundez/button" title="Sponsor Lundez" height="35" width="116" style="border: 0;"></iframe><div>&nbsp;on GitHub</div></div></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/londogard" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">Feeds</div><ul class="footer__items"><li class="footer__item"><a href="https://blog.londogard.com/blog/rss.xml" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>RSS<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://blog.johnnyreilly.com/blog/atom.xml" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Atom<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2022 Londogard. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.1532c46a.js"></script>
<script src="/assets/js/main.2212e7b3.js"></script>
</body>
</html>