<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.15">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Londogard Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Londogard Blog Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><title data-react-helmet="true">GPT2-snapsvisor - Generating Swedish Drinking Songs | Londogard Blog</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://blog.londogard.com/blog/gpt2-snapsvisor"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_tag" content="default"><meta data-react-helmet="true" name="keywords" content="nlp, kotlin, jvm, deep-learning, machine-learning, blog"><meta data-react-helmet="true" property="og:title" content="GPT2-snapsvisor - Generating Swedish Drinking Songs | Londogard Blog"><meta data-react-helmet="true" name="description" content="Snapsvisor is traditional Swedish Drinking Songs, sometimes they need some refreshing which I try to do through AI here! ;)"><meta data-react-helmet="true" property="og:description" content="Snapsvisor is traditional Swedish Drinking Songs, sometimes they need some refreshing which I try to do through AI here! ;)"><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="article:published_time" content="2022-07-07T00:00:00.000Z"><meta data-react-helmet="true" property="article:author" content="https://github.com/lundez"><meta data-react-helmet="true" property="article:tag" content="machine-learning,nlp,fun"><link data-react-helmet="true" rel="icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://blog.londogard.com/blog/gpt2-snapsvisor"><link data-react-helmet="true" rel="alternate" href="https://blog.londogard.com/blog/gpt2-snapsvisor" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://blog.londogard.com/blog/gpt2-snapsvisor" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.2b27dec1.css">
<link rel="preload" href="/assets/js/runtime~main.09bd1e8c.js" as="script">
<link rel="preload" href="/assets/js/main.95872d60.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="Londogard logo" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/favicon.ico" alt="Londogard logo" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title">Londogard Blog</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/blog/archive">Blog Archive</a><a class="navbar__item navbar__link" href="/presentations">Presentations</a></div><div class="navbar__items navbar__items--right"><a href="https://londogard.com/about" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>About<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><a href="https://londogard.com/projects" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>Londogard Projects<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><a href="https://github.com/londogard" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_Pssr toggle_TdHA toggleDisabled_jDku"><div class="toggleTrack_SSoT" role="button" tabindex="-1"><div class="toggleTrackCheck_XobZ"><span class="toggleIcon_eZtF">🌜</span></div><div class="toggleTrackX_YkSC"><span class="toggleIcon_eZtF">🌞</span></div><div class="toggleTrackThumb_uRm4"></div></div><input type="checkbox" class="toggleScreenReader_JnkT" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-post-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_a9qW thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_uKok margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Kvuv"><li class="sidebarItem_CF0Q"><a aria-current="page" class="sidebarItemLink_miNk sidebarItemLinkActive_RRTD" href="/blog/gpt2-snapsvisor">GPT2-snapsvisor - Generating Swedish Drinking Songs</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/timeseries-pt-3">Forecasting Crypto Prices using Deep Learning (Time Series #3)</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/timeseries-pt-2">Predicting Stock Prices using classical machine Learning (Time Series #2)</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/timeseries-pt-1">Decomposing &amp; Working with Time Series (Time Series #1)</a></li><li class="sidebarItem_CF0Q"><a class="sidebarItemLink_miNk" href="/blog/kotlinjs-onnx-deep-learning-browser">KotlinJS, ONNX and Deep Learning in the browser</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="blogPostTitle_rzP5" itemprop="headline">GPT2-snapsvisor - Generating Swedish Drinking Songs</h1><div class="blogPostData_Zg1s margin-vert--md"><time datetime="2022-07-07T00:00:00.000Z" itemprop="datePublished">July 7, 2022</time> · <!-- -->9 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_FlmR"><div class="avatar margin-bottom--sm"><a href="https://github.com/lundez" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_o0gy" src="https://github.com/lundez.png" alt="Hampus Londögård"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/lundez" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Hampus Londögård</span></a></div><small class="avatar__subtitle" itemprop="description">Main Contributor of Londogard</small></div></div></div></div></header><div id="post-content" class="markdown" itemprop="articleBody"><p>This midsummer my friends gave me the idea that I should generate Swedish Drinking Songs, or <em>Snapsvisor</em>, using Machine Learning and I thought it could be a lot of fun! 🍻  </p><p>To achieve the best results I&#x27;d need access to GPT-3, or equivalent model, alas I don’t and as such I needed  to do some extra work! Fun work though! 🤓</p><p>First some examples:
<img src="/assets/images/snapsvisor-1e9929b990748f972dcc7653fd5e73be.png" width="1028" height="443"></p><p>Why GPT-3?</p><ul><li>Possible to do <em>prompt engineering</em>, which gwern has a great <a href="https://www.gwern.net/GPT-3#prompts-as-programming" target="_blank" rel="noopener noreferrer">blog on</a><ul><li>TL;DR prompt engineering allows you to write a prompt and get a response, e.g. “step-by-step how to write a blog” and the return the step-by-step.</li></ul></li><li>Much better zero-/one-/few-shot learning<ul><li>Because the model has a ton more parameters and trained on a larger dataset</li></ul></li></ul><p>Drawbacks with GPT-2:</p><ul><li>The performance is noticable worse because of the lower parameters and less data, sometimes called tokens, used to train the model.</li></ul><p>As such the result is not amazing, but it&#x27;s capable and really funny - based on the premise that you know Swedish!</p><p><strong>It&#x27;s available on the <a href="https://huggingface.co/lunde/gpt2-snapsvisor" target="_blank" rel="noopener noreferrer">HuggingFace Hub</a></strong> with a <strong>inference widget</strong> and <strong>as a pre-trained model</strong>, which can generate your own <em>Snapsvisor</em> - N.B. it removes newlines. </p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> AutoTokenizer</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> AutoModelForCausalLM</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoTokenizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;lunde/gpt2-snapsvisor&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoModelForCausalLM</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;lunde/gpt2-snapsvisor&quot;</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="gpt-3-few-shot-learning-and-prompt-engineering">GPT-3: Few-Shot Learning and Prompt Engineering<a class="hash-link" href="#gpt-3-few-shot-learning-and-prompt-engineering" title="Direct link to heading">​</a></h3><p>Few-Shot Learning is the capability to solve an unknown task using either very few or no (training) data points at all to solve, which can successfully be done today.</p><p>In other words, we can achieve great accuracy with little or no data att all!</p><p>Few-Shot Learning reminds me of how human learns, we are very fast at generalizing knowledge. By knowing the difference between a cat, dog and tiger we can very fast learn that a lion is a unique animal and if we are told the name we know that this unique animal is a lion!</p><p>We are also able to make up words that we don&#x27;t know about, like &quot;car wheel&quot; by seeing a wheel on a car!</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="few-shot-learning-explained">Few-Shot Learning Explained<a class="hash-link" href="#few-shot-learning-explained" title="Direct link to heading">​</a></h3><p>Less theory, more examples!</p><p><em>Prompt Engineering</em>  is a Few-Shot technique that grew increasingly powerful with each generation of Large Language Models (LLM) and with GPT-3 it became incredibly good.</p><ul><li><strong>Model:</strong> The Large Language Model (LLM) being used, e.g. GPT-3 .</li><li><strong>Prompt:</strong> The text given to the LLM to generate an answer from, or complete.</li><li><strong>Zero-shot:</strong> A prompt with no examples, e.g. <code>The name of a character from Star Wars is:</code> or <code>[Swedish: &quot;Snaps!&quot;, English: &quot;</code></li><li><strong>Few-shot:</strong> A prompt with one (1-shot) or more (n-shot, few-shot) examples. See example below</li></ul><p>To then give a example of few-shot (4) prompt:</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">This is a list of startup ideas:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. [Tag: Internet] A website that lets you post articles you&#x27;ve written, and other people can help you edit them.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. [Tag: Home] A website that lets you share a photo of something broken in your house, and then local people can offer to fix it for you.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. [Tag: Children] An online service that teaches children how to code.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. [Tag: Financial] An online service that allows people to rent out their unused durable goods to people who need them.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">5. [Tag: Machine Learning]</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>Using <em>Prompt Engineering</em> and GPT-3 I&#x27;m certain that it&#x27;d be possible to generate <em>Snapsvisor</em> with little data, i.e. Few-Shot Learning.</p><p>GPT-2’s few-shot capabilities are much smaller as such I need to <em>Fine Tune</em> the model.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="fine-tuning-a-model">Fine-Tuning a model<a class="hash-link" href="#fine-tuning-a-model" title="Direct link to heading">​</a></h3><p>Fine-Tuning a model can be done in multiple ways, three examples of fine-tuning is</p><ol><li><em>Training</em> (like normally)</li><li><em>Freezing</em></li><li><em>Dynamic Learning Rate</em></li></ol><p><strong>Training</strong></p><p>Simply train your pre-trailed model with the new dataset. The Language Models parameters is already encoded with knowledge about language, structure and semantic meaning. This efficient representation and initiation means that it faster learns about new, similar, tasks than a pseudo-random weight initialization.  </p><p>It has to be noted that the pre-training task, scheme and data impacts the later fine-tuning.</p><p><strong>Freezing</strong>   </p><p>Freezing layers is one of the most common approaches, usually freezing all layers except the <em>head</em> <!-- -->-<!-- --> the head is the final layer(s) and the rest is the <em>backbone</em>. Usually the head is equal to the classification layer. </p><p>In other words, the head takes an internal representation, embedding, and learns to decode it in the optimal way to solve the task.</p><p>By only changing your head and training that part we train the model faster and don&#x27;t risk forgetting important information in the network.</p><p><img src="/assets/images/06406d83-410b-4e79-b2c8-025c53dbf9b2-f81b488e9be1175647320ce40bffb42f.png" width="676" height="526">  </p><blockquote><p><strong>Important info early in the network:</strong><br>
<!-- -->Early in the network important information is chopped into large pieces and unimportant information is largely removed.<br>
<!-- -->Like carpeting you first chop the large pieces and the further you get the smaller and finer details are built. The same can be said about neural networks. <br>
<!-- -->This means that if we learn to remove important information at the early stages we&#x27;ll loose it. This is catastrophic forgetting.</p></blockquote><p>Once the head is trained we can improve the results further by gradually unfreezing the last layers, one at a time. But make sure to have a low learning rate as otherwise the model might forget important information.</p><p><img src="/assets/images/ed771f34-3726-43f3-8d73-194f9e94e42d-58c36830ef3b7be797166dc1ea1950f1.png" width="697" height="504">  </p><p><strong>Dynamic Learning Rate</strong>   </p><p>Rather than freezing and unfreezing layer there&#x27;s a technique where you apply different learning rates, lower in early layers and larger at the final ones.</p><p>This means that we don&#x27;t risk forgetting important information in the early layers.</p><p><img src="/assets/images/e449ace7-df38-4bda-bc44-38a8cad9ad18-e57b5e256d9a69944498a4211fc2c4cc.png" width="762" height="489">  </p><h3 class="anchor anchorWithStickyNavbar_mojV" id="building-the-dataset-of-snapsvisor">Building the dataset of Snapsvisor<a class="hash-link" href="#building-the-dataset-of-snapsvisor" title="Direct link to heading">​</a></h3><p>Because only GPT-2 was accessible we must <em>Fine-Tune</em> the model. Gathering the data becomes the first and most important step, and we need many <em>Snapsvisor</em>.</p><p>To build this dataset I decided to do what most software developers decide to do in this stage, <em>scrape the internet</em>. The internet is really a wonderful source of data and I found multiple sites that had <em>Snapsvisor</em>.</p><p>To query and parse these I needed my necessary tools, which in Python naturally is </p><ol><li><code>requests</code></li><li><code>BeautifulSoup4</code></li></ol><h5 class="anchor anchorWithStickyNavbar_mojV" id="requests">Requests<a class="hash-link" href="#requests" title="Direct link to heading">​</a></h5><p>It’s very easy to do HTTP-requests using <code>requests</code>, simply call <code>.get</code> or <code>.post</code></p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> requests</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">url </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;https://www.website.com/path/to/query&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">resp </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> requests</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">get</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">url</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">resp</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">status_code</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> resp</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">text </span><span class="token comment" style="color:#999988;font-style:italic"># also possible to run resp.json</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>And if the web-page blocks you by some reason most of the times it can be solved by updating the <code>headers</code>  supplied.</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">headers </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;User-Agent&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:20.0) Gecko/20100101 Firefox/20.0&quot;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">resp </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> requests</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">get</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">url</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> headers</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">headers</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">text</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>That’s all we need to learn about <code>requests</code> for now!</p><h5 class="anchor anchorWithStickyNavbar_mojV" id="beautifulsoup">BeautifulSoup<a class="hash-link" href="#beautifulsoup" title="Direct link to heading">​</a></h5><p>And how about BeautifulSoup, or bs4 as it&#x27;s sometimes called?</p><p>It’s also rather easy, the webpage is returned almost like a dictionary with tools to query in-memory.</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">resp </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> requests</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">get</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">url</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">text</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">soup </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> BeautifulSoup</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">resp</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;html.parser&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># now you can query `soup.find_all(&quot;a&quot;)` to get all a-elements in the HTML page etc</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>To learn more see the documentation at <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" target="_blank" rel="noopener noreferrer">https://www.crummy.com/software/BeautifulSoup/bs4/doc/</a>.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="fine-tuning-the-model">Fine-Tuning the model<a class="hash-link" href="#fine-tuning-the-model" title="Direct link to heading">​</a></h3><p>I found a swedish version of GPT-2 in the HuggingFace Hub 🥳</p><p>Fine-Tuning the model on my data to generate <em>Snapsvisor</em> is not far away! 😎</p><p>To move fast and make it easy I chose to use the HuggingFace Trainer-API. A better tutorial than this one is available in the HuggingFace documentation.</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> AutoTokenizer</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> TextDataset</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> DataCollatorForLanguageModeling</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> Trainer</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> TrainingArguments</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> AutoModelForCausalLM</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model_name </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;flax-community/swe-gpt-wiki&quot;</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># replace with your model</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoTokenizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model_name</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoModelForCausalLM</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">gpt_model</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>With the pretrained model and tokenizer locked and loaded we&#x27;re ready to fine-tune with our own data. </p><p>Loading our dataset can be done in multiple ways, but the easiest is most likely to either use HuggingFace <code>[datasets](https://huggingface.co/docs/datasets)</code> or through their <code>DataCollatorForLanguageModelling</code> .</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">load_dataset</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">train_path</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> tokenizer</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    train_dataset </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> TextDataset</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          tokenizer</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">tokenizer</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          file_path</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">train_path</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          block_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">128</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    data_collator </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> DataCollatorForLanguageModeling</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         tokenizer</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">tokenizer</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> mlm</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">False</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> train_dataset</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> data_collator</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">train_path </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;all_text.txt&quot;</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># replace with your training file</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">train_dataset</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> data_collator </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> load_dataset</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">train_path</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> tokenizer</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>With our model, tokenizer and (training) dataset ready we can start fine-tuning the model! This is easiest done using HuggingFace’s <code>Trainer</code> .</p><p>HuggingFace has used a <em>Argument-Object</em> pattern to reduce the number of arguments to the <code>Trainer</code>. The <code>TrainingArguments</code>  class wraps a lot of the arguments, fully typed. 👌</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">training_args </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> TrainingArguments</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    output_dir</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;./gpt2-snaps&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># The output directory</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    overwrite_output_dir</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># Overwrite the content of the output directory</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    num_train_epochs</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">300</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># Number of training epochs</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    per_device_train_batch_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">8</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># Batch size for training</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    save_steps</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1000</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># After # steps model is saved</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    warmup_steps</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">500</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># Number of warmup steps for learning rate scheduler</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    fp16</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># Activate float-point=16 precision to train faster</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">trainer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> Trainer</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    args</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">training_args</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    data_collator</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">data_collator</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    train_dataset</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">train_dataset</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>Training is one click away! <strong>But we don&#x27;t have a validation dataset?</strong></p><p>As I have little data I chose to train with all data, I don&#x27;t really care if we overfit the data (unless it looks bad) for this small task. As such we use all the data to train our Language Model.</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">trainer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">train</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">resume_from_checkpoint</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">trainer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">save_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>Generating text, or <code>inference</code>, is smooth using HuggingFace <code>pipelines</code>.</p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> pipeline</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">trainer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cpu</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">snaps </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> pipeline</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;text-generation&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">trainer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> tokenizer</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">gpt_model</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">result </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> snaps</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;Nu tar vi en nubbe&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>That&#x27;s all there is really!</p><p>Some examples:</p><blockquote><p>Nu tar vi en nubbe, <br>
<!-- -->Den ska hellre krypa och bränna upp. <br>
<!-- -->Vi bränna, men inte mjölka oss, <br>
<!-- -->och bränner till bords</p></blockquote><blockquote><p>Nu tar vi en nubbe – slåss här i ett svep.<br>
<!-- -->Byssa luderorgon, snapsar!<br>
<!-- -->När den evigt låga solen tar oss en ljus natt,<br>
<!-- -->ingen blir så dragen vid näsan</p></blockquote><h2 class="anchor anchorWithStickyNavbar_mojV" id="tldr-too-long-didnt-read">TL;DR (Too Long; Didn’t Read)<a class="hash-link" href="#tldr-too-long-didnt-read" title="Direct link to heading">​</a></h2><p>For those that are not interested in details or writeups I thought I’d leave a small TL;DR</p><ol><li>Find a pre-trained Language Model (e.g. GPT-2) (<a href="https://huggingface.co/flax-community/swe-gpt-wiki" target="_blank" rel="noopener noreferrer">link</a>)</li><li>Scrape the web for text data (in my case “Snapsvisor”) using <code>requests</code>  (<a href="https://requests.readthedocs.io/" target="_blank" rel="noopener noreferrer">link</a>) and <code>beautifulsoup4</code> (<a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" target="_blank" rel="noopener noreferrer">link</a>)</li><li>Fine-Tune the model using HuggingFace <code>Trainer</code>-<!-- -->api (<a href="https://huggingface.co/docs/transformers/main_classes/trainer" target="_blank" rel="noopener noreferrer">link</a>)</li><li>Generate text using HuggingFace <code>pipelines</code> (<a href="https://huggingface.co/docs/transformers/main_classes/pipelines" target="_blank" rel="noopener noreferrer">link</a>)</li></ol><p>And in the end we can generate some <em>Snapsvisor</em>, like the following examples</p><blockquote><p>Snälla skålar till en nubbe, buguperrens till en skål.<br>
<!-- -->Snapsen får ta en nubbe,<br>
<!-- -->när nubben inte tagit visdomsträngar,<br>
<!-- -->sen får ta nubben hellre.<br>
<!-- -->Hinka lilla magen, ta nubben,<br>
<!-- -->där ska det gå till en nubbe.  </p></blockquote><blockquote><p>Nu tar vi en nubbe, <br>
<!-- -->Den ska hellre krypa och bränna upp. <br>
<!-- -->Vi bränna, men inte mjölka oss, <br>
<!-- -->och bränner till bords</p></blockquote><blockquote><p>Nu tar vi en nubbe – slåss här i ett svep.<br>
<!-- -->Byssa luderorgon, snapsar!<br>
<!-- -->När den evigt låga solen tar oss en ljus natt,<br>
<!-- -->ingen blir så dragen vid näsan</p></blockquote><p>And <strong>it&#x27;s available on the <a href="https://huggingface.co/lunde/gpt2-snapsvisor" target="_blank" rel="noopener noreferrer">HuggingFace Hub</a></strong> with a <strong>inference widget</strong>, which can generate your own <em>Snapsvisor</em> - N.B. it removes newlines. </p><div class="codeBlockContainer_I0IT language-python theme-code-block"><div class="codeBlockContent_wNvx python"><pre tabindex="0" class="prism-code language-python codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> AutoTokenizer</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> AutoModelForCausalLM</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoTokenizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;lunde/gpt2-snapsvisor&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoModelForCausalLM</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;lunde/gpt2-snapsvisor&quot;</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>Until next time!</p><p>~Hampus Londögård</p></div><footer class="row docusaurus-mt-lg blogPostDetailsFull_h6_j"><div class="col"><b>Tags:</b><ul class="tags_XVD_ padding--none margin-left--sm"><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/machine-learning">machine-learning</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/nlp">nlp</a></li><li class="tag_JSN8"><a class="tag_hD8n tagRegular_D6E_" href="/blog/tags/fun">fun</a></li></ul></div><div class="col margin-top--sm"><a href="https://github.com/londogard/londogard/blog/2022-07-07-snapsvisor-generated/2022-07-07-snapsvisor-generator.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_dcUD" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><div class="pagination-nav__item"></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/blog/timeseries-pt-3"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Forecasting Crypto Prices using Deep Learning (Time Series #3)</div></a></div></nav></main><div class="col col--2"><div class="tableOfContents_cNA8 thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#gpt-3-few-shot-learning-and-prompt-engineering" class="table-of-contents__link toc-highlight">GPT-3: Few-Shot Learning and Prompt Engineering</a></li><li><a href="#few-shot-learning-explained" class="table-of-contents__link toc-highlight">Few-Shot Learning Explained</a></li><li><a href="#fine-tuning-a-model" class="table-of-contents__link toc-highlight">Fine-Tuning a model</a></li><li><a href="#building-the-dataset-of-snapsvisor" class="table-of-contents__link toc-highlight">Building the dataset of Snapsvisor</a></li><li><a href="#fine-tuning-the-model" class="table-of-contents__link toc-highlight">Fine-Tuning the model</a></li><li><a href="#tldr-too-long-didnt-read" class="table-of-contents__link toc-highlight">TL;DR (Too Long; Didn’t Read)</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Support Londogard</div><ul class="footer__items"><li class="footer__item"><a href="https://www.buymeacoffee.com/hlondogard" target="_blank"><img src="https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png" alt="Buy Me A Coffee" style="height: 60px !important;width: 217px !important;"></a></li><li class="footer__item"><div style="display: flex; align-items: center;"><iframe src="https://github.com/sponsors/Lundez/button" title="Sponsor Lundez" height="35" width="116" style="border: 0;"></iframe><div>&nbsp;on GitHub</div></div></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/londogard" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">Feeds</div><ul class="footer__items"><li class="footer__item"><a href="https://blog.londogard.com/blog/rss.xml" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>RSS<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://blog.johnnyreilly.com/blog/atom.xml" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Atom<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2022 Londogard. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.09bd1e8c.js"></script>
<script src="/assets/js/main.95872d60.js"></script>
</body>
</html>