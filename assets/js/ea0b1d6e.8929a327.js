"use strict";(self.webpackChunklondogard=self.webpackChunklondogard||[]).push([[9185],{3905:function(e,t,r){r.d(t,{Zo:function(){return p},kt:function(){return u}});var n=r(7294);function o(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function a(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?a(Object(r),!0).forEach((function(t){o(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):a(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,n,o=function(e,t){if(null==e)return{};var r,n,o={},a=Object.keys(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||(o[r]=e[r]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var c=n.createContext({}),s=function(e){var t=n.useContext(c),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},p=function(e){var t=s(e.components);return n.createElement(c.Provider,{value:t},e.children)},f={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var r=e.components,o=e.mdxType,a=e.originalType,c=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),d=s(r),u=o,m=d["".concat(c,".").concat(u)]||d[u]||f[u]||a;return r?n.createElement(m,i(i({ref:t},p),{},{components:r})):n.createElement(m,i({ref:t},p))}));function u(e,t){var r=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=r.length,i=new Array(a);i[0]=d;var l={};for(var c in t)hasOwnProperty.call(t,c)&&(l[c]=t[c]);l.originalType=e,l.mdxType="string"==typeof e?e:o,i[1]=l;for(var s=2;s<a;s++)i[s]=r[s];return n.createElement.apply(null,i)}return n.createElement.apply(null,r)}d.displayName="MDXCreateElement"},5020:function(e,t,r){r.r(t),r.d(t,{frontMatter:function(){return l},contentTitle:function(){return c},metadata:function(){return s},assets:function(){return p},toc:function(){return f},default:function(){return u}});var n=r(7462),o=r(3366),a=(r(7294),r(3905)),i=["components"],l={title:"Transformers From Scratch",description:"In this post I walk through Self-Attention Transformers from scratch with demos at the end for Text Classification & Generation, where the PyTorch-code is wrapped by fast.ai to simplify end-2-end.",tags:["nlp","machine-learning","deep-learning","workshop"],authors:"hlondogard"},c=void 0,s={permalink:"/blog/2021/02/18/transformers-explained",editUrl:"https://github.com/londogard/londogard/blog/2021-02-18-transformers-explained/index.md",source:"@site/blog/2021-02-18-transformers-explained/index.md",title:"Transformers From Scratch",description:"In this post I walk through Self-Attention Transformers from scratch with demos at the end for Text Classification & Generation, where the PyTorch-code is wrapped by fast.ai to simplify end-2-end.",date:"2021-02-18T00:00:00.000Z",formattedDate:"February 18, 2021",tags:[{label:"nlp",permalink:"/blog/tags/nlp"},{label:"machine-learning",permalink:"/blog/tags/machine-learning"},{label:"deep-learning",permalink:"/blog/tags/deep-learning"},{label:"workshop",permalink:"/blog/tags/workshop"}],readingTime:30.31,truncated:!0,authors:[{name:"Hampus Lond\xf6g\xe5rd",title:"Main Contributor of Londogard",url:"https://github.com/lundez",imageURL:"https://github.com/lundez.png",key:"hlondogard"}],frontMatter:{title:"Transformers From Scratch",description:"In this post I walk through Self-Attention Transformers from scratch with demos at the end for Text Classification & Generation, where the PyTorch-code is wrapped by fast.ai to simplify end-2-end.",tags:["nlp","machine-learning","deep-learning","workshop"],authors:"hlondogard"},prevItem:{title:"When to use what - RegExp, String Replace & Character Replace (JVM/Kotlin)",permalink:"/blog/2021/03/17/replace-in-string"},nextItem:{title:"TIL: GitPod - your editor in the cloud",permalink:"/blog/2021/01/21/til-gitpod-kotlin-jvm"}},p={authorsImageUrls:[void 0]},f=[],d={toc:f};function u(e){var t=e.components,r=(0,o.Z)(e,i);return(0,a.kt)("wrapper",(0,n.Z)({},d,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"In this post I walk through Self-Attention Transformers from scratch with demos at the end for Text Classification & Generation, where the PyTorch-code is wrapped by fast.ai to simplify end-2-end."))}u.isMDXComponent=!0}}]);