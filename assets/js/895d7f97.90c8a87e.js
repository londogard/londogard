"use strict";(self.webpackChunklondogard=self.webpackChunklondogard||[]).push([[5768],{3905:function(t,e,a){a.d(e,{Zo:function(){return m},kt:function(){return u}});var n=a(7294);function l(t,e,a){return e in t?Object.defineProperty(t,e,{value:a,enumerable:!0,configurable:!0,writable:!0}):t[e]=a,t}function s(t,e){var a=Object.keys(t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(t);e&&(n=n.filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable}))),a.push.apply(a,n)}return a}function r(t){for(var e=1;e<arguments.length;e++){var a=null!=arguments[e]?arguments[e]:{};e%2?s(Object(a),!0).forEach((function(e){l(t,e,a[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(t,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(e){Object.defineProperty(t,e,Object.getOwnPropertyDescriptor(a,e))}))}return t}function i(t,e){if(null==t)return{};var a,n,l=function(t,e){if(null==t)return{};var a,n,l={},s=Object.keys(t);for(n=0;n<s.length;n++)a=s[n],e.indexOf(a)>=0||(l[a]=t[a]);return l}(t,e);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(t);for(n=0;n<s.length;n++)a=s[n],e.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(t,a)&&(l[a]=t[a])}return l}var p=n.createContext({}),o=function(t){var e=n.useContext(p),a=e;return t&&(a="function"==typeof t?t(e):r(r({},e),t)),a},m=function(t){var e=o(t.components);return n.createElement(p.Provider,{value:e},t.children)},d={inlineCode:"code",wrapper:function(t){var e=t.children;return n.createElement(n.Fragment,{},e)}},k=n.forwardRef((function(t,e){var a=t.components,l=t.mdxType,s=t.originalType,p=t.parentName,m=i(t,["components","mdxType","originalType","parentName"]),k=o(a),u=l,c=k["".concat(p,".").concat(u)]||k[u]||d[u]||s;return a?n.createElement(c,r(r({ref:e},m),{},{components:a})):n.createElement(c,r({ref:e},m))}));function u(t,e){var a=arguments,l=e&&e.mdxType;if("string"==typeof t||l){var s=a.length,r=new Array(s);r[0]=k;var i={};for(var p in e)hasOwnProperty.call(e,p)&&(i[p]=e[p]);i.originalType=t,i.mdxType="string"==typeof t?t:l,r[1]=i;for(var o=2;o<s;o++)r[o]=a[o];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}k.displayName="MDXCreateElement"},8172:function(t,e,a){a.r(e),a.d(e,{frontMatter:function(){return i},contentTitle:function(){return p},metadata:function(){return o},assets:function(){return m},toc:function(){return d},default:function(){return u}});var n=a(7462),l=a(3366),s=(a(7294),a(3905)),r=["components"],i={title:"[CA]: Time Series #2 - Predicting Stock Prices (Time Series) using classical machine Learning",description:"In this post we'll look at stocks, forecasting and predictions using classical machine learning (sklearn) approaches.",slug:"timeseries-pt-2",tags:["machine-learning","timeseries","workshop"],authors:"hlondogard"},p=void 0,o={permalink:"/blog/timeseries-pt-2",editUrl:"https://github.com/londogard/londogard/blog/2022-03-12-timeseries-pt-2/index.md",source:"@site/blog/2022-03-12-timeseries-pt-2/index.md",title:"[CA]: Time Series #2 - Predicting Stock Prices (Time Series) using classical machine Learning",description:"In this post we'll look at stocks, forecasting and predictions using classical machine learning (sklearn) approaches.",date:"2022-03-12T00:00:00.000Z",formattedDate:"March 12, 2022",tags:[{label:"machine-learning",permalink:"/blog/tags/machine-learning"},{label:"timeseries",permalink:"/blog/tags/timeseries"},{label:"workshop",permalink:"/blog/tags/workshop"}],readingTime:14.865,truncated:!0,authors:[{name:"Hampus Lond\xf6g\xe5rd",title:"Main Contributor of Londogard",url:"https://github.com/lundez",imageURL:"https://github.com/lundez.png",key:"hlondogard"}],frontMatter:{title:"[CA]: Time Series #2 - Predicting Stock Prices (Time Series) using classical machine Learning",description:"In this post we'll look at stocks, forecasting and predictions using classical machine learning (sklearn) approaches.",slug:"timeseries-pt-2",tags:["machine-learning","timeseries","workshop"],authors:"hlondogard"},prevItem:{title:"[CA]: Time Series #3 - Forecasting Cryptocurrency Prices (Time Series) using Deep Learning (PyTorch, Tensorflow/Keras & darts)",permalink:"/blog/timeseries-pt-3"},nextItem:{title:"[CA]: Time Series #1 - Decomposing & Working with Time Series",permalink:"/blog/timeseries-pt-1"}},m={authorsImageUrls:[void 0]},d=[{value:"Predicting Time Series \ud83d\udcc8",id:"predicting-time-series-",children:[{value:"Installation &amp; Imports",id:"installation--imports",children:[],level:3},{value:"Minor Analysis",id:"minor-analysis",children:[],level:3},{value:"Predicting Based on historical performance",id:"predicting-based-on-historical-performance",children:[{value:"Extra Self Exercises",id:"extra-self-exercises",children:[],level:4}],level:3}],level:2}],k={toc:d};function u(t){var e=t.components,i=(0,l.Z)(t,r);return(0,s.kt)("wrapper",(0,n.Z)({},k,i,{components:e,mdxType:"MDXLayout"}),(0,s.kt)("a",{href:"https://colab.research.google.com/github/londogard/londogard/blob/master/blog/2022-03-11-timeseries-pt-2/index.ipynb",target:"_parent"},(0,s.kt)("img",{src:"https://colab.research.google.com/assets/colab-badge.svg",alt:"Open In Colab"})),(0,s.kt)("p",null,"\u26a0\ufe0fPlease be aware that ",(0,s.kt)("strong",{parentName:"p"},"this blog is much easier and nicer to read directly in ",(0,s.kt)("inlineCode",{parentName:"strong"},"Colab")," \ud83d\udc46 or through ",(0,s.kt)("a",{parentName:"strong",href:"https://github.com/londogard/londogard/blob/master/blog/2022-03-11-timeseries-pt-1/index.ipynb"},"GitHub")),"!"),(0,s.kt)("h1",{id:"ca-time-series-2---predicting-stock-prices-time-series-using-classical-machine-learning"},"[","CA","]",": Time Series #2 - Predicting Stock Prices (Time Series) using classical Machine Learning"),(0,s.kt)("p",null,(0,s.kt)("inlineCode",{parentName:"p"},"CA=Competence Afternoon")),(0,s.kt)("p",null,"To learn more about Time Series and how one can analyze them please view the other parts,"),(0,s.kt)("ol",null,(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("a",{parentName:"li",href:"timeseries-pt-1"},"Part One - Decomposing & Working with Time Series (theoretical)")),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("a",{parentName:"li",href:"timeseries-pt-2"},"Part Two - Predicting Stock Prices (Time Series) using classical Machine Learning")),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("a",{parentName:"li",href:"timeseries-pt-3"},"Part Three -Forecasting Cryptocurrency Prices (Time Series) using Deep Learning (PyTorch, Tensorflow/Keras & darts)"))),(0,s.kt)("h2",{id:"predicting-time-series-"},"Predicting Time Series \ud83d\udcc8"),(0,s.kt)("p",null,"Today we will move from learning how to analyze Time Series to actually predicting them using simple models and data."),(0,s.kt)("p",null,"We'll be predicting Stocks from the top tech companies like Apple & Google.",(0,s.kt)("br",{parentName:"p"}),"\n","In ",(0,s.kt)("a",{parentName:"p",href:"timeseries-pt-3"},"part #3")," we'll move back to the crypto world!"),(0,s.kt)("p",null,"To be able to predict the data we must understand it and we'll make a minor analysis."),(0,s.kt)("h3",{id:"installation--imports"},"Installation & Imports"),(0,s.kt)("p",null,"Feel free to ignore the cells and simply run them, the lazy style \ud83e\udd71"),(0,s.kt)("p",null,"Installing the important libraries..."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"from IPython.display import clear_output\n!pip install -U pandas_datareader\n!pip install plotly\n!pip install matplotlib==3.1.3\n\nclear_output()\n")),(0,s.kt)("p",null,"And importing them..."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np  # linear algebra\nimport pandas_datareader as pdr\nimport seaborn as sns\n\nfrom datetime import datetime\n")),(0,s.kt)("h3",{id:"minor-analysis"},"Minor Analysis"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"df = pdr.get_data_yahoo(['AAPL', 'GOOGL', 'AMZN', 'MSFT', 'GE'])\ndf.head()\n")),(0,s.kt)("div",null,(0,s.kt)("table",{border:"1",class:"dataframe"},(0,s.kt)("thead",null,(0,s.kt)("tr",null,(0,s.kt)("th",null,"Attributes"),(0,s.kt)("th",{colspan:"5",halign:"left"},"Adj Close"),(0,s.kt)("th",{colspan:"5",halign:"left"},"Close"),(0,s.kt)("th",null,"..."),(0,s.kt)("th",{colspan:"5",halign:"left"},"Open"),(0,s.kt)("th",{colspan:"5",halign:"left"},"Volume")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"Symbols"),(0,s.kt)("th",null,"AAPL"),(0,s.kt)("th",null,"GOOGL"),(0,s.kt)("th",null,"AMZN"),(0,s.kt)("th",null,"MSFT"),(0,s.kt)("th",null,"GE"),(0,s.kt)("th",null,"AAPL"),(0,s.kt)("th",null,"GOOGL"),(0,s.kt)("th",null,"AMZN"),(0,s.kt)("th",null,"MSFT"),(0,s.kt)("th",null,"GE"),(0,s.kt)("th",null,"..."),(0,s.kt)("th",null,"AAPL"),(0,s.kt)("th",null,"GOOGL"),(0,s.kt)("th",null,"AMZN"),(0,s.kt)("th",null,"MSFT"),(0,s.kt)("th",null,"GE"),(0,s.kt)("th",null,"AAPL"),(0,s.kt)("th",null,"GOOGL"),(0,s.kt)("th",null,"AMZN"),(0,s.kt)("th",null,"MSFT"),(0,s.kt)("th",null,"GE")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"Date"),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null))),(0,s.kt)("tbody",null,(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-14"),(0,s.kt)("td",null,"32.807190"),(0,s.kt)("td",null,"865.909973"),(0,s.kt)("td",null,"852.530029"),(0,s.kt)("td",null,"60.125767"),(0,s.kt)("td",null,"212.658173"),(0,s.kt)("td",null,"34.747501"),(0,s.kt)("td",null,"865.909973"),(0,s.kt)("td",null,"852.530029"),(0,s.kt)("td",null,"64.410004"),(0,s.kt)("td",null,"227.230774"),(0,s.kt)("td",null,"..."),(0,s.kt)("td",null,"34.825001"),(0,s.kt)("td",null,"863.750000"),(0,s.kt)("td",null,"853.549988"),(0,s.kt)("td",null,"64.529999"),(0,s.kt)("td",null,"228.923080"),(0,s.kt)("td",null,"61236400.0"),(0,s.kt)("td",null,"1061700.0"),(0,s.kt)("td",null,"2130600.0"),(0,s.kt)("td",null,"14280200.0"),(0,s.kt)("td",null,"2964208.0")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-15"),(0,s.kt)("td",null,"33.154175"),(0,s.kt)("td",null,"868.390015"),(0,s.kt)("td",null,"852.969971"),(0,s.kt)("td",null,"60.443142"),(0,s.kt)("td",null,"214.241959"),(0,s.kt)("td",null,"35.115002"),(0,s.kt)("td",null,"868.390015"),(0,s.kt)("td",null,"852.969971"),(0,s.kt)("td",null,"64.750000"),(0,s.kt)("td",null,"228.923080"),(0,s.kt)("td",null,"..."),(0,s.kt)("td",null,"34.852501"),(0,s.kt)("td",null,"867.940002"),(0,s.kt)("td",null,"854.330017"),(0,s.kt)("td",null,"64.550003"),(0,s.kt)("td",null,"227.307693"),(0,s.kt)("td",null,"102767200.0"),(0,s.kt)("td",null,"1332900.0"),(0,s.kt)("td",null,"2562200.0"),(0,s.kt)("td",null,"24833800.0"),(0,s.kt)("td",null,"3268564.0")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-16"),(0,s.kt)("td",null,"33.208466"),(0,s.kt)("td",null,"870.000000"),(0,s.kt)("td",null,"853.419983"),(0,s.kt)("td",null,"60.340454"),(0,s.kt)("td",null,"214.169983"),(0,s.kt)("td",null,"35.172501"),(0,s.kt)("td",null,"870.000000"),(0,s.kt)("td",null,"853.419983"),(0,s.kt)("td",null,"64.639999"),(0,s.kt)("td",null,"228.846161"),(0,s.kt)("td",null,"..."),(0,s.kt)("td",null,"35.180000"),(0,s.kt)("td",null,"870.530029"),(0,s.kt)("td",null,"855.299988"),(0,s.kt)("td",null,"64.750000"),(0,s.kt)("td",null,"229.230774"),(0,s.kt)("td",null,"76928000.0"),(0,s.kt)("td",null,"1104500.0"),(0,s.kt)("td",null,"1842300.0"),(0,s.kt)("td",null,"20674300.0"),(0,s.kt)("td",null,"2756910.0")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-17"),(0,s.kt)("td",null,"33.043240"),(0,s.kt)("td",null,"872.369995"),(0,s.kt)("td",null,"852.309998"),(0,s.kt)("td",null,"60.555153"),(0,s.kt)("td",null,"215.105835"),(0,s.kt)("td",null,"34.997501"),(0,s.kt)("td",null,"872.369995"),(0,s.kt)("td",null,"852.309998"),(0,s.kt)("td",null,"64.870003"),(0,s.kt)("td",null,"229.846161"),(0,s.kt)("td",null,"..."),(0,s.kt)("td",null,"35.250000"),(0,s.kt)("td",null,"873.679993"),(0,s.kt)("td",null,"853.489990"),(0,s.kt)("td",null,"64.910004"),(0,s.kt)("td",null,"229.615387"),(0,s.kt)("td",null,"175540000.0"),(0,s.kt)("td",null,"1868300.0"),(0,s.kt)("td",null,"3384400.0"),(0,s.kt)("td",null,"49219700.0"),(0,s.kt)("td",null,"5673070.0")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-20"),(0,s.kt)("td",null,"33.390213"),(0,s.kt)("td",null,"867.909973"),(0,s.kt)("td",null,"856.969971"),(0,s.kt)("td",null,"60.611160"),(0,s.kt)("td",null,"214.097946"),(0,s.kt)("td",null,"35.365002"),(0,s.kt)("td",null,"867.909973"),(0,s.kt)("td",null,"856.969971"),(0,s.kt)("td",null,"64.930000"),(0,s.kt)("td",null,"228.769226"),(0,s.kt)("td",null,"..."),(0,s.kt)("td",null,"35.099998"),(0,s.kt)("td",null,"869.479980"),(0,s.kt)("td",null,"851.510010"),(0,s.kt)("td",null,"64.910004"),(0,s.kt)("td",null,"230.000000"),(0,s.kt)("td",null,"86168000.0"),(0,s.kt)("td",null,"1542200.0"),(0,s.kt)("td",null,"2282700.0"),(0,s.kt)("td",null,"14598100.0"),(0,s.kt)("td",null,"2454062.0")))),(0,s.kt)("p",null,"5 rows \xd7 30 columns")),(0,s.kt)("p",null,"Looks fine, but how much data did we download?",(0,s.kt)("br",{parentName:"p"}),"\n","We can view the ",(0,s.kt)("inlineCode",{parentName:"p"},".index")," which is a ",(0,s.kt)("inlineCode",{parentName:"p"},"DateTimeIndex")," and figure out how it stretches."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"df.index[0],df.index[-1]\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"(Timestamp('2017-03-14 00:00:00'), Timestamp('2022-03-11 00:00:00'))\n")),(0,s.kt)("p",null,"Hmm, 5 years, that should be enough to find some kind of patterns.",(0,s.kt)("br",{parentName:"p"}),"\n","Now let us analyze this data further by looking at if the stocks correlate somehow! \ud83e\udd20"),(0,s.kt)("blockquote",null,(0,s.kt)("p",{parentName:"blockquote"},(0,s.kt)("strong",{parentName:"p"},"N.B.")," this analysis was first done by Heidi Mach, it's something I would never have done myself. Really cool results incoming!")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"df['Adj Close'].corr().style.background_gradient(cmap=\"Blues\")\n")),(0,s.kt)("table",{id:"T_ad2a9_"},(0,s.kt)("thead",null,(0,s.kt)("tr",null,(0,s.kt)("th",{class:"index_name level0"},"Symbols"),(0,s.kt)("th",{class:"col_heading level0 col0"},"AAPL"),(0,s.kt)("th",{class:"col_heading level0 col1"},"GOOGL"),(0,s.kt)("th",{class:"col_heading level0 col2"},"AMZN"),(0,s.kt)("th",{class:"col_heading level0 col3"},"MSFT"),(0,s.kt)("th",{class:"col_heading level0 col4"},"GE")),(0,s.kt)("tr",null,(0,s.kt)("th",{class:"index_name level0"},"Symbols"),(0,s.kt)("th",{class:"blank col0"},"\xa0"),(0,s.kt)("th",{class:"blank col1"},"\xa0"),(0,s.kt)("th",{class:"blank col2"},"\xa0"),(0,s.kt)("th",{class:"blank col3"},"\xa0"),(0,s.kt)("th",{class:"blank col4"},"\xa0"))),(0,s.kt)("tbody",null,(0,s.kt)("tr",null,(0,s.kt)("th",{id:"T_ad2a9_level0_row0",class:"row_heading level0 row0"},"AAPL"),(0,s.kt)("td",{id:"T_ad2a9_row0_col0",class:"data row0 col0"},"1.000000"),(0,s.kt)("td",{id:"T_ad2a9_row0_col1",class:"data row0 col1"},"0.951564"),(0,s.kt)("td",{id:"T_ad2a9_row0_col2",class:"data row0 col2"},"0.934927"),(0,s.kt)("td",{id:"T_ad2a9_row0_col3",class:"data row0 col3"},"0.978283"),(0,s.kt)("td",{id:"T_ad2a9_row0_col4",class:"data row0 col4"},"-0.282471")),(0,s.kt)("tr",null,(0,s.kt)("th",{id:"T_ad2a9_level0_row1",class:"row_heading level0 row1"},"GOOGL"),(0,s.kt)("td",{id:"T_ad2a9_row1_col0",class:"data row1 col0"},"0.951564"),(0,s.kt)("td",{id:"T_ad2a9_row1_col1",class:"data row1 col1"},"1.000000"),(0,s.kt)("td",{id:"T_ad2a9_row1_col2",class:"data row1 col2"},"0.866374"),(0,s.kt)("td",{id:"T_ad2a9_row1_col3",class:"data row1 col3"},"0.960317"),(0,s.kt)("td",{id:"T_ad2a9_row1_col4",class:"data row1 col4"},"-0.191266")),(0,s.kt)("tr",null,(0,s.kt)("th",{id:"T_ad2a9_level0_row2",class:"row_heading level0 row2"},"AMZN"),(0,s.kt)("td",{id:"T_ad2a9_row2_col0",class:"data row2 col0"},"0.934927"),(0,s.kt)("td",{id:"T_ad2a9_row2_col1",class:"data row2 col1"},"0.866374"),(0,s.kt)("td",{id:"T_ad2a9_row2_col2",class:"data row2 col2"},"1.000000"),(0,s.kt)("td",{id:"T_ad2a9_row2_col3",class:"data row2 col3"},"0.944168"),(0,s.kt)("td",{id:"T_ad2a9_row2_col4",class:"data row2 col4"},"-0.498395")),(0,s.kt)("tr",null,(0,s.kt)("th",{id:"T_ad2a9_level0_row3",class:"row_heading level0 row3"},"MSFT"),(0,s.kt)("td",{id:"T_ad2a9_row3_col0",class:"data row3 col0"},"0.978283"),(0,s.kt)("td",{id:"T_ad2a9_row3_col1",class:"data row3 col1"},"0.960317"),(0,s.kt)("td",{id:"T_ad2a9_row3_col2",class:"data row3 col2"},"0.944168"),(0,s.kt)("td",{id:"T_ad2a9_row3_col3",class:"data row3 col3"},"1.000000"),(0,s.kt)("td",{id:"T_ad2a9_row3_col4",class:"data row3 col4"},"-0.373495")),(0,s.kt)("tr",null,(0,s.kt)("th",{id:"T_ad2a9_level0_row4",class:"row_heading level0 row4"},"GE"),(0,s.kt)("td",{id:"T_ad2a9_row4_col0",class:"data row4 col0"},"-0.282471"),(0,s.kt)("td",{id:"T_ad2a9_row4_col1",class:"data row4 col1"},"-0.191266"),(0,s.kt)("td",{id:"T_ad2a9_row4_col2",class:"data row4 col2"},"-0.498395"),(0,s.kt)("td",{id:"T_ad2a9_row4_col3",class:"data row4 col3"},"-0.373495"),(0,s.kt)("td",{id:"T_ad2a9_row4_col4",class:"data row4 col4"},"1.000000")))),(0,s.kt)("p",null,"Holy macaron, that's a lot more correlated data than I expected! \ud83d\ude40  "),(0,s.kt)("p",null,"The ",(0,s.kt)("inlineCode",{parentName:"p"},"seaborn")," library has a function called ",(0,s.kt)("inlineCode",{parentName:"p"},"pairplot")," which plots this correlation, but using the points which is visually interesting in comparison to simply seeing the table above."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"df = df['Adj Close']\ndf = df.drop(columns=\"GE\")\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"sns.pairplot(df.drop_duplicates())\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"<seaborn.axisgrid.PairGrid at 0x7f1fbb4ef650>\n")),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"png",src:a(6157).Z,width:"709",height:"709"})),(0,s.kt)("p",null,"Does this in fact mean what that we can predict prices of a stock based on their competition? The correlation does suggest so."),(0,s.kt)("p",null,"Let's try it!"),(0,s.kt)("p",null,"First we'll try using a ",(0,s.kt)("inlineCode",{parentName:"p"},"LinearRegression")," which simply said fits a line to be as close to all points as possible."),(0,s.kt)("p",null,(0,s.kt)("img",{parentName:"p",src:"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/600px-Linear_regression.svg.png",alt:"linear regression wikipedia"})),(0,s.kt)("blockquote",null,(0,s.kt)("p",{parentName:"blockquote"},"Source: Wikipedia.org")),(0,s.kt)("p",null,"First we import ",(0,s.kt)("inlineCode",{parentName:"p"},"LinearRegression")," through ",(0,s.kt)("inlineCode",{parentName:"p"},"scikit-learn")," and then we add ",(0,s.kt)("inlineCode",{parentName:"p"},"train_test_split")," which allows us to split our data into a training and testing dataset."),(0,s.kt)("p",null,"Whenever you test your Machine Learning or Deep Learning Models you never want to test it on data that it has trained on, as you might've overfitted the data and have a really good result until you see new data points."),(0,s.kt)("p",null,"The end-goal of a model is to generalize a problem and find the local minima which optimizes the funtion for the data points. By only looking at the same data we can't be sure we generalized correctly."),(0,s.kt)("p",null,"And the code \ud83d\udc69\u200d\ud83d\udcbb"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_absolute_error\n\nnon_google_df = df.drop(columns=\"GOOGL\")\nX_train, X_valid, y_train, y_valid = train_test_split(non_google_df, df['GOOGL'], test_size=0.2)\n\nclf = LinearRegression()\n")),(0,s.kt)("p",null,"We got our data divided into ",(0,s.kt)("inlineCode",{parentName:"p"},"valid")," and ",(0,s.kt)("inlineCode",{parentName:"p"},"train"),", we got a regression model in our ",(0,s.kt)("inlineCode",{parentName:"p"},"clf"),"."),(0,s.kt)("p",null,"Let us predict the data and view our ",(0,s.kt)("inlineCode",{parentName:"p"},"r2_score")," and ",(0,s.kt)("inlineCode",{parentName:"p"},"mean_absolute_error"),"."),(0,s.kt)("blockquote",null,(0,s.kt)("p",{parentName:"blockquote"},"\ud83d\udca1",(0,s.kt)("br",{parentName:"p"}),"\n",(0,s.kt)("strong",{parentName:"p"},"r2_score:"),"  ",(0,s.kt)("em",{parentName:"p"},"(coefficient of determination) regression score function."),(0,s.kt)("br",{parentName:"p"}),"\n","Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a  score of 0.0."),(0,s.kt)("p",{parentName:"blockquote"},(0,s.kt)("strong",{parentName:"p"},"mean_absolute_error:")," ",(0,s.kt)("em",{parentName:"p"},"Mean absolute error regression loss."))),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"clf.fit(X_train, y_train)\npreds = clf.predict(X_valid)\n\nr2_score(y_valid, preds), mean_absolute_error(y_valid, preds)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"(0.9431732611282428, 130.75344061010207)\n")),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},(0,s.kt)("span",{parentName:"strong",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msup",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msup"},"R"),(0,s.kt)("mn",{parentName:"msup"},"2")),(0,s.kt)("mo",{parentName:"mrow"},"="),(0,s.kt)("mn",{parentName:"mrow"},"93"),(0,s.kt)("mi",{parentName:"mrow",mathvariant:"normal"},"%")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"R^2 = 93 \\%")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8141em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.00773em"}},"R"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.8141em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-3.063em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},"2")))))))),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}}),(0,s.kt)("span",{parentName:"span",className:"mrel"},"="),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}})),(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8056em",verticalAlign:"-0.0556em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"93%"))))))," \ud83e\udd73"),(0,s.kt)("p",null,"That's actually not bad at all, the ",(0,s.kt)("inlineCode",{parentName:"p"},"mean_absolute_error")," being 129.7 is not very telling. Either we have to view the data to understand the magnituide, or we can apply ",(0,s.kt)("inlineCode",{parentName:"p"},"MAPE")," which is the ",(0,s.kt)("em",{parentName:"p"},"Mean Absolute Percentage Error"),".  "),(0,s.kt)("p",null,"Not sure if I'm lazy or simply want to show you the other function \ud83e\udd14, but I'll use ",(0,s.kt)("inlineCode",{parentName:"p"},"MAPE"),"!"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"from sklearn.metrics import mean_absolute_percentage_error\n\nmean_absolute_percentage_error(y_valid, preds)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"0.0854923639443305\n")),(0,s.kt)("p",null,(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mo",{parentName:"mrow"},"<"),(0,s.kt)("mn",{parentName:"mrow"},"9"),(0,s.kt)("mi",{parentName:"mrow",mathvariant:"normal"},"%")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"< 9\\%")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.5782em",verticalAlign:"-0.0391em"}}),(0,s.kt)("span",{parentName:"span",className:"mrel"},"<"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}})),(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8056em",verticalAlign:"-0.0556em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"9%"))))),(0,s.kt)("br",{parentName:"p"}),"\n","Pretty acceptable considering we have not done anything except deliver data to one of the simplest models that exists!  "),(0,s.kt)("p",null,"Let's show this visually!"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"import plotly.express as px\n\n# px.line(y=[y_valid, preds])\n")),(0,s.kt)("details",null,(0,s.kt)("summary",null,"Show Plotly Chart (code cell only visible in active notebook)"),(0,s.kt)("img",{src:"simple-preds.png"})),(0,s.kt)("p",null,"Looks pretty good, but it is very messy... Something is off right?"),(0,s.kt)("p",null,"The index is not a ",(0,s.kt)("inlineCode",{parentName:"p"},"DateTimeIndex")," anymore because we shuffled the data in ",(0,s.kt)("inlineCode",{parentName:"p"},"train_test_split")," -- a big difference is thereby applied."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"y_valid.plot()\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"<matplotlib.axes._subplots.AxesSubplot at 0x7f1fb5e5f310>\n")),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"png",src:a(1153).Z,width:"381",height:"252"})),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'y_valid.plot(legend="Valid")\npd.Series(preds, index=y_valid.index).plot(legend="Pred")\n')),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"<matplotlib.axes._subplots.AxesSubplot at 0x7f1fb5dd5190>\n")),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"png",src:a(6786).Z,width:"381",height:"252"})),(0,s.kt)("p",null,"Looks pretty fly, but can we take it further?",(0,s.kt)("br",{parentName:"p"}),"\n","...yes we can! \ud83d\ude0e"),(0,s.kt)("p",null,"I see a few options, the two first being:"),(0,s.kt)("ol",null,(0,s.kt)("li",{parentName:"ol"},"Scaling the data as errors at the end are larger than in the beggining based on stocks rising."),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("inlineCode",{parentName:"li"},"LinearRegression")," is a very simple yet efficient model that we can try to replace.")),(0,s.kt)("p",null,"Let's start with the second point, ",(0,s.kt)("inlineCode",{parentName:"p"},"scikit-learn")," has a multitude of regression-models, one being ",(0,s.kt)("inlineCode",{parentName:"p"},"RandomForestRegressor")," that's pretty strong."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"from sklearn.ensemble import RandomForestRegressor\n\nclf = RandomForestRegressor()\nclf.fit(X_train, y_train)\n\npreds = clf.predict(X_valid)\nr2_score(y_valid, preds), mean_absolute_percentage_error(y_valid, preds)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"(0.9971090451830482, 0.015725346089653435)\n")),(0,s.kt)("p",null,"\ud83d\ude32",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msup",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msup"},"R"),(0,s.kt)("mn",{parentName:"msup"},"2")),(0,s.kt)("mo",{parentName:"mrow"},">"),(0,s.kt)("mn",{parentName:"mrow"},"99"),(0,s.kt)("mi",{parentName:"mrow",mathvariant:"normal"},"%")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"R^2 >99\\%")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8532em",verticalAlign:"-0.0391em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.00773em"}},"R"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.8141em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-3.063em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},"2")))))))),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}}),(0,s.kt)("span",{parentName:"span",className:"mrel"},">"),(0,s.kt)("span",{parentName:"span",className:"mspace",style:{marginRight:"0.2778em"}})),(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8056em",verticalAlign:"-0.0556em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"99%")))))),(0,s.kt)("p",null,"That's actually crazy. And ",(0,s.kt)("inlineCode",{parentName:"p"},"MAPE")," is not even 2%."),(0,s.kt)("p",null,"Let's view it!"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'y_valid.plot(legend="Valid")\npd.Series(preds, index=y_valid.index).plot(legend="Pred")\n')),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"<matplotlib.axes._subplots.AxesSubplot at 0x7f1fcaeacad0>\n")),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"png",src:a(8767).Z,width:"381",height:"252"})),(0,s.kt)("p",null,"That's an incredibly fitted curve."),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"How is this possible?"),"  "),(0,s.kt)("ol",null,(0,s.kt)("li",{parentName:"ol"},"We most likely overfit the data.  "),(0,s.kt)("li",{parentName:"ol"},"We are looking at ",(0,s.kt)("inlineCode",{parentName:"li"},"AMZN"),", ",(0,s.kt)("inlineCode",{parentName:"li"},"AAPL")," and more data that is highly correlated during the ",(0,s.kt)("strong",{parentName:"li"},"same")," day as the one we wish to predict. ")),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"In the end this is a ",(0,s.kt)("strong",{parentName:"li"},"useless task"),", if we know the prices of today we'd also know ",(0,s.kt)("inlineCode",{parentName:"li"},"GOOGL"),"'s prices!")),(0,s.kt)("ol",{start:3},(0,s.kt)("li",{parentName:"ol"},"We're using shuffled data, meaning that in a way we've seen the future and past values surrounding the predicted one. This is a regression problem and not really a forecasting problem, which is simpler than forecasting.")),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"Impressive nontheless"),(0,s.kt)("br",{parentName:"p"}),"\n","Even as I'm aware of all the drawbacks I'm thouroughly impresed by the results we're seeing.  "),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"Making it more interesting"),(0,s.kt)("br",{parentName:"p"}),"\n",'We should make use of the previous days data to make sure we are not "cheating".'),(0,s.kt)("p",null,"Let's get on it! \ud83c\udfaf"),(0,s.kt)("hr",null),(0,s.kt)("p",null,"We'll be able to move, or ",(0,s.kt)("em",{parentName:"p"},"shift"),", the data using \u02cbpd.DataFrame.shift\u02cb which shifts the data either forwad (",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mo",{parentName:"mrow"},"+"),(0,s.kt)("mi",{parentName:"mrow"},"X")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"+X")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.7667em",verticalAlign:"-0.0833em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"+"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.07847em"}},"X"))))),") or backwards (",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("mo",{parentName:"mrow"},"\u2212"),(0,s.kt)("mi",{parentName:"mrow"},"X")),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"-X")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.7667em",verticalAlign:"-0.0833em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},"\u2212"),(0,s.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.07847em"}},"X"))))),")."),(0,s.kt)("p",null,"And while we're at it, let's group this up into a function."),(0,s.kt)("blockquote",null,(0,s.kt)("p",{parentName:"blockquote"},"\u2139\ufe0f",(0,s.kt)("br",{parentName:"p"}),"\n",(0,s.kt)("a",{parentName:"p",href:"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html"},(0,s.kt)("inlineCode",{parentName:"a"},"pd.DataFrame.shift")),": ",(0,s.kt)("em",{parentName:"p"},"Shift index by desired number of periods with an optional time freq."),"  ")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'def fit_validate_plot(X_train, X_valid, y_train, y_valid):\n  clf = RandomForestRegressor()\n  clf.fit(X_train, y_train)\n\n  preds = clf.predict(X_valid)\n  pd.DataFrame({\'Valid\': y_valid, \'Preds\': preds}, index=y_valid.index).plot()\n  \n  print(f"""\n  $R^2$: {r2_score(y_valid, preds)}\n  MAPE: {mean_absolute_percentage_error(y_valid, preds)}\n  MAE: {mean_absolute_error(y_valid, preds)}\n  """)\n')),(0,s.kt)("p",null,"And making use of it will now be easy! \ud83d\ude0d",(0,s.kt)("br",{parentName:"p"}),"\n",(0,s.kt)("em",{parentName:"p"},"Refactoring")," and ",(0,s.kt)("em",{parentName:"p"},"abstractions")," are incredibly important."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"X_train, X_valid, y_train, y_valid = train_test_split(df.drop(columns=\"GOOGL\").shift(1).iloc[1:], df['GOOGL'].iloc[1:], test_size=0.2)\n\nfit_validate_plot(X_train, X_valid, y_train, y_valid)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"  $R^2$: 0.9948464033958241\n  MAPE: 0.019439064157954267\n  MAE: 29.527943362281434\n  \n")),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"png",src:a(6367).Z,width:"381",height:"252"})),(0,s.kt)("p",null,"\ud83e\udd2f this is crazy impressive!"),(0,s.kt)("p",null,"We made the task at hands legit by only using historical data of ",(0,s.kt)("inlineCode",{parentName:"p"},"GOOGL"),"'s competitors. The ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msup",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msup"},"R"),(0,s.kt)("mn",{parentName:"msup"},"2"))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"R^2")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.8141em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal",style:{marginRight:"0.00773em"}},"R"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.8141em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-3.063em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},"2")))))))))))),"  and ",(0,s.kt)("inlineCode",{parentName:"p"},"MAPE")," is incredible.  "),(0,s.kt)("p",null,"It'd be interesting to investigate how badly we overfit the data, but that's for another day."),(0,s.kt)("p",null,"And how about if we ",(0,s.kt)("strong",{parentName:"p"},"don't")," shuffle the data? E.g. we do an actual forecast and not regression!"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"X_train, X_valid, y_train, y_valid = train_test_split(df.drop(columns=\"GOOGL\").shift(1).iloc[1:], df['GOOGL'].iloc[1:], test_size=0.2, shuffle=False)\n\nfit_validate_plot(X_train, X_valid, y_train, y_valid)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"  $R^2$: -7.02034763602467\n  MAPE: 0.24152517366886156\n  MAE: 660.6506098187159\n  \n")),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"png",src:a(4946).Z,width:"387",height:"260"})),(0,s.kt)("p",null,"\ud83e\udd2f\ud83d\ude2d"),(0,s.kt)("p",null,"What are we seeing and why?",(0,s.kt)("br",{parentName:"p"}),"\n",(0,s.kt)("strong",{parentName:"p"},"Regression")," algorithms/models try to fit a line to multiple points and it should be able to guess what point the data has depending on its features. In our case the regression algorithm has never seen data as high as above ",(0,s.kt)("inlineCode",{parentName:"p"},"y_train.max()"),", which means it can't guess the data."),(0,s.kt)("p",null,"Don't trust me? Simply validate by looking at the chart \ud83d\udc46."),(0,s.kt)("p",null,(0,s.kt)("img",{parentName:"p",src:"https://kagi.com/proxy/giphy.gif?c=tZl8lX5nYA-SXtLOSzNn-ptLUKm5FsSjvUOEfgN1REnlyKe27jFR0yp0jV69mnJIn7oABzGenQdoyNvQVaofhM7A_zXGa3_FEeM5n85RocE%3D",alt:null})),(0,s.kt)("p",null,"What's one way to fix this? ",(0,s.kt)("strong",{parentName:"p"},"Scaling"),(0,s.kt)("br",{parentName:"p"}),"\n","How will we try to achieve this practically? ",(0,s.kt)("strong",{parentName:"p"},"LogReturn")),(0,s.kt)("blockquote",null,(0,s.kt)("p",{parentName:"blockquote"},"\ud83d\udca1\nYou can also take the %-difference, which according to Taylors Theorem will approximate the LogReturn.")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"def log_return(x: pd.DataFrame) -> pd.DataFrame:\n  return x.apply(lambda x: np.log(x/x.shift(1))).dropna()\n\nlog_return(df).head()\n")),(0,s.kt)("div",null,(0,s.kt)("table",{border:"1",class:"dataframe"},(0,s.kt)("thead",null,(0,s.kt)("tr",null,(0,s.kt)("th",null,"Symbols"),(0,s.kt)("th",null,"AAPL"),(0,s.kt)("th",null,"GOOGL"),(0,s.kt)("th",null,"AMZN"),(0,s.kt)("th",null,"MSFT")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"Date"),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null))),(0,s.kt)("tbody",null,(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-15"),(0,s.kt)("td",null,"0.010521"),(0,s.kt)("td",null,"0.002860"),(0,s.kt)("td",null,"0.000516"),(0,s.kt)("td",null,"0.005265")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-16"),(0,s.kt)("td",null,"0.001636"),(0,s.kt)("td",null,"0.001852"),(0,s.kt)("td",null,"0.000527"),(0,s.kt)("td",null,"-0.001700")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-17"),(0,s.kt)("td",null,"-0.004988"),(0,s.kt)("td",null,"0.002720"),(0,s.kt)("td",null,"-0.001301"),(0,s.kt)("td",null,"0.003552")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-20"),(0,s.kt)("td",null,"0.010446"),(0,s.kt)("td",null,"-0.005126"),(0,s.kt)("td",null,"0.005453"),(0,s.kt)("td",null,"0.000924")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-21"),(0,s.kt)("td",null,"-0.011518"),(0,s.kt)("td",null,"-0.020687"),(0,s.kt)("td",null,"-0.016199"),(0,s.kt)("td",null,"-0.011151"))))),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"df_lr = log_return(df)\nX_train, X_valid, y_train, y_valid = train_test_split(df_lr.drop(columns=\"GOOGL\").shift(1).iloc[1:], df_lr['GOOGL'].iloc[1:], test_size=0.2, shuffle=False)\n\nfit_validate_plot(X_train, X_valid, y_train, y_valid)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"  $R^2$: -0.15979886803424925\n  MAPE: 33272784735.11796\n  MAE: 0.01244440133653395\n  \n")),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"png",src:a(6350).Z,width:"387",height:"260"})),(0,s.kt)("p",null,"Most certainly ",(0,s.kt)("strong",{parentName:"p"},"not")," perfect... Forecasting seems harder than expected based on our initial results...",(0,s.kt)("br",{parentName:"p"}),"\n","And that's really because we weren't forecasting before, we were solving a ",(0,s.kt)("em",{parentName:"p"},"regression-problem")),(0,s.kt)("p",null,"Perhaps we need to use more data than simply the previous day?"),(0,s.kt)("h3",{id:"predicting-based-on-historical-performance"},"Predicting Based on historical performance"),(0,s.kt)("p",null,"We might predict based on historical performance."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"df.head()\n")),(0,s.kt)("div",null,(0,s.kt)("table",{border:"1",class:"dataframe"},(0,s.kt)("thead",null,(0,s.kt)("tr",null,(0,s.kt)("th",null,"Symbols"),(0,s.kt)("th",null,"AAPL"),(0,s.kt)("th",null,"GOOGL"),(0,s.kt)("th",null,"AMZN"),(0,s.kt)("th",null,"MSFT")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"Date"),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null))),(0,s.kt)("tbody",null,(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-14"),(0,s.kt)("td",null,"32.807190"),(0,s.kt)("td",null,"865.909973"),(0,s.kt)("td",null,"852.530029"),(0,s.kt)("td",null,"60.125767")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-15"),(0,s.kt)("td",null,"33.154175"),(0,s.kt)("td",null,"868.390015"),(0,s.kt)("td",null,"852.969971"),(0,s.kt)("td",null,"60.443142")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-16"),(0,s.kt)("td",null,"33.208466"),(0,s.kt)("td",null,"870.000000"),(0,s.kt)("td",null,"853.419983"),(0,s.kt)("td",null,"60.340454")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-17"),(0,s.kt)("td",null,"33.043240"),(0,s.kt)("td",null,"872.369995"),(0,s.kt)("td",null,"852.309998"),(0,s.kt)("td",null,"60.555153")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-20"),(0,s.kt)("td",null,"33.390213"),(0,s.kt)("td",null,"867.909973"),(0,s.kt)("td",null,"856.969971"),(0,s.kt)("td",null,"60.611160"))))),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"df = df[['GOOGL']]\ndf.head()\n")),(0,s.kt)("div",null,(0,s.kt)("table",{border:"1",class:"dataframe"},(0,s.kt)("thead",null,(0,s.kt)("tr",null,(0,s.kt)("th",null,"Symbols"),(0,s.kt)("th",null,"GOOGL")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"Date"),(0,s.kt)("th",null))),(0,s.kt)("tbody",null,(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-14"),(0,s.kt)("td",null,"865.909973")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-15"),(0,s.kt)("td",null,"868.390015")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-16"),(0,s.kt)("td",null,"870.000000")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-17"),(0,s.kt)("td",null,"872.369995")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-20"),(0,s.kt)("td",null,"867.909973"))))),(0,s.kt)("p",null,"\u2705 Only Google Data",(0,s.kt)("br",{parentName:"p"}),"\n","\u274c Historical Data"),(0,s.kt)("p",null,"So what should we do? One way to solve this is to use ",(0,s.kt)("inlineCode",{parentName:"p"},"shift")," multiple times."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"def build_history(df: pd.DataFrame, num_back: int) -> pd.DataFrame:\n  for i in range(num_back):\n    df.loc[:, f\"t_{i}\"] = df['GOOGL'].shift(i + 1)\n  \n  return df\n\nbuild_history(df, 3).head()\n")),(0,s.kt)("div",null,(0,s.kt)("table",{border:"1",class:"dataframe"},(0,s.kt)("thead",null,(0,s.kt)("tr",null,(0,s.kt)("th",null,"Symbols"),(0,s.kt)("th",null,"GOOGL"),(0,s.kt)("th",null,"t_0"),(0,s.kt)("th",null,"t_1"),(0,s.kt)("th",null,"t_2")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"Date"),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null))),(0,s.kt)("tbody",null,(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-14"),(0,s.kt)("td",null,"865.909973"),(0,s.kt)("td",null,"NaN"),(0,s.kt)("td",null,"NaN"),(0,s.kt)("td",null,"NaN")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-15"),(0,s.kt)("td",null,"868.390015"),(0,s.kt)("td",null,"865.909973"),(0,s.kt)("td",null,"NaN"),(0,s.kt)("td",null,"NaN")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-16"),(0,s.kt)("td",null,"870.000000"),(0,s.kt)("td",null,"868.390015"),(0,s.kt)("td",null,"865.909973"),(0,s.kt)("td",null,"NaN")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-17"),(0,s.kt)("td",null,"872.369995"),(0,s.kt)("td",null,"870.000000"),(0,s.kt)("td",null,"868.390015"),(0,s.kt)("td",null,"865.909973")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-20"),(0,s.kt)("td",null,"867.909973"),(0,s.kt)("td",null,"872.369995"),(0,s.kt)("td",null,"870.000000"),(0,s.kt)("td",null,"868.390015"))))),(0,s.kt)("p",null,"Notice how ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"t"),(0,s.kt)("mn",{parentName:"msub"},"0"))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"t_0")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.7651em",verticalAlign:"-0.15em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"t"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3011em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},"0")))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"}))))))))))," is the previous value, ",(0,s.kt)("span",{parentName:"p",className:"math math-inline"},(0,s.kt)("span",{parentName:"span",className:"katex"},(0,s.kt)("span",{parentName:"span",className:"katex-mathml"},(0,s.kt)("math",{parentName:"span",xmlns:"http://www.w3.org/1998/Math/MathML"},(0,s.kt)("semantics",{parentName:"math"},(0,s.kt)("mrow",{parentName:"semantics"},(0,s.kt)("msub",{parentName:"mrow"},(0,s.kt)("mi",{parentName:"msub"},"t"),(0,s.kt)("mn",{parentName:"msub"},"1"))),(0,s.kt)("annotation",{parentName:"semantics",encoding:"application/x-tex"},"t_1")))),(0,s.kt)("span",{parentName:"span",className:"katex-html","aria-hidden":"true"},(0,s.kt)("span",{parentName:"span",className:"base"},(0,s.kt)("span",{parentName:"span",className:"strut",style:{height:"0.7651em",verticalAlign:"-0.15em"}}),(0,s.kt)("span",{parentName:"span",className:"mord"},(0,s.kt)("span",{parentName:"span",className:"mord mathnormal"},"t"),(0,s.kt)("span",{parentName:"span",className:"msupsub"},(0,s.kt)("span",{parentName:"span",className:"vlist-t vlist-t2"},(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.3011em"}},(0,s.kt)("span",{parentName:"span",style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"}},(0,s.kt)("span",{parentName:"span",className:"pstrut",style:{height:"2.7em"}}),(0,s.kt)("span",{parentName:"span",className:"sizing reset-size6 size3 mtight"},(0,s.kt)("span",{parentName:"span",className:"mord mtight"},"1")))),(0,s.kt)("span",{parentName:"span",className:"vlist-s"},"\u200b")),(0,s.kt)("span",{parentName:"span",className:"vlist-r"},(0,s.kt)("span",{parentName:"span",className:"vlist",style:{height:"0.15em"}},(0,s.kt)("span",{parentName:"span"}))))))))))," two steps back, and so on.",(0,s.kt)("br",{parentName:"p"}),"\n","This is actually ",(0,s.kt)("em",{parentName:"p"},"very")," memory intense as our data grows X times, one time per time step we build. In ",(0,s.kt)("a",{parentName:"p",href:"timeseries-pt-3"},"part #3")," we'll go through how one can solve this issue."),(0,s.kt)("p",null,"No we need to drop all places where we don't have any history. That is easily achieved by dropping ",(0,s.kt)("inlineCode",{parentName:"p"},"NaN"),"."),(0,s.kt)("blockquote",null,(0,s.kt)("p",{parentName:"blockquote"},"\u2139\ufe0f",(0,s.kt)("br",{parentName:"p"}),"\n",(0,s.kt)("a",{parentName:"p",href:"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html"},(0,s.kt)("inlineCode",{parentName:"a"},"pd.DataFrame.dropna")),": ",(0,s.kt)("em",{parentName:"p"},"Remove missing values."),(0,s.kt)("br",{parentName:"p"}),"\n",(0,s.kt)("inlineCode",{parentName:"p"},"axis")," attribute tells if you wish to drop rows or columns based on ",(0,s.kt)("inlineCode",{parentName:"p"},"NaN"),", default is row.")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"df = build_history(df, 7)\ndf = df.dropna()\ndf.head()\n")),(0,s.kt)("div",null,(0,s.kt)("table",{border:"1",class:"dataframe"},(0,s.kt)("thead",null,(0,s.kt)("tr",null,(0,s.kt)("th",null,"Symbols"),(0,s.kt)("th",null,"GOOGL"),(0,s.kt)("th",null,"t_0"),(0,s.kt)("th",null,"t_1"),(0,s.kt)("th",null,"t_2"),(0,s.kt)("th",null,"t_3"),(0,s.kt)("th",null,"t_4"),(0,s.kt)("th",null,"t_5"),(0,s.kt)("th",null,"t_6")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"Date"),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null),(0,s.kt)("th",null))),(0,s.kt)("tbody",null,(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-23"),(0,s.kt)("td",null,"839.650024"),(0,s.kt)("td",null,"849.799988"),(0,s.kt)("td",null,"850.140015"),(0,s.kt)("td",null,"867.909973"),(0,s.kt)("td",null,"872.369995"),(0,s.kt)("td",null,"870.000000"),(0,s.kt)("td",null,"868.390015"),(0,s.kt)("td",null,"865.909973")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-24"),(0,s.kt)("td",null,"835.140015"),(0,s.kt)("td",null,"839.650024"),(0,s.kt)("td",null,"849.799988"),(0,s.kt)("td",null,"850.140015"),(0,s.kt)("td",null,"867.909973"),(0,s.kt)("td",null,"872.369995"),(0,s.kt)("td",null,"870.000000"),(0,s.kt)("td",null,"868.390015")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-27"),(0,s.kt)("td",null,"838.510010"),(0,s.kt)("td",null,"835.140015"),(0,s.kt)("td",null,"839.650024"),(0,s.kt)("td",null,"849.799988"),(0,s.kt)("td",null,"850.140015"),(0,s.kt)("td",null,"867.909973"),(0,s.kt)("td",null,"872.369995"),(0,s.kt)("td",null,"870.000000")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-28"),(0,s.kt)("td",null,"840.630005"),(0,s.kt)("td",null,"838.510010"),(0,s.kt)("td",null,"835.140015"),(0,s.kt)("td",null,"839.650024"),(0,s.kt)("td",null,"849.799988"),(0,s.kt)("td",null,"850.140015"),(0,s.kt)("td",null,"867.909973"),(0,s.kt)("td",null,"872.369995")),(0,s.kt)("tr",null,(0,s.kt)("th",null,"2017-03-29"),(0,s.kt)("td",null,"849.869995"),(0,s.kt)("td",null,"840.630005"),(0,s.kt)("td",null,"838.510010"),(0,s.kt)("td",null,"835.140015"),(0,s.kt)("td",null,"839.650024"),(0,s.kt)("td",null,"849.799988"),(0,s.kt)("td",null,"850.140015"),(0,s.kt)("td",null,"867.909973"))))),(0,s.kt)("p",null,"LGTM \u2705"),(0,s.kt)("hr",null),(0,s.kt)("p",null,"Let's scale our data and then make predictions.",(0,s.kt)("br",{parentName:"p"}),"\n","As previously,"),(0,s.kt)("ol",null,(0,s.kt)("li",{parentName:"ol"},"Scale data"),(0,s.kt)("li",{parentName:"ol"},"Split data"),(0,s.kt)("li",{parentName:"ol"},"Fit data"),(0,s.kt)("li",{parentName:"ol"},"Predict data"),(0,s.kt)("li",{parentName:"ol"},"Validate")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"df_lr = log_return(df)\nX_train, X_valid, y_train, y_valid = train_test_split(df_lr.iloc[:, 1:], df_lr['GOOGL'], test_size=0.2, shuffle=False)\n\nfit_validate_plot(X_train, X_valid, y_train, y_valid)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"  $R^2$: -0.09291251083922969\n  MAPE: 10166738051.820312\n  MAE: 0.01198089072877809\n  \n")),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"png",src:a(4833).Z,width:"388",height:"260"})),(0,s.kt)("p",null,"Not great, not awful. Some self-exercises:"),(0,s.kt)("ol",null,(0,s.kt)("li",{parentName:"ol"},"How would we do without scaling?"),(0,s.kt)("li",{parentName:"ol"},"How would we do without shuffling?"),(0,s.kt)("li",{parentName:"ol"},"Any other ideas? Try 'em out!")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"# Test your own ideas\n")),(0,s.kt)("p",null,"If you didn't try previously, try appling a rolling mean and rerun  ",(0,s.kt)("inlineCode",{parentName:"p"},"fit_validate_plot"),' as this should reduce the "swings" and thereby be a little bit more predictable.'),(0,s.kt)("blockquote",null,(0,s.kt)("p",{parentName:"blockquote"},"\ud83d\udca1\n",(0,s.kt)("a",{parentName:"p",href:"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html"},(0,s.kt)("inlineCode",{parentName:"a"},"pd.DataFrame.Rolling")),": ",(0,s.kt)("em",{parentName:"p"},"Provide rolling window calculations."),(0,s.kt)("br",{parentName:"p"}),"\n","In other words: We slide a window on our data and do calculations, in our case ",(0,s.kt)("inlineCode",{parentName:"p"},"mean"),". This window includes ",(0,s.kt)("inlineCode",{parentName:"p"},"window"),", ",(0,s.kt)("inlineCode",{parentName:"p"},"min_periods"),", ",(0,s.kt)("inlineCode",{parentName:"p"},"center")," & more attributes which impacts size of window, how large minimal window can be, and more.")),(0,s.kt)("p",null,"Validating what ",(0,s.kt)("inlineCode",{parentName:"p"},"rolling.mean()")," does to our data:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"df['GOOGL_ROLLING'] = df['GOOGL'].rolling(3).mean()  # Rolling over 3 days mean\ndf[-100:].plot(y=['GOOGL', 'GOOGL_ROLLING'])\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"<matplotlib.axes._subplots.AxesSubplot at 0x7f1fb531bc90>\n")),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"png",src:a(8493).Z,width:"381",height:"260"})),(0,s.kt)("p",null,"Zooming \ud83d\udd0d"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"df_last_months = df[df.index > datetime(2021, 6, 6)]\n\n# df_last_months.plot(y=['GOOGL', 'GOOGL_ROLLING'], backend='plotly')\n")),(0,s.kt)("details",null,(0,s.kt)("summary",null,"Show Plotly Chart (code cell only visible in active notebook)"),(0,s.kt)("img",{src:"zoom-preds.png"})),(0,s.kt)("p",null,"The curve is ",(0,s.kt)("em",{parentName:"p"},"very")," similar, but different.  "),(0,s.kt)("blockquote",null,(0,s.kt)("p",{parentName:"blockquote"},(0,s.kt)("strong",{parentName:"p"},"Self-exercise"),": Test applying different functions like ",(0,s.kt)("inlineCode",{parentName:"p"},"min"),", ",(0,s.kt)("inlineCode",{parentName:"p"},"max")," and expanding window size into more days.")),(0,s.kt)("p",null,"And validating what this does to our prediction."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"df_lr = df.pct_change().dropna().rolling(3).mean().dropna()\nX_train, X_valid, y_train, y_valid = train_test_split(df_lr.iloc[:, 1:], df_lr['GOOGL'], test_size=0.2, shuffle=False)\n\nfit_validate_plot(X_train, X_valid, y_train, y_valid)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"  $R^2$: 0.8997161594986378\n  MAPE: 0.8209516085248725\n  MAE: 0.0019317335823510523\n  \n")),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"png",src:a(7749).Z,width:"389",height:"260"})),(0,s.kt)("p",null,"We're back! \ud83e\udd73"),(0,s.kt)("p",null,"It's not perfect, but we got something. And we can work with something. We can work with something... :)"),(0,s.kt)("blockquote",null,(0,s.kt)("p",{parentName:"blockquote"},(0,s.kt)("strong",{parentName:"p"},"Self-exercise"),": Validat how ",(0,s.kt)("inlineCode",{parentName:"p"},"rolling")," would affect our non-history-based forecasting")),(0,s.kt)("p",null,"Let's reverse our transformation to see what we'd actually predict in the end."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"y_rolling = df['GOOGL'].rolling(3).mean().dropna()\ny_train_non_scaled, y_valid_non_scaled = train_test_split(y_rolling, test_size=0.2, shuffle=False)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"clf = RandomForestRegressor()\nclf.fit(X_train, y_train)\npreds = clf.predict(X_valid)\n\npreds = (preds + 1).cumprod() # Cummulative multiplication, first day + 1%, but then we got -1%, that's 1.01 * 0.99\npreds = preds * y_train_non_scaled.iloc[-1] # Scaling it up based on the last training value\n\n# pd.DataFrame({'Preds': preds, 'Valid Rolling': y_valid_non_scaled[1:], 'Valid': df['GOOGL'].iloc[-len(preds):]}).plot(backend='plotly')\n")),(0,s.kt)("details",null,(0,s.kt)("summary",null,"Show Plotly Chart (code cell only visible in active notebook)"),(0,s.kt)("img",{src:"final-preds.png"})),(0,s.kt)("p",null,"Seems as we're a little low in our predictions, but the curve is followed after all."),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"What issues are left?")),(0,s.kt)("ol",null,(0,s.kt)("li",{parentName:"ol"},"We are not using an ",(0,s.kt)("inlineCode",{parentName:"li"},"AutoRegressive")," model which might be interesting.")),(0,s.kt)("ul",null,(0,s.kt)("li",{parentName:"ul"},"More about this in the next session")),(0,s.kt)("ol",{start:2},(0,s.kt)("li",{parentName:"ol"},'We are not using the "better" models, e.g. Neural Networks or statistic-model for Time Series like ',(0,s.kt)("inlineCode",{parentName:"li"},"ARIMA"),".")),(0,s.kt)("p",null,"Personally I'm very pleased with the results and can't wait to get started on ",(0,s.kt)("strong",{parentName:"p"},"part #3"),"!"),(0,s.kt)("hr",null),(0,s.kt)("p",null,"To learn more about Time Series and how one can analyze them please view the other parts,"),(0,s.kt)("ol",null,(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("a",{parentName:"li",href:"timeseries-pt-1"},"Part One - Decomposing & Working with Time Series (theoretical)")),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("a",{parentName:"li",href:"timeseries-pt-2"},"Part Two - Predicting Stock Prices (Time Series) using classical Machine Learning")),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("a",{parentName:"li",href:"timeseries-pt-3"},"Part Three -Forecasting Cryptocurrency Prices (Time Series) using Deep Learning (PyTorch, Tensorflow/Keras & darts)"))),(0,s.kt)("hr",null),(0,s.kt)("h4",{id:"extra-self-exercises"},"Extra Self Exercises"),(0,s.kt)("ol",null,(0,s.kt)("li",{parentName:"ol"},"Try different window-sizes with ",(0,s.kt)("inlineCode",{parentName:"li"},"rolling")),(0,s.kt)("li",{parentName:"ol"},"Try different length of history to predict new result on"),(0,s.kt)("li",{parentName:"ol"},"Test new architectures"),(0,s.kt)("li",{parentName:"ol"},"Find your own way to improve the results")))}u.isMDXComponent=!0},6157:function(t,e,a){e.Z=a.p+"assets/images/output_15_1-eac771ad08611e9a6229f2fa28b4886d.png"},1153:function(t,e,a){e.Z=a.p+"assets/images/output_26_1-0eb3b8de0560211d764f1688dbb3283e.png"},6786:function(t,e,a){e.Z=a.p+"assets/images/output_27_1-19dc9e3abe3e376feb3b4f116cad8b6c.png"},8767:function(t,e,a){e.Z=a.p+"assets/images/output_31_1-334b7cda7c02f5d3cb02a272b2e64977.png"},6367:function(t,e,a){e.Z=a.p+"assets/images/output_35_1-8355e5c703dfdc87c75f2dbbb422275b.png"},4946:function(t,e,a){e.Z=a.p+"assets/images/output_37_1-4a35347e69bf52cbc96feb1bf90e3ba2.png"},6350:function(t,e,a){e.Z=a.p+"assets/images/output_42_1-aa4705aa889f30f6f4304af58aa714f7.png"},4833:function(t,e,a){e.Z=a.p+"assets/images/output_52_1-7059b04ce6a1e0e7a30f1db99c79580a.png"},8493:function(t,e,a){e.Z=a.p+"assets/images/output_56_1-a598ec37df96e3f28420905ff167e55c.png"},7749:function(t,e,a){e.Z=a.p+"assets/images/output_61_1-48891e3002696f0ca239280ed84e319c.png"}}]);